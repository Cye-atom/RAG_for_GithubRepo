{
    "tests": [
        "AgentRunResult(output='Este documento pertence ao diretório \"tests\" e contém arquivos de testes automatizados para indicadores técnicos financeiros da biblioteca pandas-ta. Ele inclui testes para diferentes categorias de extensões, como candle, ciclos, momentum, sobreposição, performance e estatísticas. Além disso, os arquivos config.py e context.py configuram dados de amostra (sample_data) e o ambiente de testes. Tecnologias principais: Python, unittest, pandas, pandas-ta.')\ntests/__init__.py\n\n\n\n\ntests/config.py\n\nimport os\nfrom pandas import DatetimeIndex, read_csv\n\nVERBOSE  True\n\nALERT  f\"[!]\"\nINFO  f\"[i]\"\n\nCORRELATION  \"corr\"  # \"sem\"\nCORRELATION_THRESHOLD  0.99  # Less than 0.99 is undesirable\n\nsample_data  read_csv(\n    f\"data/SPY_D.csv\",\n    index_col0,\n    parse_datesTrue,\n    infer_datetime_formatTrue,\n    keep_date_colTrue,\n)\nsample_data.set_index(DatetimeIndex(sample_data[\"date\"]), inplaceTrue, dropTrue)\nsample_data.drop(\"date\", axis1, inplaceTrue)\n\n\ndef error_analysis(df, kind, msg, iconINFO, newlineTrue):\n    if VERBOSE:\n        s  f\"{icon} {df.name}['{kind}']: {msg}\"\n        if newline:\n            s  f\"\\n{s}\"\n        print(s)\n\n\n\ntests/context.py\n\nimport os\nimport sys\n\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n\nimport pandas_ta\n\n\n\ntests/test_ext_indicator_candle.py\n\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import TestCase\nfrom pandas import DataFrame\n\n\nclass TestCandleExtension(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_cdl_doji_ext(self):\n        self.data.ta.cdl_doji(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"CDL_DOJI_10_0.1\")\n\n    def test_cdl_inside_ext(self):\n        self.data.ta.cdl_inside(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"CDL_INSIDE\")\n\n    def test_ha_ext(self):\n        self.data.ta.ha(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-4:]), [\"HA_open\", \"HA_high\", \"HA_low\", \"HA_close\"])\n\n\n\ntests/test_ext_indicator_cycles.py\n\nfrom pandas.core.series import Series\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import TestCase\nfrom pandas import DataFrame\n\n\nclass TestCylesExtension(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_ebsw_ext(self):\n        self.data.ta.ebsw(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"EBSW_40_10\")\n\n\n\ntests/test_ext_indicator_momentum.py\n\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import skip, TestCase\nfrom pandas import DataFrame\n\n\nclass TestMomentumExtension(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_ao_ext(self):\n        self.data.ta.ao(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"AO_5_34\")\n\n    def test_apo_ext(self):\n        self.data.ta.apo(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"APO_12_26\")\n\n    def test_bias_ext(self):\n        self.data.ta.bias(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"BIAS_SMA_26\")\n\n    def test_bop_ext(self):\n        self.data.ta.bop(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"BOP\")\n\n    def test_brar_ext(self):\n        self.data.ta.brar(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"AR_26\", \"BR_26\"])\n\n    def test_cci_ext(self):\n        self.data.ta.cci(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"CCI_14_0.015\")\n\n    def test_cfo_ext(self):\n        self.data.ta.cfo(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"CFO_9\")\n\n    def test_cg_ext(self):\n        self.data.ta.cg(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"CG_10\")\n\n    def test_cmo_ext(self):\n        self.data.ta.cmo(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"CMO_14\")\n\n    def test_coppock_ext(self):\n        self.data.ta.coppock(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"COPC_11_14_10\")\n\n    def test_er_ext(self):\n        self.data.ta.er(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"ER_10\")\n\n    def test_eri_ext(self):\n        self.data.ta.eri(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"BULLP_13\", \"BEARP_13\"])\n\n    def test_fisher_ext(self):\n        self.data.ta.fisher(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"FISHERT_9_1\", \"FISHERTs_9_1\"])\n\n    def test_inertia_ext(self):\n        self.data.ta.inertia(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"INERTIA_20_14\")\n\n    def test_inertia_refined_ext(self):\n        self.data.ta.inertia(refinedTrue, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"INERTIAr_20_14\")\n\n    def test_inertia_thirds_ext(self):\n        self.data.ta.inertia(thirdsTrue, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"INERTIAt_20_14\")\n\n    def test_kdj_ext(self):\n        self.data.ta.kdj(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-3:]), [\"K_9_3\", \"D_9_3\", \"J_9_3\"])\n\n    def test_kst_ext(self):\n        self.data.ta.kst(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"KST_10_15_20_30_10_10_10_15\", \"KSTs_9\"])\n\n    def test_macd_ext(self):\n        self.data.ta.macd(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-3:]), [\"MACD_12_26_9\", \"MACDh_12_26_9\", \"MACDs_12_26_9\"])\n\n    def test_mom_ext(self):\n        self.data.ta.mom(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"MOM_10\")\n\n    def test_pgo_ext(self):\n        self.data.ta.pgo(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"PGO_14\")\n\n    def test_ppo_ext(self):\n        self.data.ta.ppo(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-3:]), [\"PPO_12_26_9\", \"PPOh_12_26_9\", \"PPOs_12_26_9\"])\n\n    def test_psl_ext(self):\n        self.data.ta.psl(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"PSL_12\")\n\n    def test_pvo_ext(self):\n        self.data.ta.pvo(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-3:]), [\"PVO_12_26_9\", \"PVOh_12_26_9\", \"PVOs_12_26_9\"])\n\n    def test_qqe_ext(self):\n        self.data.ta.qqe(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-4:]), [\"QQE_14_5_4.236\", \"QQE_14_5_4.236_RSIMA\", \"QQEl_14_5_4.236\", \"QQEs_14_5_4.236\"])\n\n    def test_roc_ext(self):\n        self.data.ta.roc(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"ROC_10\")\n\n    def test_rsi_ext(self):\n        self.data.ta.rsi(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"RSI_14\")\n\n    def test_rsx_ext(self):\n        self.data.ta.rsx(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"RSX_14\")\n\n    def test_rvgi_ext(self):\n        self.data.ta.rvgi(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"RVGI_14_4\", \"RVGIs_14_4\"])\n\n    def test_slope_ext(self):\n        self.data.ta.slope(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"SLOPE_1\")\n\n        self.data.ta.slope(appendTrue, as_angleTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"ANGLEr_1\")\n\n        self.data.ta.slope(appendTrue, as_angleTrue, to_degreesTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"ANGLEd_1\")\n\n    def test_smi_ext(self):\n        self.data.ta.smi(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-3:]), [\"SMI_5_20_5\", \"SMIs_5_20_5\", \"SMIo_5_20_5\"])\n\n        self.data.ta.smi(scalar10, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-3:]), [\"SMI_5_20_5_10.0\", \"SMIs_5_20_5_10.0\", \"SMIo_5_20_5_10.0\"])\n\n    def test_squeeze_ext(self):\n        self.data.ta.squeeze(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-4:]), [\"SQZ_20_2.0_20_1.5\", \"SQZ_ON\", \"SQZ_OFF\", \"SQZ_NO\"])\n\n        self.data.ta.squeeze(trFalse, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(\n            list(self.data.columns[-4:]),\n            [\"SQZ_ON\", \"SQZ_OFF\", \"SQZ_NO\", \"SQZhlr_20_2.0_20_1.5\"]\n        )\n\n    def test_stoch_ext(self):\n        self.data.ta.stoch(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"STOCHk_14_3_3\", \"STOCHd_14_3_3\"])\n\n    def test_stochrsi_ext(self):\n        self.data.ta.stochrsi(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"STOCHRSIk_14_14_3_3\", \"STOCHRSId_14_14_3_3\"])\n\n    def test_td_seq_ext(self):\n        self.data.ta.td_seq(show_allFalse, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"TD_SEQ_UP\", \"TD_SEQ_DN\"])\n\n        self.data.ta.td_seq(show_allTrue, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"TD_SEQ_UPa\", \"TD_SEQ_DNa\"])\n\n    def test_trix_ext(self):\n        self.data.ta.trix(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"TRIX_30_9\", \"TRIXs_30_9\"])\n\n    def test_tsi_ext(self):\n        self.data.ta.tsi(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"TSI_13_25\")\n\n    def test_uo_ext(self):\n        self.data.ta.uo(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"UO_7_14_28\")\n\n    def test_willr_ext(self):\n        self.data.ta.willr(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"WILLR_14\")\n\n\n\ntests/test_ext_indicator_overlap_ext.py\n\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import skip, TestCase\nfrom pandas import DataFrame\n\n\nclass TestOverlapExtension(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_alma_ext(self):\n        self.data.ta.alma(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"ALMA_10_6.0_0.85\")\n\n    def test_dema_ext(self):\n        self.data.ta.dema(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"DEMA_10\")\n\n    def test_ema_ext(self):\n        self.data.ta.ema(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"EMA_10\")\n\n    def test_fwma_ext(self):\n        self.data.ta.fwma(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"FWMA_10\")\n\n    def test_hilo_ext(self):\n        self.data.ta.hilo(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-3:]), [\"HILO_13_21\", \"HILOl_13_21\", \"HILOs_13_21\"])\n\n    def test_hl2_ext(self):\n        self.data.ta.hl2(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"HL2\")\n\n    def test_hlc3_ext(self):\n        self.data.ta.hlc3(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"HLC3\")\n\n    def test_hma_ext(self):\n        self.data.ta.hma(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"HMA_10\")\n\n    def test_hwma_ext(self):\n        self.data.ta.hwma(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"HWMA_0.2_0.1_0.1\")\n\n    def test_kama_ext(self):\n        self.data.ta.kama(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"KAMA_10_2_30\")\n\n    def test_ichimoku_ext(self):\n        self.data.ta.ichimoku(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-5:]), [\"ISA_9\", \"ISB_26\", \"ITS_9\", \"IKS_26\", \"ICS_26\"])\n\n    def test_linreg_ext(self):\n        self.data.ta.linreg(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"LR_14\")\n\n    def test_mcgd_ext(self):\n        self.data.ta.mcgd(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"MCGD_10\")\n\n    def test_midpoint_ext(self):\n        self.data.ta.midpoint(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"MIDPOINT_2\")\n\n    def test_midprice_ext(self):\n        self.data.ta.midprice(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"MIDPRICE_2\")\n\n    def test_ohlc4_ext(self):\n        self.data.ta.ohlc4(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"OHLC4\")\n\n    def test_pwma_ext(self):\n        self.data.ta.pwma(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"PWMA_10\")\n\n    def test_rma_ext(self):\n        self.data.ta.rma(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"RMA_10\")\n\n    def test_sinwma_ext(self):\n        self.data.ta.sinwma(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"SINWMA_14\")\n\n    def test_sma_ext(self):\n        self.data.ta.sma(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"SMA_10\")\n\n    def test_ssf_ext(self):\n        self.data.ta.ssf(appendTrue, poles2)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"SSF_10_2\")\n\n        self.data.ta.ssf(appendTrue, poles3)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"SSF_10_3\")\n\n    def test_swma_ext(self):\n        self.data.ta.swma(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"SWMA_10\")\n\n    def test_supertrend_ext(self):\n        self.data.ta.supertrend(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-4:]), [\"SUPERT_7_3.0\", \"SUPERTd_7_3.0\", \"SUPERTl_7_3.0\", \"SUPERTs_7_3.0\"])\n\n    def test_t3_ext(self):\n        self.data.ta.t3(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"T3_10_0.7\")\n\n    def test_tema_ext(self):\n        self.data.ta.tema(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"TEMA_10\")\n\n    def test_trima_ext(self):\n        self.data.ta.trima(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"TRIMA_10\")\n\n    def test_vidya_ext(self):\n        self.data.ta.vidya(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"VIDYA_14\")\n\n    def test_vwap_ext(self):\n        self.data.ta.vwap(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"VWAP_D\")\n\n    def test_vwma_ext(self):\n        self.data.ta.vwma(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"VWMA_10\")\n\n    def test_wcp_ext(self):\n        self.data.ta.wcp(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"WCP\")\n\n    def test_wma_ext(self):\n        self.data.ta.wma(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"WMA_10\")\n\n    def test_zlma_ext(self):\n        self.data.ta.zlma(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"ZL_EMA_10\")\n\n\n\ntests/test_ext_indicator_performance.py\n\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import TestCase\nfrom pandas import DataFrame\n\n\nclass TestPerformaceExtension(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.islong  cls.data[\"close\"] > pandas_ta.sma(cls.data[\"close\"], length50)\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.data\n        del cls.islong\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_log_return_ext(self):\n        self.data.ta.log_return(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"LOGRET_1\")\n\n    def test_cum_log_return_ext(self):\n        self.data.ta.log_return(appendTrue, cumulativeTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"CUMLOGRET_1\")\n\n    def test_percent_return_ext(self):\n        self.data.ta.percent_return(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"PCTRET_1\")\n\n    def test_cum_percent_return_ext(self):\n        self.data.ta.percent_return(appendTrue, cumulativeTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"CUMPCTRET_1\")\n\n    def test_log_trend_return_ext(self):\n        tr  self.data.ta.trend_return(trendself.islong, logTrue, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-6:]), list(tr.columns))\n        self.data.drop(columnstr.columns, inplaceTrue, errors\"ignore\")\n\n    def test_pct_trend_return_ext(self):\n        tr  self.data.ta.trend_return(trendself.islong, logFalse, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-6:]), list(tr.columns))\n        self.data.drop(columnstr.columns, inplaceTrue, errors\"ignore\")\n\n\ntests/test_ext_indicator_statistics.py\n\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import TestCase\nfrom pandas import DataFrame\n\n\nclass TestStatisticsExtension(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_entropy_ext(self):\n        self.data.ta.entropy(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"ENTP_10\")\n\n    def test_kurtosis_ext(self):\n        self.data.ta.kurtosis(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"KURT_30\")\n\n    def test_mad_ext(self):\n        self.data.ta.mad(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"MAD_30\")\n\n    def test_median_ext(self):\n        self.data.ta.median(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"MEDIAN_30\")\n\n    def test_quantile_ext(self):\n        self.data.ta.quantile(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"QTL_30_0.5\")\n\n    def test_skew_ext(self):\n        self.data.ta.skew(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"SKEW_30\")\n\n    def test_stdev_ext(self):\n        self.data.ta.stdev(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"STDEV_30\")\n\n    def test_variance_ext(self):\n        self.data.ta.variance(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"VAR_30\")\n\n\n\n",
        "AgentRunResult(output='Contexto: Diretório tests na raiz do projeto, contendo testes unitários que verificam a extensão da biblioteca pandas_ta.\\n\\nTópicos e Tecnologias:\\n- Python, unittest, pandas, pandas_ta, TA-Lib (talib)\\n- Testes de indicadores técnicos:\\n  - Tendência (ADX, Aroon, PSAR, TTM Trend)\\n  - Volatilidade (ATR, BBands, Donchian, NATR)\\n  - Volume (OBV, CMF, PVT)\\n  - Candle patterns (Doji, Inside)\\n  - Ciclos (EBSW)\\n- Estrutura comum: uso de pandas DataFrame/Series, validação de colunas resultantes, comportamento de extensões.')\ntests/test_ext_indicator_trend.py\n\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import skip, TestCase\nfrom pandas import DataFrame\n\n\nclass TestTrendExtension(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_adx_ext(self):\n        self.data.ta.adx(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-3:]), [\"ADX_14\", \"DMP_14\", \"DMN_14\"])\n\n    def test_amat_ext(self):\n        self.data.ta.amat(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"AMATe_LR_2\", \"AMATe_SR_2\"])\n\n    def test_aroon_ext(self):\n        self.data.ta.aroon(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-3:]), [\"AROOND_14\", \"AROONU_14\", \"AROONOSC_14\"])\n\n    def test_chop_ext(self):\n        self.data.ta.chop(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"CHOP_14_1_100\")\n\n    def test_cksp_ext(self):\n        self.data.ta.cksp(tvmodeFalse, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        print(self.data.columns[-3:])\n        self.assertEqual(list(self.data.columns[-2:]), [\"CKSPl_10_3_20\", \"CKSPs_10_3_20\"])\n\n    def test_cksp_tv_ext(self):\n        self.data.ta.cksp(tvmodeTrue, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"CKSPl_10_1_9\", \"CKSPs_10_1_9\"])\n\n    def test_decay_ext(self):\n        self.data.ta.decay(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"LDECAY_5\")\n\n        self.data.ta.decay(mode\"exp\", appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"EXPDECAY_5\")\n\n    def test_decreasing_ext(self):\n        self.data.ta.decreasing(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"DEC_1\")\n\n        self.data.ta.decreasing(length3, strictTrue, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"SDEC_3\")\n\n    def test_dpo_ext(self):\n        self.data.ta.dpo(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"DPO_20\")\n\n    def test_increasing_ext(self):\n        self.data.ta.increasing(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"INC_1\")\n\n        self.data.ta.increasing(length3, strictTrue, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"SINC_3\")\n\n    def test_long_run_ext(self):\n        # Nothing passed, return self\n        self.assertEqual(self.data.ta.long_run(appendTrue).shape, self.data.shape)\n\n        fast  self.data.ta.ema(8)\n        slow  self.data.ta.ema(21)\n        self.data.ta.long_run(fast, slow, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"LR_2\")\n\n    def test_psar_ext(self):\n        self.data.ta.psar(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(\n            list(self.data.columns[-4:]), [\"PSARl_0.02_0.2\", \"PSARs_0.02_0.2\", \"PSARaf_0.02_0.2\", \"PSARr_0.02_0.2\"])\n\n    def test_qstick_ext(self):\n        self.data.ta.qstick(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"QS_10\")\n\n    def test_short_run_ext(self):\n        # Nothing passed, return self\n        self.assertEqual(\n            self.data.ta.short_run(appendTrue).shape, self.data.shape)\n\n        fast  self.data.ta.ema(8)\n        slow  self.data.ta.ema(21)\n        self.data.ta.short_run(fast, slow, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"SR_2\")\n\n    def test_ttm_trend_ext(self):\n        self.data.ta.ttm_trend(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-1:]), [\"TTM_TRND_6\"])\n\n    def test_vortext_ext(self):\n        self.data.ta.vortex(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-2:]), [\"VTXP_14\", \"VTXM_14\"])\n\n\n\ntests/test_ext_indicator_volatility.py\n\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import TestCase\nfrom pandas import DataFrame\n\n\nclass TestVolatilityExtension(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_aberration_ext(self):\n        self.data.ta.aberration(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-4:]), [\"ABER_ZG_5_15\", \"ABER_SG_5_15\", \"ABER_XG_5_15\", \"ABER_ATR_5_15\"])\n\n    def test_accbands_ext(self):\n        self.data.ta.accbands(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-3:]), [\"ACCBL_20\", \"ACCBM_20\", \"ACCBU_20\"])\n\n    def test_atr_ext(self):\n        self.data.ta.atr(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"ATRr_14\")\n\n    def test_bbands_ext(self):\n        self.data.ta.bbands(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-4:]), [\"BBL_5_2.0\", \"BBM_5_2.0\", \"BBU_5_2.0\", \"BBB_5_2.0\"])\n\n    def test_donchian_ext(self):\n        self.data.ta.donchian(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-3:]), [\"DCL_20_20\", \"DCM_20_20\", \"DCU_20_20\"])\n\n    def test_kc_ext(self):\n        self.data.ta.kc(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-3:]), [\"KCLe_20_2\", \"KCBe_20_2\", \"KCUe_20_2\"])\n\n    def test_massi_ext(self):\n        self.data.ta.massi(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"MASSI_9_25\")\n\n    def test_natr_ext(self):\n        self.data.ta.natr(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"NATR_14\")\n\n    def test_pdist_ext(self):\n        self.data.ta.pdist(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"PDIST\")\n\n    def test_rvi_ext(self):\n        self.data.ta.rvi(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"RVI_14\")\n\n    def test_rvi_refined_ext(self):\n        self.data.ta.rvi(refinedTrue, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"RVIr_14\")\n\n    def test_rvi_thirds_ext(self):\n        self.data.ta.rvi(thirdsTrue, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"RVIt_14\")\n\n    def test_thermo_ext(self):\n        self.data.ta.thermo(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(list(self.data.columns[-4:]), [\"THERMO_20_2_0.5\", \"THERMOma_20_2_0.5\", \"THERMOl_20_2_0.5\", \"THERMOs_20_2_0.5\"])\n\n    def test_true_range_ext(self):\n        self.data.ta.true_range(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"TRUERANGE_1\")\n\n    def test_ui_ext(self):\n        self.data.ta.ui(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"UI_14\")\n\n        self.data.ta.ui(appendTrue, evergetTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"UIe_14\")\n\n\n\ntests/test_ext_indicator_volume.py\n\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import TestCase\nfrom pandas import DataFrame\n\n\nclass TestVolumeExtension(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.open  cls.data[\"open\"]\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.data\n        del cls.open\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_ad_ext(self):\n        self.data.ta.ad(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"AD\")\n\n    def test_ad_open_ext(self):\n        self.data.ta.ad(open_self.open, appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"ADo\")\n\n    def test_adosc_ext(self):\n        self.data.ta.adosc(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"ADOSC_3_10\")\n\n    def test_aobv_ext(self):\n        self.data.ta.aobv(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(\n            list(self.data.columns[-7:]),\n            [\"OBV\", \"OBV_min_2\", \"OBV_max_2\", \"OBVe_4\", \"OBVe_12\", \"AOBV_LR_2\", \"AOBV_SR_2\"],\n        )\n        # Remove \"OBV\" so it does not interfere with test_obv_ext()\n        self.data.drop(\"OBV\", axis1, inplaceTrue)\n\n    def test_cmf_ext(self):\n        self.data.ta.cmf(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"CMF_20\")\n\n    def test_efi_ext(self):\n        self.data.ta.efi(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"EFI_13\")\n\n    def test_eom_ext(self):\n        self.data.ta.eom(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"EOM_14_100000000\")\n\n    def test_mfi_ext(self):\n        self.data.ta.mfi(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"MFI_14\")\n\n    def test_nvi_ext(self):\n        self.data.ta.nvi(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"NVI_1\")\n\n    def test_obv_ext(self):\n        self.data.ta.obv(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"OBV\")\n\n    def test_pvi_ext(self):\n        self.data.ta.pvi(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"PVI_1\")\n\n    def test_pvol_ext(self):\n        self.data.ta.pvol(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"PVOL\")\n\n    def test_pvr_ext(self):\n        self.data.ta.pvr(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"PVR\")\n\n    def test_pvt_ext(self):\n        self.data.ta.pvt(appendTrue)\n        self.assertIsInstance(self.data, DataFrame)\n        self.assertEqual(self.data.columns[-1], \"PVT\")\n\n    def test_vp_ext(self):\n        result  self.data.ta.vp()\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"VP_10\")\n\n\n\ntests/test_indicator_candle.py\n\nfrom .config import error_analysis, sample_data, CORRELATION, CORRELATION_THRESHOLD, VERBOSE\nfrom .context import pandas_ta\n\nfrom unittest import TestCase, skip\nimport pandas.testing as pdt\nfrom pandas import DataFrame, Series\n\nimport talib as tal\n\n\nclass TestCandle(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.data.columns  cls.data.columns.str.lower()\n        cls.open  cls.data[\"open\"]\n        cls.high  cls.data[\"high\"]\n        cls.low  cls.data[\"low\"]\n        cls.close  cls.data[\"close\"]\n        if \"volume\" in cls.data.columns:\n            cls.volume  cls.data[\"volume\"]\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.open\n        del cls.high\n        del cls.low\n        del cls.close\n        if hasattr(cls, \"volume\"):\n            del cls.volume\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_ha(self):\n        result  pandas_ta.ha(self.open, self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"Heikin-Ashi\")\n\n    def test_cdl_doji(self):\n        result  pandas_ta.cdl_doji(self.open, self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"CDL_DOJI_10_0.1\")\n\n        try:\n            expected  tal.CDLDOJI(self.open, self.high, self.low, self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_cdl_inside(self):\n        result  pandas_ta.cdl_inside(self.open, self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"CDL_INSIDE\")\n\n        result  pandas_ta.cdl_inside(self.open, self.high, self.low, self.close, asboolTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"CDL_INSIDE\")\n\n\n\ntests/test_indicator_cycles.py\n\nfrom .config import error_analysis, sample_data, CORRELATION, CORRELATION_THRESHOLD, VERBOSE\nfrom .context import pandas_ta\n\nfrom unittest import TestCase, skip\nimport pandas.testing as pdt\nfrom pandas import DataFrame, Series\n\nimport talib as tal\n\n\nclass TestCycles(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.data.columns  cls.data.columns.str.lower()\n        cls.open  cls.data[\"open\"]\n        cls.high  cls.data[\"high\"]\n        cls.low  cls.data[\"low\"]\n        cls.close  cls.data[\"close\"]\n        if \"volume\" in cls.data.columns:\n            cls.volume  cls.data[\"volume\"]\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.open\n        del cls.high\n        del cls.low\n        del cls.close\n        if hasattr(cls, \"volume\"):\n            del cls.volume\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_ebsw(self):\n        result  pandas_ta.ebsw(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"EBSW_40_10\")\n\n\n\n",
        "AgentRunResult(output='Context: Root/tests  \\nThis file contains unit tests for momentum-based technical indicators using the pandas_ta and TA-Lib libraries. Tests assess correctness, correlation, and consistency of indicator outputs.')\ntests/test_indicator_momentum.py\n\nfrom .config import error_analysis, sample_data, CORRELATION, CORRELATION_THRESHOLD, VERBOSE\nfrom .context import pandas_ta\n\nfrom unittest import TestCase, skip\nimport pandas.testing as pdt\nfrom pandas import DataFrame, Series\n\nimport talib as tal\n\n\nclass TestMomentum(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.data.columns  cls.data.columns.str.lower()\n        cls.open  cls.data[\"open\"]\n        cls.high  cls.data[\"high\"]\n        cls.low  cls.data[\"low\"]\n        cls.close  cls.data[\"close\"]\n        if \"volume\" in cls.data.columns:\n            cls.volume  cls.data[\"volume\"]\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.open\n        del cls.high\n        del cls.low\n        del cls.close\n        if hasattr(cls, \"volume\"):\n            del cls.volume\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_datetime_ordered(self):\n        # Test if datetime64 index and ordered\n        result  self.data.ta.datetime_ordered\n        self.assertTrue(result)\n\n        # Test if not ordered\n        original  self.data.copy()\n        reversal  original.ta.reverse\n        result  reversal.ta.datetime_ordered\n        self.assertFalse(result)\n\n        # Test a non-datetime64 index\n        original  self.data.copy()\n        original.reset_index(inplaceTrue)\n        result  original.ta.datetime_ordered\n        self.assertFalse(result)\n\n    def test_reverse(self):\n        original  self.data.copy()\n        result  original.ta.reverse\n\n        # Check if first and last time are reversed\n        self.assertEqual(result.index[-1], original.index[0])\n        self.assertEqual(result.index[0], original.index[-1])\n\n    def test_ao(self):\n        result  pandas_ta.ao(self.high, self.low)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"AO_5_34\")\n\n    def test_apo(self):\n        result  pandas_ta.apo(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"APO_12_26\")\n\n        try:\n            expected  tal.APO(self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_bias(self):\n        result  pandas_ta.bias(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"BIAS_SMA_26\")\n\n    def test_bop(self):\n        result  pandas_ta.bop(self.open, self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"BOP\")\n\n        try:\n            expected  tal.BOP(self.open, self.high, self.low, self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_brar(self):\n        result  pandas_ta.brar(self.open, self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"BRAR_26\")\n\n    def test_cci(self):\n        result  pandas_ta.cci(self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"CCI_14_0.015\")\n\n        try:\n            expected  tal.CCI(self.high, self.low, self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_cfo(self):\n        result  pandas_ta.cfo(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"CFO_9\")\n\n    def test_cg(self):\n        result  pandas_ta.cg(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"CG_10\")\n\n    def test_cmo(self):\n        result  pandas_ta.cmo(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"CMO_14\")\n\n        try:\n            expected  tal.CMO(self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_coppock(self):\n        result  pandas_ta.coppock(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"COPC_11_14_10\")\n\n    def test_er(self):\n        result  pandas_ta.er(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"ER_10\")\n\n    def test_eri(self):\n        result  pandas_ta.eri(self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"ERI_13\")\n\n    def test_fisher(self):\n        result  pandas_ta.fisher(self.high, self.low)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"FISHERT_9_1\")\n\n    def test_inertia(self):\n        result  pandas_ta.inertia(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"INERTIA_20_14\")\n\n        result  pandas_ta.inertia(self.close, self.high, self.low, refinedTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"INERTIAr_20_14\")\n\n        result  pandas_ta.inertia(self.close, self.high, self.low, thirdsTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"INERTIAt_20_14\")\n\n    def test_kdj(self):\n        result  pandas_ta.kdj(self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"KDJ_9_3\")\n\n    def test_kst(self):\n        result  pandas_ta.kst(self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"KST_10_15_20_30_10_10_10_15_9\")\n\n    def test_macd(self):\n        result  pandas_ta.macd(self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"MACD_12_26_9\")\n\n        try:\n            expected  tal.MACD(self.close)\n            expecteddf  DataFrame({\"MACD_12_26_9\": expected[0], \"MACDh_12_26_9\": expected[2], \"MACDs_12_26_9\": expected[1]})\n            pdt.assert_frame_equal(result, expecteddf)\n        except AssertionError as ae:\n            try:\n                macd_corr  pandas_ta.utils.df_error_analysis(result.iloc[:, 0], expecteddf.iloc[:, 0], colCORRELATION)\n                self.assertGreater(macd_corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result.iloc[:, 0], CORRELATION, ex)\n\n            try:\n                history_corr  pandas_ta.utils.df_error_analysis(result.iloc[:, 1], expecteddf.iloc[:, 1], colCORRELATION)\n                self.assertGreater(history_corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result.iloc[:, 1], CORRELATION, ex, newlineFalse)\n\n            try:\n                signal_corr  pandas_ta.utils.df_error_analysis(result.iloc[:, 2], expecteddf.iloc[:, 2], colCORRELATION)\n                self.assertGreater(signal_corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result.iloc[:, 2], CORRELATION, ex, newlineFalse)\n\n    def test_mom(self):\n        result  pandas_ta.mom(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"MOM_10\")\n\n        try:\n            expected  tal.MOM(self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_pgo(self):\n        result  pandas_ta.pgo(self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"PGO_14\")\n\n    def test_ppo(self):\n        result  pandas_ta.ppo(self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"PPO_12_26_9\")\n\n        try:\n            expected  tal.PPO(self.close)\n            pdt.assert_series_equal(result[\"PPO_12_26_9\"], expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result[\"PPO_12_26_9\"], expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result[\"PPO_12_26_9\"], CORRELATION, ex)\n\n    def test_psl(self):\n        result  pandas_ta.psl(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"PSL_12\")\n\n    def test_pvo(self):\n        result  pandas_ta.pvo(self.volume)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"PVO_12_26_9\")\n\n    def test_qqe(self):\n        result  pandas_ta.qqe(self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"QQE_14_5_4.236\")\n\n    def test_roc(self):\n        result  pandas_ta.roc(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"ROC_10\")\n\n        try:\n            expected  tal.ROC(self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_rsi(self):\n        result  pandas_ta.rsi(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"RSI_14\")\n\n        try:\n            expected  tal.RSI(self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_rsx(self):\n        result  pandas_ta.rsx(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"RSX_14\")\n\n    def test_rvgi(self):\n        result  pandas_ta.rvgi(self.open, self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"RVGI_14_4\")\n\n    def test_slope(self):\n        result  pandas_ta.slope(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"SLOPE_1\")\n\n    def test_slope_as_angle(self):\n        result  pandas_ta.slope(self.close, as_angleTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"ANGLEr_1\")\n\n    def test_slope_as_angle_to_degrees(self):\n        result  pandas_ta.slope(self.close, as_angleTrue, to_degreesTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"ANGLEd_1\")\n\n    def test_smi(self):\n        result  pandas_ta.smi(self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"SMI_5_20_5\")\n        self.assertEqual(len(result.columns), 3)\n\n    def test_smi_scalar(self):\n        result  pandas_ta.smi(self.close, scalar10)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"SMI_5_20_5_10.0\")\n        self.assertEqual(len(result.columns), 3)\n\n    def test_squeeze(self):\n        result  pandas_ta.squeeze(self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"SQZ_20_2.0_20_1.5\")\n\n        result  pandas_ta.squeeze(self.high, self.low, self.close, trFalse)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"SQZhlr_20_2.0_20_1.5\")\n\n        result  pandas_ta.squeeze(self.high, self.low, self.close, lazybearTrue)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"SQZ_20_2.0_20_1.5_LB\")\n\n        result  pandas_ta.squeeze(self.high, self.low, self.close, trFalse, lazybearTrue)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"SQZhlr_20_2.0_20_1.5_LB\")\n\n    # @skip\n    def test_stoch(self):\n        # TV Correlation\n        result  pandas_ta.stoch(self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"STOCH_14_3_3\")\n\n    def test_stochrsi(self):\n        # TV Correlation\n        result  pandas_ta.stochrsi(self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"STOCHRSI_14_14_3_3\")\n\n    def test_td_seq(self):\n        result  pandas_ta.td_seq(self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"TD_SEQ\")\n\n    def test_trix(self):\n        result  pandas_ta.trix(self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"TRIX_30_9\")\n\n    def test_tsi(self):\n        result  pandas_ta.tsi(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"TSI_13_25\")\n\n    def test_uo(self):\n        result  pandas_ta.uo(self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"UO_7_14_28\")\n\n        try:\n            expected  tal.ULTOSC(self.high, self.low, self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_willr(self):\n        result  pandas_ta.willr(self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"WILLR_14\")\n\n        try:\n            expected  tal.WILLR(self.high, self.low, self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n\n\n",
        "AgentRunResult(output='Este conteúdo está na pasta raiz/tests e contém testes unitários para o pacote pandas_ta. Os arquivos testam indicadores técnicos usados em análise técnica de séries temporais:\\n\\n- test_indicator_overlap.py: testa indicadores de sobreposição como médias móveis (SMA, EMA, WMA, HMA, etc.), ichimoku, supertrend e VWAP.\\n- test_indicator_performance.py: testa funções de retorno (logarítmico, percentual, cumulativo) e estratégias baseadas em tendência.\\n- test_indicator_statistics.py: testa estatísticas descritivas como entropia, desvio padrão, z-score, variância e curtose.\\n- test_indicator_trend.py: testa indicadores de tendência como ADX, Aroon, SAR, DPO, CHOP, PSAR, Vortex e funções personalizadas como decay, increasing/decreasing e long_run/short_run.\\n\\nTecnologias: unittest, pandas, pandas.testing, TA-Lib, pandas_ta.')\ntests/test_indicator_overlap.py\n\nfrom .config import CORRELATION, CORRELATION_THRESHOLD, error_analysis, sample_data, VERBOSE\nfrom .context import pandas_ta\n\nfrom unittest import TestCase\nimport pandas.testing as pdt\nfrom pandas import DataFrame, Series\n\nimport talib as tal\n\n\nclass TestOverlap(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.data.columns  cls.data.columns.str.lower()\n        cls.open  cls.data[\"open\"]\n        cls.high  cls.data[\"high\"]\n        cls.low  cls.data[\"low\"]\n        cls.close  cls.data[\"close\"]\n        if \"volume\" in cls.data.columns:\n            cls.volume  cls.data[\"volume\"]\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.open\n        del cls.high\n        del cls.low\n        del cls.close\n        if hasattr(cls, \"volume\"):\n            del cls.volume\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_alma(self):\n        result  pandas_ta.alma(self.close)# , lengthNone, sigmaNone, distribution_offset)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"ALMA_10_6.0_0.85\")\n\n    def test_dema(self):\n        result  pandas_ta.dema(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"DEMA_10\")\n\n        try:\n            expected  tal.DEMA(self.close, 10)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_ema(self):\n        result  pandas_ta.ema(self.close, presmaFalse)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"EMA_10\")\n\n        try:\n            expected  tal.EMA(self.close, 10)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_fwma(self):\n        result  pandas_ta.fwma(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"FWMA_10\")\n\n    def test_hilo(self):\n        result  pandas_ta.hilo(self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"HILO_13_21\")\n\n    def test_hl2(self):\n        result  pandas_ta.hl2(self.high, self.low)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"HL2\")\n\n    def test_hlc3(self):\n        result  pandas_ta.hlc3(self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"HLC3\")\n\n        try:\n            expected  tal.TYPPRICE(self.high, self.low, self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_hma(self):\n        result  pandas_ta.hma(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"HMA_10\")\n\n    def test_hwma(self):\n        result  pandas_ta.hwma(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"HWMA_0.2_0.1_0.1\")\n\n    def test_kama(self):\n        result  pandas_ta.kama(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"KAMA_10_2_30\")\n\n    def test_ichimoku(self):\n        ichimoku, span  pandas_ta.ichimoku(self.high, self.low, self.close)\n        self.assertIsInstance(ichimoku, DataFrame)\n        self.assertIsInstance(span, DataFrame)\n        self.assertEqual(ichimoku.name, \"ICHIMOKU_9_26_52\")\n        self.assertEqual(span.name, \"ICHISPAN_9_26\")\n\n    def test_linreg(self):\n        result  pandas_ta.linreg(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"LR_14\")\n\n        try:\n            expected  tal.LINEARREG(self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_linreg_angle(self):\n        result  pandas_ta.linreg(self.close, angleTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"LRa_14\")\n\n        try:\n            expected  tal.LINEARREG_ANGLE(self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_linreg_intercept(self):\n        result  pandas_ta.linreg(self.close, interceptTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"LRb_14\")\n\n        try:\n            expected  tal.LINEARREG_INTERCEPT(self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_linreg_r(self):\n        result  pandas_ta.linreg(self.close, rTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"LRr_14\")\n\n    def test_linreg_slope(self):\n        result  pandas_ta.linreg(self.close, slopeTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"LRm_14\")\n\n        try:\n            expected  tal.LINEARREG_SLOPE(self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_ma(self):\n        result  pandas_ta.ma()\n        self.assertIsInstance(result, list)\n        self.assertGreater(len(result), 0)\n\n        result  pandas_ta.ma(\"ema\", self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"EMA_10\")\n\n        result  pandas_ta.ma(\"fwma\", self.close, length15)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"FWMA_15\")\n\n    def test_mcgd(self):\n        result  pandas_ta.mcgd(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"MCGD_10\")\n\n    def test_midpoint(self):\n        result  pandas_ta.midpoint(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"MIDPOINT_2\")\n\n        try:\n            expected  tal.MIDPOINT(self.close, 2)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_midprice(self):\n        result  pandas_ta.midprice(self.high, self.low)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"MIDPRICE_2\")\n\n        try:\n            expected  tal.MIDPRICE(self.high, self.low, 2)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_ohlc4(self):\n        result  pandas_ta.ohlc4(self.open, self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"OHLC4\")\n\n    def test_pwma(self):\n        result  pandas_ta.pwma(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"PWMA_10\")\n\n    def test_rma(self):\n        result  pandas_ta.rma(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"RMA_10\")\n\n    def test_sinwma(self):\n        result  pandas_ta.sinwma(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"SINWMA_14\")\n\n    def test_sma(self):\n        result  pandas_ta.sma(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"SMA_10\")\n\n        try:\n            expected  tal.SMA(self.close, 10)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_ssf(self):\n        result  pandas_ta.ssf(self.close, poles2)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"SSF_10_2\")\n\n        result  pandas_ta.ssf(self.close, poles3)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"SSF_10_3\")\n\n    def test_swma(self):\n        result  pandas_ta.swma(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"SWMA_10\")\n\n    def test_supertrend(self):\n        result  pandas_ta.supertrend(self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"SUPERT_7_3.0\")\n\n    def test_t3(self):\n        result  pandas_ta.t3(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"T3_10_0.7\")\n\n        try:\n            expected  tal.T3(self.close, 10)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_tema(self):\n        result  pandas_ta.tema(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"TEMA_10\")\n\n        try:\n            expected  tal.TEMA(self.close, 10)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_trima(self):\n        result  pandas_ta.trima(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"TRIMA_10\")\n\n        try:\n            expected  tal.TRIMA(self.close, 10)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_vidya(self):\n        result  pandas_ta.vidya(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"VIDYA_14\")\n\n    def test_vwap(self):\n        result  pandas_ta.vwap(self.high, self.low, self.close, self.volume)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"VWAP_D\")\n\n    def test_vwma(self):\n        result  pandas_ta.vwma(self.close, self.volume)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"VWMA_10\")\n\n    def test_wcp(self):\n        result  pandas_ta.wcp(self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"WCP\")\n\n        try:\n            expected  tal.WCLPRICE(self.high, self.low, self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_wma(self):\n        result  pandas_ta.wma(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"WMA_10\")\n\n        try:\n            expected  tal.WMA(self.close, 10)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_zlma(self):\n        result  pandas_ta.zlma(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"ZL_EMA_10\")\n\n\n\ntests/test_indicator_performance.py\n\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import TestCase\nfrom pandas import Series\n\n\nclass TestPerformace(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.close  cls.data[\"close\"]\n        cls.islong  (cls.close > pandas_ta.sma(cls.close, length8)).astype(int)\n        cls.pctret  pandas_ta.percent_return(cls.close, cumulativeFalse)\n        cls.logret  pandas_ta.percent_return(cls.close, cumulativeFalse)\n\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.data\n        del cls.close\n        del cls.islong\n        del cls.pctret\n        del cls.logret\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_log_return(self):\n        result  pandas_ta.log_return(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"LOGRET_1\")\n\n    def test_cum_log_return(self):\n        result  pandas_ta.log_return(self.close, cumulativeTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"CUMLOGRET_1\")\n\n    def test_percent_return(self):\n        result  pandas_ta.percent_return(self.close, cumulativeFalse)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"PCTRET_1\")\n\n    def test_cum_percent_return(self):\n        result  pandas_ta.percent_return(self.close, cumulativeTrue)\n        self.assertEqual(result.name, \"CUMPCTRET_1\")\n\n    def test_log_trend_return(self):\n        result  pandas_ta.trend_return(self.close, self.islong, logTrue)\n        self.assertEqual(result.name, \"TRl\")\n\n    def test_cum_log_trend_return(self):\n        result  pandas_ta.trend_return(self.close, self.islong, logTrue)\n        self.assertEqual(result.name, \"TRl\")\n\n    def test_pct_trend_return(self):\n        result  pandas_ta.trend_return(self.close, self.islong, logFalse)\n        self.assertEqual(result.name, \"TRp\")\n\n    def test_cum_pct_trend_return(self):\n        result  pandas_ta.trend_return(self.close, self.islong, logFalse)\n        self.assertEqual(result.name, \"TRp\")\n\n\ntests/test_indicator_statistics.py\n\nfrom .config import error_analysis, sample_data, CORRELATION, CORRELATION_THRESHOLD, VERBOSE\nfrom .context import pandas_ta\n\nfrom unittest import TestCase, skip\nimport pandas.testing as pdt\nfrom pandas import Series\n\nimport talib as tal\n\n\nclass TestStatistics(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.data.columns  cls.data.columns.str.lower()\n        cls.open  cls.data[\"open\"]\n        cls.high  cls.data[\"high\"]\n        cls.low  cls.data[\"low\"]\n        cls.close  cls.data[\"close\"]\n        if \"volume\" in cls.data.columns:\n            cls.volume  cls.data[\"volume\"]\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.open\n        del cls.high\n        del cls.low\n        del cls.close\n        if hasattr(cls, \"volume\"):\n            del cls.volume\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_entropy(self):\n        result  pandas_ta.entropy(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"ENTP_10\")\n\n    def test_kurtosis(self):\n        result  pandas_ta.kurtosis(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"KURT_30\")\n\n    def test_mad(self):\n        result  pandas_ta.mad(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"MAD_30\")\n\n    def test_median(self):\n        result  pandas_ta.median(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"MEDIAN_30\")\n\n    def test_quantile(self):\n        result  pandas_ta.quantile(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"QTL_30_0.5\")\n\n    def test_skew(self):\n        result  pandas_ta.skew(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"SKEW_30\")\n\n    def test_stdev(self):\n        result  pandas_ta.stdev(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"STDEV_30\")\n\n        try:\n            expected  tal.STDDEV(self.close, 30)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_variance(self):\n        result  pandas_ta.variance(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"VAR_30\")\n\n        try:\n            expected  tal.VAR(self.close, 30)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_zscore(self):\n        result  pandas_ta.zscore(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"Z_30\")\n\n\n\ntests/test_indicator_trend.py\n\nfrom .config import error_analysis, sample_data, CORRELATION, CORRELATION_THRESHOLD, VERBOSE\nfrom .context import pandas_ta\n\nfrom unittest import TestCase, skip\nimport pandas.testing as pdt\nfrom pandas import DataFrame, Series\n\nimport talib as tal\n\n\nclass TestTrend(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.data.columns  cls.data.columns.str.lower()\n        cls.open  cls.data[\"open\"]\n        cls.high  cls.data[\"high\"]\n        cls.low  cls.data[\"low\"]\n        cls.close  cls.data[\"close\"]\n        if \"volume\" in cls.data.columns:\n            cls.volume  cls.data[\"volume\"]\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.open\n        del cls.high\n        del cls.low\n        del cls.close\n        if hasattr(cls, \"volume\"):\n            del cls.volume\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_adx(self):\n        result  pandas_ta.adx(self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"ADX_14\")\n\n        try:\n            expected  tal.ADX(self.high, self.low, self.close)\n            pdt.assert_series_equal(result.iloc[:, 0], expected)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result.iloc[:, 0], expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_amat(self):\n        result  pandas_ta.amat(self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"AMAT_EMA_8_21_2\")\n\n    def test_aroon(self):\n        result  pandas_ta.aroon(self.high, self.low)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"AROON_14\")\n\n        try:\n            expected  tal.AROON(self.high, self.low)\n            expecteddf  DataFrame({\"AROOND_14\": expected[0], \"AROONU_14\": expected[1]})\n            pdt.assert_frame_equal(result, expecteddf)\n        except AssertionError as ae:\n            try:\n                aroond_corr  pandas_ta.utils.df_error_analysis(result.iloc[:, 0], expecteddf.iloc[:, 0], colCORRELATION)\n                self.assertGreater(aroond_corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result.iloc[:, 0], CORRELATION, ex)\n\n            try:\n                aroonu_corr  pandas_ta.utils.df_error_analysis(result.iloc[:, 1], expecteddf.iloc[:, 1], colCORRELATION)\n                self.assertGreater(aroonu_corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result.iloc[:, 1], CORRELATION, ex, newlineFalse)\n\n    def test_aroon_osc(self):\n        result  pandas_ta.aroon(self.high, self.low)\n\n        try:\n            expected  tal.AROONOSC(self.high, self.low)\n            pdt.assert_series_equal(result.iloc[:, 2], expected)\n        except AssertionError as ae:\n            try:\n                aroond_corr  pandas_ta.utils.df_error_analysis(result.iloc[:,2], expected,colCORRELATION)\n                self.assertGreater(aroond_corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result.iloc[:, 0], CORRELATION, ex)\n\n    def test_chop(self):\n        result  pandas_ta.chop(self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"CHOP_14_1_100\")\n\n    def test_cksp(self):\n        result  pandas_ta.cksp(self.high, self.low, self.close, tvmodeFalse)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"CKSP_10_3_20\")\n\n    def test_cksp_tv(self):\n        result  pandas_ta.cksp(self.high, self.low, self.close, tvmodeTrue)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"CKSP_10_1_9\")\n\n    def test_decay(self):\n        result  pandas_ta.decay(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"LDECAY_5\")\n\n        result  pandas_ta.decay(self.close, mode\"exp\")\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"EXPDECAY_5\")\n\n    def test_decreasing(self):\n        result  pandas_ta.decreasing(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"DEC_1\")\n\n        result  pandas_ta.decreasing(self.close, length3, strictTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"SDEC_3\")\n\n    def test_dpo(self):\n        result  pandas_ta.dpo(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"DPO_20\")\n\n    def test_increasing(self):\n        result  pandas_ta.increasing(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"INC_1\")\n\n        result  pandas_ta.increasing(self.close, length3, strictTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"SINC_3\")\n\n    def test_long_run(self):\n        result  pandas_ta.long_run(self.close, self.open)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"LR_2\")\n\n    def test_psar(self):\n        result  pandas_ta.psar(self.high, self.low)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"PSAR_0.02_0.2\")\n\n        # Combine Long and Short SAR\"s into one SAR value\n        psar  result[result.columns[:2]].fillna(0)\n        psar  psar[psar.columns[0]] + psar[psar.columns[1]]\n        psar.name  result.name\n\n        try:\n            expected  tal.SAR(self.high, self.low)\n            pdt.assert_series_equal(psar, expected)\n        except AssertionError as ae:\n            try:\n                psar_corr  pandas_ta.utils.df_error_analysis(psar, expected, colCORRELATION)\n                self.assertGreater(psar_corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(psar, CORRELATION, ex)\n\n    def test_qstick(self):\n        result  pandas_ta.qstick(self.open, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"QS_10\")\n\n    def test_short_run(self):\n        result  pandas_ta.short_run(self.close, self.open)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"SR_2\")\n\n    def test_ttm_trend(self):\n        result  pandas_ta.ttm_trend(self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"TTMTREND_6\")\n\n    def test_vortex(self):\n        result  pandas_ta.vortex(self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"VTX_14\")\n\n\n\n",
        "AgentRunResult(output='Este conteúdo está no diretório raiz/tests e inclui os arquivos de teste test_indicator_volatility.py, test_indicator_volume.py e test_strategy.py. Ele cobre testes unitários para indicadores técnicos de análise de volatilidade e volume (como ATR, BBANDS, OBV, MFI), com validações contra a biblioteca TA-Lib, além de testes para execução de estratégias completas com indicadores agrupados por categoria. As tecnologias utilizadas incluem Python, pandas, unittest e pandas-ta.')\ntests/test_indicator_volatility.py\n\nfrom .config import error_analysis, sample_data, CORRELATION, CORRELATION_THRESHOLD, VERBOSE\nfrom .context import pandas_ta\n\nfrom unittest import TestCase, skip\nimport pandas.testing as pdt\nfrom pandas import DataFrame, Series\n\nimport talib as tal\n\n\nclass TestVolatility(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.data.columns  cls.data.columns.str.lower()\n        cls.open  cls.data[\"open\"]\n        cls.high  cls.data[\"high\"]\n        cls.low  cls.data[\"low\"]\n        cls.close  cls.data[\"close\"]\n        if \"volume\" in cls.data.columns:\n            cls.volume  cls.data[\"volume\"]\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.open\n        del cls.high\n        del cls.low\n        del cls.close\n        if hasattr(cls, \"volume\"):\n            del cls.volume\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_aberration(self):\n        result  pandas_ta.aberration(self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"ABER_5_15\")\n\n    def test_accbands(self):\n        result  pandas_ta.accbands(self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"ACCBANDS_20\")\n\n    def test_atr(self):\n        result  pandas_ta.atr(self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"ATRr_14\")\n\n        try:\n            expected  tal.ATR(self.high, self.low, self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_bbands(self):\n        result  pandas_ta.bbands(self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"BBANDS_5_2.0\")\n\n        try:\n            expected  tal.BBANDS(self.close)\n            expecteddf  DataFrame({\"BBL_5_2.0\": expected[0], \"BBM_5_2.0\": expected[1], \"BBU_5_2.0\": expected[2]})\n            pdt.assert_frame_equal(result, expecteddf)\n        except AssertionError as ae:\n            try:\n                bbl_corr  pandas_ta.utils.df_error_analysis(result.iloc[:, 0], expecteddf.iloc[:,0], colCORRELATION)\n                self.assertGreater(bbl_corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result.iloc[:, 0], CORRELATION, ex)\n\n            try:\n                bbm_corr  pandas_ta.utils.df_error_analysis(result.iloc[:, 1], expecteddf.iloc[:,1], colCORRELATION)\n                self.assertGreater(bbm_corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result.iloc[:, 1], CORRELATION, ex, newlineFalse)\n\n            try:\n                bbu_corr  pandas_ta.utils.df_error_analysis(result.iloc[:, 2], expecteddf.iloc[:,2], colCORRELATION)\n                self.assertGreater(bbu_corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result.iloc[:, 2], CORRELATION, ex, newlineFalse)\n\n    def test_donchian(self):\n        result  pandas_ta.donchian(self.high, self.low)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"DC_20_20\")\n\n        result  pandas_ta.donchian(self.high, self.low, lower_length20, upper_length5)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"DC_20_5\")\n\n    def test_kc(self):\n        result  pandas_ta.kc(self.high, self.low, self.close)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"KCe_20_2\")\n\n        result  pandas_ta.kc(self.high, self.low, self.close, mamode\"sma\")\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"KCs_20_2\")\n\n    def test_massi(self):\n        result  pandas_ta.massi(self.high, self.low)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"MASSI_9_25\")\n\n    def test_natr(self):\n        result  pandas_ta.natr(self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"NATR_14\")\n\n        try:\n            expected  tal.NATR(self.high, self.low, self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_pdist(self):\n        result  pandas_ta.pdist(self.open, self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"PDIST\")\n\n    def test_rvi(self):\n        result  pandas_ta.rvi(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"RVI_14\")\n\n        result  pandas_ta.rvi(self.close, self.high, self.low, refinedTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"RVIr_14\")\n\n        result  pandas_ta.rvi(self.close, self.high, self.low, thirdsTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"RVIt_14\")\n\n    def test_thermo(self):\n        result  pandas_ta.thermo(self.high, self.low)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"THERMO_20_2_0.5\")\n\n    def test_true_range(self):\n        result  pandas_ta.true_range(self.high, self.low, self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"TRUERANGE_1\")\n\n        try:\n            expected  tal.TRANGE(self.high, self.low, self.close)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_ui(self):\n        result  pandas_ta.ui(self.close)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"UI_14\")\n\n        result  pandas_ta.ui(self.close, evergetTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"UIe_14\")\n\n\n\ntests/test_indicator_volume.py\n\nfrom .config import error_analysis, sample_data, CORRELATION, CORRELATION_THRESHOLD, VERBOSE\nfrom .context import pandas_ta\n\nfrom unittest import TestCase, skip\nimport pandas.testing as pdt\nfrom pandas import DataFrame, Series\n\nimport talib as tal\n\n\nclass TestVolume(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.data.columns  cls.data.columns.str.lower()\n        cls.open  cls.data[\"open\"]\n        cls.high  cls.data[\"high\"]\n        cls.low  cls.data[\"low\"]\n        cls.close  cls.data[\"close\"]\n        if \"volume\" in cls.data.columns:\n            cls.volume_  cls.data[\"volume\"]\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.open\n        del cls.high\n        del cls.low\n        del cls.close\n        if hasattr(cls, \"volume\"):\n            del cls.volume_\n        del cls.data\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_ad(self):\n        result  pandas_ta.ad(self.high, self.low, self.close, self.volume_)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"AD\")\n\n        try:\n            expected  tal.AD(self.high, self.low, self.close, self.volume_)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_ad_open(self):\n        result  pandas_ta.ad(self.high, self.low, self.close, self.volume_, self.open)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"ADo\")\n\n    def test_adosc(self):\n        result  pandas_ta.adosc(self.high, self.low, self.close, self.volume_)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"ADOSC_3_10\")\n\n        try:\n            expected  tal.ADOSC(self.high, self.low, self.close, self.volume_)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_aobv(self):\n        result  pandas_ta.aobv(self.close, self.volume_)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"AOBVe_4_12_2_2_2\")\n\n    def test_cmf(self):\n        result  pandas_ta.cmf(self.high, self.low, self.close, self.volume_)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"CMF_20\")\n\n    def test_efi(self):\n        result  pandas_ta.efi(self.close, self.volume_)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"EFI_13\")\n\n    def test_eom(self):\n        result  pandas_ta.eom(self.high, self.low, self.close, self.volume_)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"EOM_14_100000000\")\n\n    def test_mfi(self):\n        result  pandas_ta.mfi(self.high, self.low, self.close, self.volume_)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"MFI_14\")\n\n        try:\n            expected  tal.MFI(self.high, self.low, self.close, self.volume_)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_nvi(self):\n        result  pandas_ta.nvi(self.close, self.volume_)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"NVI_1\")\n\n    def test_obv(self):\n        result  pandas_ta.obv(self.close, self.volume_)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"OBV\")\n\n        try:\n            expected  tal.OBV(self.close, self.volume_)\n            pdt.assert_series_equal(result, expected, check_namesFalse)\n        except AssertionError as ae:\n            try:\n                corr  pandas_ta.utils.df_error_analysis(result, expected, colCORRELATION)\n                self.assertGreater(corr, CORRELATION_THRESHOLD)\n            except Exception as ex:\n                error_analysis(result, CORRELATION, ex)\n\n    def test_pvi(self):\n        result  pandas_ta.pvi(self.close, self.volume_)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"PVI_1\")\n\n    def test_pvol(self):\n        result  pandas_ta.pvol(self.close, self.volume_)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"PVOL\")\n\n    def test_pvr(self):\n        result  pandas_ta.pvr(self.close, self.volume_)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"PVR\")\n        # sample indicator values from SPY\n        self.assertEqual(result[0], 1)\n        self.assertEqual(result[1], 3)\n        self.assertEqual(result[4], 2)\n        self.assertEqual(result[6], 4)\n\n    def test_pvt(self):\n        result  pandas_ta.pvt(self.close, self.volume_)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"PVT\")\n\n    def test_vp(self):\n        result  pandas_ta.vp(self.close, self.volume_)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"VP_10\")\n\n\n\ntests/test_strategy.py\n\n# Must run seperately from the rest of the tests\n# in order to successfully run\nfrom multiprocessing import cpu_count\nfrom time import perf_counter\n\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import skip, skipUnless, TestCase\nfrom pandas import DataFrame\n\n# Strategy Testing Parameters\ncores  cpu_count()\ncumulative  False\nspeed_table  False\nstrategy_timed  False\ntimed  True\nverbose  False\n\n\nclass TestStrategyMethods(TestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.data.ta.cores  cores\n        cls.speed_test  DataFrame()\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.speed_test  cls.speed_test.T\n        cls.speed_test.index.name  \"Test\"\n        cls.speed_test.columns  [\"Columns\", \"Seconds\"]\n        if cumulative:\n            cls.speed_test[\"Cum. Seconds\"]  cls.speed_test[\"Seconds\"].cumsum()\n        if speed_table:\n            cls.speed_test.to_csv(\"tests/speed_test.csv\")\n        if timed:\n            print(f\"[i] Cores: {cls.data.ta.cores}\")\n            print(f\"[i] Total Datapoints: {cls.data.shape[0]}\")\n            print(cls.speed_test)\n        del cls.data\n\n    def setUp(self):\n        self.added_cols  0\n        self.category  \"\"\n        self.init_cols  len(self.data.columns)\n        self.time_diff  0\n        self.result  None\n        if verbose: print()\n        if timed: self.stime  perf_counter()\n\n    def tearDown(self):\n        if timed:\n            self.time_diff  perf_counter() - self.stime\n        self.added_cols  len(self.data.columns) - self.init_cols\n        self.assertGreaterEqual(self.added_cols, 1)\n\n        self.result  self.data[self.data.columns[-self.added_cols:]]\n        self.assertIsInstance(self.result, DataFrame)\n        self.data.drop(columnsself.result.columns, axis1, inplaceTrue)\n\n        self.speed_test[self.category]  [self.added_cols, self.time_diff]\n\n    # @skip\n    def test_all(self):\n        self.category  \"All\"\n        self.data.ta.strategy(verboseverbose, timedstrategy_timed)\n\n    def test_all_ordered(self):\n        self.category  \"All\"\n        self.data.ta.strategy(orderedTrue, verboseverbose, timedstrategy_timed)\n        self.category  \"All Ordered\" # Rename for Speed Table\n\n    @skipUnless(verbose, \"verbose mode only\")\n    def test_all_strategy(self):\n        self.data.ta.strategy(pandas_ta.AllStrategy, verboseverbose, timedstrategy_timed)\n\n    @skipUnless(verbose, \"verbose mode only\")\n    def test_all_name_strategy(self):\n        self.category  \"All\"\n        self.data.ta.strategy(self.category, verboseverbose, timedstrategy_timed)\n\n    # @skipUnless(verbose, \"verbose mode only\")\n    def test_all_multiparams_strategy(self):\n        self.category  \"All\"\n        self.data.ta.strategy(self.category, length10, verboseverbose, timedstrategy_timed)\n        self.data.ta.strategy(self.category, length50, verboseverbose, timedstrategy_timed)\n        self.data.ta.strategy(self.category, fast5, slow10, verboseverbose, timedstrategy_timed)\n        self.category  \"All Multiruns with diff Args\" # Rename for Speed Table\n\n    # @skip\n    def test_candles_category(self):\n        self.category  \"Candles\"\n        self.data.ta.strategy(self.category, verboseverbose, timedstrategy_timed)\n\n    # @skip\n    def test_common(self):\n        self.category  \"Common\"\n        self.data.ta.strategy(pandas_ta.CommonStrategy, verboseverbose, timedstrategy_timed)\n\n    def test_cycles_category(self):\n        self.category  \"Cycles\"\n        self.data.ta.strategy(self.category, verboseverbose, timedstrategy_timed)\n\n    # @skip\n    def test_custom_a(self):\n        self.category  \"Custom A\"\n\n        momo_bands_sma_ta  [\n            {\"kind\": \"rsi\"},  # 1\n            {\"kind\": \"macd\"},  # 3\n            {\"kind\": \"sma\", \"length\": 50},  # 1\n            {\"kind\": \"sma\", \"length\": 200 },  # 1\n            {\"kind\": \"bbands\", \"length\": 20},  # 3\n            {\"kind\": \"log_return\", \"cumulative\": True},  # 1\n            {\"kind\": \"ema\", \"close\": \"CUMLOGRET_1\", \"length\": 5, \"suffix\": \"CLR\"}\n        ]\n\n        custom  pandas_ta.Strategy(\n            \"Commons with Cumulative Log Return EMA Chain\",  # name\n            momo_bands_sma_ta,  # ta\n            \"Common indicators with specific lengths and a chained indicator\",  # description\n        )\n        self.data.ta.strategy(custom, verboseverbose, timedstrategy_timed)\n\n    # @skip\n    def test_custom_args_tuple(self):\n        self.category  \"Custom B\"\n\n        custom_args_ta  [\n            {\"kind\": \"ema\", \"params\": (5,)},\n            {\"kind\": \"fisher\", \"params\": (13, 7)}\n        ]\n\n        custom  pandas_ta.Strategy(\n            \"Custom Args Tuple\",\n            custom_args_ta,\n            \"Allow for easy filling in indicator arguments by argument placement.\"\n        )\n        self.data.ta.strategy(custom, verboseverbose, timedstrategy_timed)\n\n    def test_custom_col_names_tuple(self):\n        self.category  \"Custom C\"\n\n        custom_args_ta  [{\"kind\": \"bbands\", \"col_names\": (\"LB\", \"MB\", \"UB\", \"BW\")}]\n\n        custom  pandas_ta.Strategy(\n            \"Custom Col Numbers Tuple\",\n            custom_args_ta,\n            \"Allow for easy renaming of resultant columns\",\n        )\n        self.data.ta.strategy(custom, verboseverbose, timedstrategy_timed)\n\n    # @skip\n    def test_custom_col_numbers_tuple(self):\n        self.category  \"Custom D\"\n\n        custom_args_ta  [{\"kind\": \"macd\", \"col_numbers\": (1,)}]\n\n        custom  pandas_ta.Strategy(\n            \"Custom Col Numbers Tuple\",\n            custom_args_ta,\n            \"Allow for easy selection of resultant columns\",\n        )\n        self.data.ta.strategy(custom, verboseverbose, timedstrategy_timed)\n\n    # @skip\n    def test_custom_a(self):\n        self.category  \"Custom E\"\n\n        amat_logret_ta  [\n            {\"kind\": \"amat\", \"fast\": 20, \"slow\": 50 },  # 2\n            {\"kind\": \"log_return\", \"cumulative\": True},  # 1\n            {\"kind\": \"ema\", \"close\": \"CUMLOGRET_1\", \"length\": 5} # 1\n        ]\n\n        custom  pandas_ta.Strategy(\n            \"AMAT Log Returns\",  # name\n            amat_logret_ta,  # ta\n            \"AMAT Log Returns\",  # description\n        )\n        self.data.ta.strategy(custom, verboseverbose, timedstrategy_timed, orderedTrue)\n        self.data.ta.trend_return(trendself.data[\"AMATe_LR_2\"], cumulativeTrue, appendTrue)\n        self.assertEqual(len(self.data.columns), 15)\n\n    # @skip\n    def test_momentum_category(self):\n        self.category  \"Momentum\"\n        self.data.ta.strategy(self.category, verboseverbose, timedstrategy_timed)\n\n    # @skip\n    def test_overlap_category(self):\n        self.category  \"Overlap\"\n        self.data.ta.strategy(self.category, verboseverbose, timedstrategy_timed)\n\n    # @skip\n    def test_performance_category(self):\n        self.category  \"Performance\"\n        self.data.ta.strategy(self.category, verboseverbose, timedstrategy_timed)\n\n    # @skip\n    def test_statistics_category(self):\n        self.category  \"Statistics\"\n        self.data.ta.strategy(self.category, verboseverbose, timedstrategy_timed)\n\n    # @skip\n    def test_trend_category(self):\n        self.category  \"Trend\"\n        self.data.ta.strategy(self.category, verboseverbose, timedstrategy_timed)\n\n    # @skip\n    def test_volatility_category(self):\n        self.category  \"Volatility\"\n        self.data.ta.strategy(self.category, verboseverbose, timedstrategy_timed)\n\n    # @skip\n    def test_volume_category(self):\n        self.category  \"Volume\"\n        self.data.ta.strategy(self.category, verboseverbose, timedstrategy_timed)\n\n    # @skipUnless(verbose, \"verbose mode only\")\n    def test_all_no_multiprocessing(self):\n        self.category  \"All with No Multiprocessing\"\n\n        cores  self.data.ta.cores\n        self.data.ta.cores  0\n        self.data.ta.strategy(verboseverbose, timedstrategy_timed)\n        self.data.ta.cores  cores\n\n    # @skipUnless(verbose, \"verbose mode only\")\n    def test_custom_no_multiprocessing(self):\n        self.category  \"Custom A with No Multiprocessing\"\n\n        cores  self.data.ta.cores\n        self.data.ta.cores  0\n\n        momo_bands_sma_ta  [\n            {\"kind\": \"rsi\"},  # 1\n            {\"kind\": \"macd\"},  # 3\n            {\"kind\": \"sma\", \"length\": 50},  # 1\n            {\"kind\": \"sma\", \"length\": 200 },  # 1\n            {\"kind\": \"bbands\", \"length\": 20},  # 3\n            {\"kind\": \"log_return\", \"cumulative\": True},  # 1\n            {\"kind\": \"ema\", \"close\": \"CUMLOGRET_1\", \"length\": 5, \"suffix\": \"CLR\"}\n        ]\n\n        custom  pandas_ta.Strategy(\n            \"Commons with Cumulative Log Return EMA Chain\",  # name\n            momo_bands_sma_ta,  # ta\n            \"Common indicators with specific lengths and a chained indicator\",  # description\n        )\n        self.data.ta.strategy(custom, verboseverbose, timedstrategy_timed)\n        self.data.ta.cores  cores\n\n\n\n",
        "AgentRunResult(output='Esse conteúdo pertence ao diretório `tests/` e contém os arquivos `test_utils.py` e `test_utils_metrics.py`. Eles reúnem testes unitários para funções da biblioteca `pandas_ta`. O arquivo `test_utils.py` abrange funções utilitárias diversas como prefix/suffix de indicadores, cálculos de Fibonacci, médias (geométrica, logarítmica), regressão linear, datas, combinações, cruzamentos de séries, etc. O arquivo `test_utils_metrics.py` foca em métricas financeiras como CAGR, Sharpe Ratio, Sortino Ratio, Calmar Ratio, drawdowns e volatilidade. As tecnologias predominantes são Python, unittest, pandas, numpy e a própria pandas_ta.')\ntests/test_utils.py\n\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import skip, TestCase\nfrom unittest.mock import patch\n\nimport numpy as np\nimport numpy.testing as npt\nfrom pandas import DataFrame, Series\nfrom pandas.api.types import is_datetime64_ns_dtype, is_datetime64tz_dtype\n\n\ndata  {\n    \"zero\": [0, 0],\n    \"a\": [0, 1],\n    \"b\": [1, 0],\n    \"c\": [1, 1],\n    \"crossed\": [0, 1],\n}\n\n\nclass TestUtilities(TestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.data\n\n    def setUp(self):\n        self.crosseddf  DataFrame(data)\n        self.utils  pandas_ta.utils\n\n    def tearDown(self):\n        del self.crosseddf\n        del self.utils\n\n    def test__add_prefix_suffix(self):\n        result  self.data.ta.hl2(appendFalse, prefix\"pre\")\n        self.assertEqual(result.name, \"pre_HL2\")\n\n        result  self.data.ta.hl2(appendFalse, suffix\"suf\")\n        self.assertEqual(result.name, \"HL2_suf\")\n\n        result  self.data.ta.hl2(appendFalse, prefix\"pre\", suffix\"suf\")\n        self.assertEqual(result.name, \"pre_HL2_suf\")\n\n        result  self.data.ta.hl2(appendFalse, prefix1, suffix2)\n        self.assertEqual(result.name, \"1_HL2_2\")\n\n        result  self.data.ta.macd(appendFalse, prefix\"pre\", suffix\"suf\")\n        for col in result.columns:\n            self.assertTrue(col.startswith(\"pre_\") and col.endswith(\"_suf\"))\n\n    @skip\n    def test__above_below(self):\n        result  self.utils._above_below(self.crosseddf[\"a\"], self.crosseddf[\"zero\"], aboveTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"a_A_zero\")\n        npt.assert_array_equal(result, self.crosseddf[\"c\"])\n\n        result  self.utils._above_below(self.crosseddf[\"a\"], self.crosseddf[\"zero\"], aboveFalse)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"a_B_zero\")\n        npt.assert_array_equal(result, self.crosseddf[\"b\"])\n\n        result  self.utils._above_below(self.crosseddf[\"c\"], self.crosseddf[\"zero\"], aboveTrue)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"c_A_zero\")\n        npt.assert_array_equal(result, self.crosseddf[\"c\"])\n\n        result  self.utils._above_below(self.crosseddf[\"c\"], self.crosseddf[\"zero\"], aboveFalse)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"c_B_zero\")\n        npt.assert_array_equal(result, self.crosseddf[\"zero\"])\n\n    def test_above(self):\n        result  self.utils.above(self.crosseddf[\"a\"], self.crosseddf[\"zero\"])\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"a_A_zero\")\n        npt.assert_array_equal(result, self.crosseddf[\"c\"])\n\n        result  self.utils.above(self.crosseddf[\"zero\"], self.crosseddf[\"a\"])\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"zero_A_a\")\n        npt.assert_array_equal(result, self.crosseddf[\"b\"])\n\n    def test_above_value(self):\n        result  self.utils.above_value(self.crosseddf[\"a\"], 0)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"a_A_0\")\n        npt.assert_array_equal(result, self.crosseddf[\"c\"])\n\n        result  self.utils.above_value(self.crosseddf[\"a\"], self.crosseddf[\"zero\"])\n        self.assertIsNone(result)\n\n    def test_below(self):\n        result  self.utils.below(self.crosseddf[\"zero\"], self.crosseddf[\"a\"])\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"zero_B_a\")\n        npt.assert_array_equal(result, self.crosseddf[\"c\"])\n\n        result  self.utils.below(self.crosseddf[\"zero\"], self.crosseddf[\"a\"])\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"zero_B_a\")\n        npt.assert_array_equal(result, self.crosseddf[\"c\"])\n\n    def test_below_value(self):\n        result  self.utils.below_value(self.crosseddf[\"a\"], 0)\n        self.assertIsInstance(result, Series)\n        self.assertEqual(result.name, \"a_B_0\")\n        npt.assert_array_equal(result, self.crosseddf[\"b\"])\n\n        result  self.utils.below_value(self.crosseddf[\"a\"], self.crosseddf[\"zero\"])\n        self.assertIsNone(result)\n\n    def test_combination(self):\n        self.assertIsNotNone(self.utils.combination())\n\n        self.assertEqual(self.utils.combination(), 1)\n        self.assertEqual(self.utils.combination(r-1), 1)\n\n        self.assertEqual(self.utils.combination(n10, r4, repetitionFalse), 210)\n        self.assertEqual(self.utils.combination(n10, r4, repetitionTrue), 715)\n\n    def test_cross_above(self):\n        result  self.utils.cross(self.crosseddf[\"a\"], self.crosseddf[\"b\"])\n        self.assertIsInstance(result, Series)\n        npt.assert_array_equal(result, self.crosseddf[\"crossed\"])\n\n        result  self.utils.cross(self.crosseddf[\"a\"], self.crosseddf[\"b\"], aboveTrue)\n        self.assertIsInstance(result, Series)\n        npt.assert_array_equal(result, self.crosseddf[\"crossed\"])\n\n    def test_cross_below(self):\n        result  self.utils.cross(self.crosseddf[\"b\"], self.crosseddf[\"a\"], aboveFalse)\n        self.assertIsInstance(result, Series)\n        npt.assert_array_equal(result, self.crosseddf[\"crossed\"])\n\n    def test_df_dates(self):\n        result  self.utils.df_dates(self.data)\n        self.assertEqual(None, result)\n\n        result  self.utils.df_dates(self.data, \"1999-11-01\")\n        self.assertEqual(1, result.shape[0])\n\n        result  self.utils.df_dates(self.data, [\"1999-11-01\", \"2020-08-15\", \"2020-08-24\", \"2020-08-25\", \"2020-08-26\", \"2020-08-27\"])\n        self.assertEqual(5, result.shape[0])\n\n    def test_df_month_to_date(self):\n        result  self.utils.df_month_to_date(self.data)\n\n    def test_df_quarter_to_date(self):\n        result  self.utils.df_quarter_to_date(self.data)\n\n    def test_df_year_to_date(self):\n        result  self.utils.df_year_to_date(self.data)\n\n    def test_fibonacci(self):\n        self.assertIs(type(self.utils.fibonacci(zeroTrue, weightedFalse)), np.ndarray)\n\n        npt.assert_array_equal(self.utils.fibonacci(zeroTrue), np.array([0, 1, 1]))\n        npt.assert_array_equal(self.utils.fibonacci(zeroFalse), np.array([1, 1]))\n\n        npt.assert_array_equal(self.utils.fibonacci(n0, zeroTrue, weightedFalse), np.array([0]))\n        npt.assert_array_equal(self.utils.fibonacci(n0, zeroFalse, weightedFalse), np.array([1]))\n\n        npt.assert_array_equal(self.utils.fibonacci(n5, zeroTrue, weightedFalse), np.array([0, 1, 1, 2, 3, 5]))\n        npt.assert_array_equal(self.utils.fibonacci(n5, zeroFalse, weightedFalse), np.array([1, 1, 2, 3, 5]))\n\n    def test_fibonacci_weighted(self):\n        self.assertIs(type(self.utils.fibonacci(zeroTrue, weightedTrue)), np.ndarray)\n        npt.assert_array_equal(self.utils.fibonacci(n0, zeroTrue, weightedTrue), np.array([0]))\n        npt.assert_array_equal(self.utils.fibonacci(n0, zeroFalse, weightedTrue), np.array([1]))\n\n        npt.assert_allclose(self.utils.fibonacci(n5, zeroTrue, weightedTrue), np.array([0, 1 / 12, 1 / 12, 1 / 6, 1 / 4, 5 / 12]))\n        npt.assert_allclose(self.utils.fibonacci(n5, zeroFalse, weightedTrue), np.array([1 / 12, 1 / 12, 1 / 6, 1 / 4, 5 / 12]))\n\n\n    def test_geometric_mean(self):\n        returns  pandas_ta.percent_return(self.data.close)\n        result  self.utils.geometric_mean(returns)\n        self.assertIsInstance(result, float)\n\n        result  self.utils.geometric_mean(Series([12, 14, 11, 8]))\n        self.assertIsInstance(result, float)\n\n        result  self.utils.geometric_mean(Series([100, 50, 0, 25, 0, 60]))\n        self.assertIsInstance(result, float)\n\n        series  Series([0, 1, 2, 3])\n        result  self.utils.geometric_mean(series)\n        self.assertIsInstance(result, float)\n\n        result  self.utils.geometric_mean(-series)\n        self.assertIsInstance(result, int)\n        self.assertAlmostEqual(result, 0)\n\n    def test_get_time(self):\n        result  self.utils.get_time(to_stringTrue)\n        self.assertIsInstance(result, str)\n\n        result  self.utils.get_time(\"NZSX\", to_stringTrue)\n        self.assertTrue(\"NZSX\" in result)\n        self.assertIsInstance(result, str)\n\n        result  self.utils.get_time(\"SSE\", to_stringTrue)\n        self.assertIsInstance(result, str)\n        self.assertTrue(\"SSE\" in result)\n\n    def test_linear_regression(self):\n        x  Series([1, 2, 3, 4, 5])\n        y  Series([1.8, 2.1, 2.7, 3.2, 4])\n\n        result  self.utils.linear_regression(x, y)\n        self.assertIsInstance(result, dict)\n        self.assertIsInstance(result[\"a\"], float)\n        self.assertIsInstance(result[\"b\"], float)\n        self.assertIsInstance(result[\"r\"], float)\n        self.assertIsInstance(result[\"t\"], float)\n        self.assertIsInstance(result[\"line\"], Series)\n\n    def test_log_geometric_mean(self):\n        returns  pandas_ta.percent_return(self.data.close)\n        result  self.utils.log_geometric_mean(returns)\n        self.assertIsInstance(result, float)\n\n        result  self.utils.log_geometric_mean(Series([12, 14, 11, 8]))\n        self.assertIsInstance(result, float)\n\n        result  self.utils.log_geometric_mean(Series([100, 50, 0, 25, 0, 60]))\n        self.assertIsInstance(result, float)\n\n        series  Series([0, 1, 2, 3])\n        result  self.utils.log_geometric_mean(series)\n        self.assertIsInstance(result, float)\n\n        result  self.utils.log_geometric_mean(-series)\n        self.assertIsInstance(result, int)\n        self.assertAlmostEqual(result, 0)\n\n    def test_pascals_triangle(self):\n        self.assertIsNone(self.utils.pascals_triangle(inverseTrue), None)\n\n        array_1  np.array([1])\n        npt.assert_array_equal(self.utils.pascals_triangle(), array_1)\n        npt.assert_array_equal(self.utils.pascals_triangle(weightedTrue), array_1)\n        npt.assert_array_equal(self.utils.pascals_triangle(weightedTrue, inverseTrue), np.array([0]))\n\n        array_5  self.utils.pascals_triangle(n5)  # or np.array([1, 5, 10, 10, 5, 1])\n        array_5w  array_5 / np.sum(array_5)\n        array_5iw  1 - array_5w\n        npt.assert_array_equal(self.utils.pascals_triangle(n-5), array_5)\n        npt.assert_array_equal(self.utils.pascals_triangle(n-5, weightedTrue), array_5w)\n        npt.assert_array_equal(self.utils.pascals_triangle(n-5, weightedTrue, inverseTrue), array_5iw)\n\n        npt.assert_array_equal(self.utils.pascals_triangle(n5), array_5)\n        npt.assert_array_equal(self.utils.pascals_triangle(n5, weightedTrue), array_5w)\n        npt.assert_array_equal(self.utils.pascals_triangle(n5, weightedTrue, inverseTrue), array_5iw)\n\n    def test_symmetric_triangle(self):\n        npt.assert_array_equal(self.utils.symmetric_triangle(), np.array([1,1]))\n        npt.assert_array_equal(self.utils.symmetric_triangle(weightedTrue), np.array([0.5, 0.5]))\n\n        array_4  self.utils.symmetric_triangle(n4)  # or np.array([1, 2, 2, 1])\n        array_4w  array_4 / np.sum(array_4)\n        npt.assert_array_equal(self.utils.symmetric_triangle(n4), array_4)\n        npt.assert_array_equal(self.utils.symmetric_triangle(n4, weightedTrue), array_4w)\n\n        array_5  self.utils.symmetric_triangle(n5)  # or np.array([1, 2, 3, 2, 1])\n        array_5w  array_5 / np.sum(array_5)\n        npt.assert_array_equal(self.utils.symmetric_triangle(n5), array_5)\n        npt.assert_array_equal(self.utils.symmetric_triangle(n5, weightedTrue), array_5w)\n\n    def test_zero(self):\n        self.assertEqual(self.utils.zero(-0.0000000000000001), 0)\n        self.assertEqual(self.utils.zero(0), 0)\n        self.assertEqual(self.utils.zero(0.0), 0)\n        self.assertEqual(self.utils.zero(0.0000000000000001), 0)\n\n        self.assertNotEqual(self.utils.zero(-0.000000000000001), 0)\n        self.assertNotEqual(self.utils.zero(0.000000000000001), 0)\n        self.assertNotEqual(self.utils.zero(1), 0)\n\n    def test_get_drift(self):\n        for s in [0, None, \"\", [], {}]:\n            self.assertIsInstance(self.utils.get_drift(s), int)\n\n        self.assertEqual(self.utils.get_drift(0), 1)\n        self.assertEqual(self.utils.get_drift(1.1), 1)\n        self.assertEqual(self.utils.get_drift(-1.1), 1)\n\n    def test_get_offset(self):\n        for s in [0, None, \"\", [], {}]:\n            self.assertIsInstance(self.utils.get_offset(s), int)\n\n        self.assertEqual(self.utils.get_offset(0), 0)\n        self.assertEqual(self.utils.get_offset(-1.1), 0)\n        self.assertEqual(self.utils.get_offset(1), 1)\n\n    def test_to_utc(self):\n        result  self.utils.to_utc(self.data.copy())\n        self.assertTrue(is_datetime64_ns_dtype(result.index))\n        self.assertTrue(is_datetime64tz_dtype(result.index))\n\n    def test_total_time(self):\n        result  self.utils.total_time(self.data)\n        self.assertEqual(30.182539682539684, result)\n\n        result  self.utils.total_time(self.data, \"months\")\n        self.assertEqual(250.05753361606995, result)\n\n        result  self.utils.total_time(self.data, \"weeks\")\n        self.assertEqual(1086.5714285714287, result)\n\n        result  self.utils.total_time(self.data, \"days\")\n        self.assertEqual(7606, result)\n\n        result  self.utils.total_time(self.data, \"hours\")\n        self.assertEqual(182544, result)\n\n        result  self.utils.total_time(self.data, \"minutes\")\n        self.assertEqual(10952640.0, result)\n\n        result  self.utils.total_time(self.data, \"seconds\")\n        self.assertEqual(657158400.0, result)\n\n    def test_version(self):\n        result  pandas_ta.version\n        self.assertIsInstance(result, str)\n        print(f\"\\nPandas TA v{result}\")\n\n\ntests/test_utils_metrics.py\n\nfrom .config import sample_data\nfrom .context import pandas_ta\n\nfrom unittest import skip, TestCase\n\nfrom pandas import DataFrame\n\n\n\nclass TestUtilityMetrics(TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.data  sample_data\n        cls.close  cls.data[\"close\"]\n        cls.pctret  pandas_ta.percent_return(cls.close, cumulativeFalse)\n        cls.logret  pandas_ta.percent_return(cls.close, cumulativeFalse)\n\n    @classmethod\n    def tearDownClass(cls):\n        del cls.data\n        del cls.pctret\n        del cls.logret\n\n    def setUp(self): pass\n    def tearDown(self): pass\n\n\n    def test_cagr(self):\n        result  pandas_ta.utils.cagr(self.data.close)\n        self.assertIsInstance(result, float)\n        self.assertGreater(result, 0)\n\n    def test_calmar_ratio(self):\n        result  pandas_ta.calmar_ratio(self.close)\n        self.assertIsInstance(result, float)\n        self.assertGreaterEqual(result, 0)\n\n        result  pandas_ta.calmar_ratio(self.close, years0)\n        self.assertIsNone(result)\n\n        result  pandas_ta.calmar_ratio(self.close, years-2)\n        self.assertIsNone(result)\n\n    def test_downside_deviation(self):\n        result  pandas_ta.downside_deviation(self.pctret)\n        self.assertIsInstance(result, float)\n        self.assertGreaterEqual(result, 0)\n\n        result  pandas_ta.downside_deviation(self.logret)\n        self.assertIsInstance(result, float)\n        self.assertGreaterEqual(result, 0)\n\n    def test_drawdown(self):\n        result  pandas_ta.drawdown(self.pctret)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"DD\")\n\n        result  pandas_ta.drawdown(self.logret)\n        self.assertIsInstance(result, DataFrame)\n        self.assertEqual(result.name, \"DD\")\n\n    def test_jensens_alpha(self):\n        bench_return  self.pctret.sample(nself.close.shape[0], random_state1)\n        result  pandas_ta.jensens_alpha(self.close, bench_return)\n        self.assertIsInstance(result, float)\n        self.assertGreaterEqual(result, 0)\n\n    def test_log_max_drawdown(self):\n        result  pandas_ta.log_max_drawdown(self.close)\n        self.assertIsInstance(result, float)\n        self.assertGreaterEqual(result, 0)\n\n    def test_max_drawdown(self):\n        result  pandas_ta.max_drawdown(self.close)\n        self.assertIsInstance(result, float)\n        self.assertGreaterEqual(result, 0)\n\n        result  pandas_ta.max_drawdown(self.close, method\"percent\")\n        self.assertIsInstance(result, float)\n        self.assertGreaterEqual(result, 0)\n\n        result  pandas_ta.max_drawdown(self.close, method\"log\")\n        self.assertIsInstance(result, float)\n        self.assertGreaterEqual(result, 0)\n\n        result  pandas_ta.max_drawdown(self.close, allTrue)\n        self.assertIsInstance(result, dict)\n        self.assertIsInstance(result[\"dollar\"], float)\n        self.assertIsInstance(result[\"percent\"], float)\n        self.assertIsInstance(result[\"log\"], float)\n\n    def test_optimal_leverage(self):\n        result  pandas_ta.optimal_leverage(self.close)\n        self.assertIsInstance(result, int)\n        result  pandas_ta.optimal_leverage(self.close, logTrue)\n        self.assertIsInstance(result, int)\n\n    def test_pure_profit_score(self):\n        result  pandas_ta.pure_profit_score(self.close)\n        self.assertIsInstance(result, float)\n        self.assertGreaterEqual(result, 0)\n\n    def test_sharpe_ratio(self):\n        result  pandas_ta.sharpe_ratio(self.close)\n        self.assertIsInstance(result, float)\n        self.assertGreaterEqual(result, 0)\n\n    def test_sortino_ratio(self):\n        result  pandas_ta.sortino_ratio(self.close)\n        self.assertIsInstance(result, float)\n        self.assertGreaterEqual(result, 0)\n\n    def test_volatility(self):\n        returns_  pandas_ta.percent_return(self.close)\n        result  pandas_ta.utils.volatility(returns_, returnsTrue)\n        self.assertIsInstance(result, float)\n        self.assertGreaterEqual(result, 0)\n\n        for tf in [\"years\", \"months\", \"weeks\", \"days\", \"hours\", \"minutes\", \"seconds\"]:\n            result  pandas_ta.utils.volatility(self.close, tf)\n            with self.subTest(tftf):\n                self.assertIsInstance(result, float)\n                self.assertGreaterEqual(result, 0)\n\n\n"
    ],
    "__init__.py": [
        "AgentRunResult(output='Arquivo __init__.py na raiz do projeto — inicializa o pacote principal. Possivelmente define configurações globais ou importa módulos-chaves usados em todo o projeto.')\n__init__.py\n\n\n\n\n"
    ],
    "Makefile": [
        "AgentRunResult(output='Este Makefile na raiz do projeto automatiza comandos para testes, limpeza de arquivos .pyc e instalação de dependências. Foca em testes de módulos: utils, metrics, ta, ext e strats.')\nMakefile\n\n.PHONY: all\nall:\n\tmake test_utils\n\tmake test_metrics\n\tmake test_ta\n\tmake test_ext\n\tmake test_strats\n\ncaches:\n\tfind ./pandas_ta | grep -E \"(__pycache__|\\.pyc|\\.pyo$\\)\"\n\nclean:\n\tfind . -name '*.pyc' -exec rm -f {} +\n\ninit:\n\tpip install -r requirements.txt\n\ntest_ext:\n\tpython -m unittest -v -f tests/test_ext_indicator_*.py\n\ntest_metrics:\n\tpython -m unittest -v -f tests/test_utils_metrics.py\n\ntest_strats:\n\tpython -m unittest -v -f tests/test_strategy.py\n\ntest_ta:\n\tpython -m unittest -v -f tests/test_indicator_*.py\n\ntest_utils:\n\tpython -m unittest -v -f tests/test_utils.py\n\n\n"
    ],
    "examples": [
        "AgentRunResult(output='This document in the examples folder includes multiple Jupyter notebooks converted to scripts that demonstrate technical analysis using the pandas-ta library. The main notebook, AIExample.ipynb, showcases building and analyzing trading strategies with indicators like EMA, SMA, MACD, and trend detection, as well as visualizing trades and returns using Matplotlib and mplfinance. It uses packages like NumPy, Pandas, and Yahoo Finance data access, with partial experimentation in AI strategy output. The second file, Chande_Kroll_Stop.ipynb, encountered a processing error and contains no readable content.')\nexamples/AIExample.ipynb\n\n# Jupyter notebook converted to Python script.\n\n\"\"\"\n# Strategy Analysis with **Pandas TA** and AI/ML\n* This is a **Work in Progress** and subject to change!\n* Contributions are welcome and accepted!\n* Examples below are for **educational purposes only**.\n* **NOTE:** The **watchlist** module is independent of Pandas TA. To easily use it, copy it from your local pandas_ta installation directory into your project directory.\n\"\"\"\n\n\"\"\"\n### Required Packages\n##### Uncomment the packages you need to install or are missing\n\"\"\"\n\n#!pip install numpy\n#!pip install pandas\n#!pip install mplfinance\n#!pip install pandas-datareader\n#!pip install requests_cache\n#!pip install alphaVantage-api # Required for Watchlist\n\n%pylab inline\nimport datetime as dt\nimport random as rnd\nfrom sys import float_info as sflt\n\nimport numpy as np\nimport pandas as pd\npd.set_option('max_rows', 100)\npd.set_option('max_columns', 20)\n\nimport mplfinance as mpf\nimport pandas_ta as ta\n\nfrom watchlist import colors, Watchlist # Is this failing? If so, copy it locally. See above.\n\nprint(f\"Numpy v{np.__version__}\")\nprint(f\"Pandas v{pd.__version__}\")\nprint(f\"mplfinance v{mpf.__version__}\")\nprint(f\"\\nPandas TA v{ta.version}\\nTo install the Latest Version:\\n$ pip install -U git+https://github.com/twopirllc/pandas-ta\\n\")\n%matplotlib inline\n# Output:\n#   Populating the interactive namespace from numpy and matplotlib\n\n#   Numpy v1.20.1\n\n#   Pandas v1.2.2\n\n#   mplfinance v0.12.7a5\n\n#   \n\n#   Pandas TA v0.2.64b0\n\n#   To install the Latest Version:\n\n#   $ pip install -U git+https://github.com/twopirllc/pandas-ta\n\n#   \n\n\n\"\"\"\n## MISC Functions\n\"\"\"\n\ndef recent_bars(df, tf: str  \"1y\"):\n    # All Data: 0, Last Four Years: 0.25, Last Two Years: 0.5, This Year: 1, Last Half Year: 2, Last Quarter: 4\n    yearly_divisor  {\"all\": 0, \"10y\": 0.1, \"5y\": 0.2, \"4y\": 0.25, \"3y\": 1./3, \"2y\": 0.5, \"1y\": 1, \"6mo\": 2, \"3mo\": 4}\n    yd  yearly_divisor[tf] if tf in yearly_divisor.keys() else 0\n    return int(ta.RATE[\"TRADING_DAYS_PER_YEAR\"] / yd) if yd > 0 else df.shape[0]\n\n\"\"\"\n## Collect some Data\n\"\"\"\n\ntf  \"D\"\ntickers  [\"SPY\", \"QQQ\", \"AAPL\", \"TSLA\", \"BTC-USD\"]\nwatch  Watchlist(tickers, tftf, ds_name\"yahoo\", timedTrue)\nwatch.strategy  ta.CommonStrategy\nwatch.load(tickers, analyzeTrue, verboseFalse)\n# Output:\n#   [!] Loading All: SPY, QQQ, AAPL, TSLA, BTC-USD\n\n#   [+] Downloading[yahoo]: SPY[D]\n\n#   [+] Saving: /Users/kj/av_data/SPY_D.csv\n\n#   [i] Runtime: 523.0498 ms (0.5230 s)\n\n#   [+] Downloading[yahoo]: QQQ[D]\n\n#   [+] Saving: /Users/kj/av_data/QQQ_D.csv\n\n#   [i] Runtime: 445.0625 ms (0.4451 s)\n\n#   [+] Downloading[yahoo]: AAPL[D]\n\n#   [+] Saving: /Users/kj/av_data/AAPL_D.csv\n\n#   [i] Runtime: 476.5194 ms (0.4765 s)\n\n#   [+] Downloading[yahoo]: TSLA[D]\n\n#   [+] Saving: /Users/kj/av_data/TSLA_D.csv\n\n#   [i] Runtime: 469.3292 ms (0.4693 s)\n\n#   [+] Downloading[yahoo]: BTC-USD[D]\n\n#   [+] Saving: /Users/kj/av_data/BTC-USD_D.csv\n\n#   [i] Runtime: 460.9892 ms (0.4610 s)\n\n\n\"\"\"\n# Select an Asset\n\"\"\"\n\nticker  tickers[0]\nprint(f\"{ticker} {watch.data[ticker].shape}\\nColumns: {', '.join(list(watch.data[ticker].columns))}\")\n# Output:\n#   SPY (7100, 12)\n\n#   Columns: open, high, low, close, volume, dividends, split, SMA_10, SMA_20, SMA_50, SMA_200, VOL_SMA_20\n\n\n\"\"\"\n### Trim it\n\"\"\"\n\nduration  \"1y\"\nrecent  recent_bars(watch.data[ticker], duration)\nasset  watch.data[ticker].copy().tail(recent)\n\n\"\"\"\n# Create a Trend\n\"\"\"\n\n# Example Long Trends\n# long  ta.sma(asset.close, 10) < ta.sma(asset.close, 20) # SMA(10) > SMA(20)\nlong  ta.ema(asset.close, 8) > ta.ema(asset.close, 21) # EMA(8) > EMA(21)\n# long  ta.increasing(ta.ema(asset.close, 50))\n# long  ta.macd(asset.close).iloc[:,1] > 0 # MACD Histogram is positive\n\nasset.ta.ema(length8, appendTrue)\nasset.ta.ema(length21, appendTrue)\nasset.ta.ema(length50, appendTrue)\nasset[asset.columns[5:]].tail()\n# Output:\n#               dividends  split      SMA_10      SMA_20      SMA_50     SMA_200  \\\n\n#   date                                                                           \n\n#   2021-04-05        0.0      0  394.909998  392.709276  387.393192  352.643440   \n\n#   2021-04-06        0.0      0  396.262997  393.991583  387.882991  353.139745   \n\n#   2021-04-07        0.0      0  397.971997  395.025780  388.352087  353.647168   \n\n#   2021-04-08        0.0      0  400.071997  396.036369  388.871745  354.154454   \n\n#   2021-04-09        0.0      0  402.250995  396.998604  389.637791  354.669523   \n\n#   \n\n#               VOL_SMA_20       EMA_8      EMA_21      EMA_50  \n\n#   date                                                        \n\n#   2021-04-05  97120120.0  397.670340  393.120112  386.866944  \n\n#   2021-04-06  94073315.0  399.548041  394.301919  387.621965  \n\n#   2021-04-07  91192240.0  401.112920  395.419017  388.365810  \n\n#   2021-04-08  88602355.0  402.758935  396.610015  389.156170  \n\n#   2021-04-09  87353990.0  404.699170  397.962740  390.032006  \n\n\"\"\"\n## Calculate Trend Returns from the long trend\n\"\"\"\n\ntrendy  asset.ta.trend_return(trendlong, asboolFalse, appendTrue)\ntrendy.tail() # Third Column is the long trend; binary sequences\n# Output:\n#               TR_LOGRET_1  TR_CUMLOGRET_1  TR_Trends  TR_Trades  TR_Entries  \\\n\n#   date                                                                        \n\n#   2021-04-05     0.014251        0.051645          1          0           0   \n\n#   2021-04-06    -0.000591        0.051055          1          0           0   \n\n#   2021-04-07     0.001157        0.052211          1          0           0   \n\n#   2021-04-08     0.004736        0.056947          1          0           0   \n\n#   2021-04-09     0.007244        0.064191          1          0           0   \n\n#   \n\n#               TR_Exits  \n\n#   date                  \n\n#   2021-04-05         0  \n\n#   2021-04-06         0  \n\n#   2021-04-07         0  \n\n#   2021-04-08         0  \n\n#   2021-04-09         0  \n\n\"\"\"\n### Simple Price Chart\n\"\"\"\n\nextime  ta.get_time(to_stringTrue)\nchart_  asset[[\"close\", \"EMA_8\", \"EMA_21\", \"EMA_50\"]]\nchart_.plot(figsize(16, 10), colorcolors(\"BkGrOrRd\"), titlef\"{ticker} {extime}\", gridTrue)\n# Output:\n#   <AxesSubplot:title{'center':'SPY Saturday April 10, 2021, NYSE: 5:41:45, Local: 9:41:45 PDT, Day 100/365 (27.0%)'}, xlabel'date'>\n#   <Figure size 1152x720 with 1 Axes>\n\n\"\"\"\n## Entries & Exits\n\"\"\"\n\nentries  trendy.TR_Entries.astype(int) * asset.close\nentries  entries[~np.isclose(entries, 0)]\nentries.name  \"Entry\"\n\nexits  trendy.TR_Exits.astype(int) * asset.close\nexits  exits[~np.isclose(exits, 0)]\nexits.name  \"Exit\"\n\ntotal_trades  trendy.TR_Trades.abs().sum()\nrt_trades  int(trendy.TR_Trades.abs().sum() // 2)\nprint(f\"Total Trades: {total_trades}\\t\\tRT Trades: {rt_trades}\")\n\nall_trades  trendy.TR_Trades.copy().fillna(0)\nall_trades  all_trades[all_trades ! 0]\n\ntrades  pd.DataFrame({\n    \"Signal\": all_trades,\n    entries.name: entries.dropna(),\n    exits.name: exits.dropna()\n})\ntrades\n# Output:\n#   Total Trades: 7\t\tRT Trades: 3\n\n#               Signal       Entry        Exit\n\n#   date                                      \n\n#   2020-05-07       1  283.139404         NaN\n\n#   2020-09-10      -1         NaN  330.066162\n\n#   2020-10-02       1  331.337799         NaN\n\n#   2020-10-27      -1         NaN  335.684937\n\n#   2020-11-04       1  340.965088         NaN\n\n#   2021-03-02      -1         NaN  385.278137\n\n#   2021-03-09       1  385.906067         NaN\n\n\"\"\"\n## Chart Display Strings\n\"\"\"\n\nfirst_date, last_date  asset.index[0], asset.index[-1]\nf_date  f\"{first_date.day_name()} {first_date.month}-{first_date.day}-{first_date.year}\"\nl_date  f\"{last_date.day_name()} {last_date.month}-{last_date.day}-{last_date.year}\"\nlast_ohlcv  f\"Last OHLCV: ({asset.iloc[-1].open:.4f}, {asset.iloc[-1].high:.4f}, {asset.iloc[-1].low:.4f}, {asset.iloc[-1].close:.4f}, {int(asset.iloc[-1].volume)})\"\nptitle  f\"\\n{ticker} [{tf} for {duration}({recent} bars)] from {f_date} to {l_date}\\n{last_ohlcv}\\n{extime}\"\n\n\"\"\"\n## Trade Chart\n\"\"\"\n\n# chart  asset[\"close\"] #asset[[\"close\", \"SMA_10\", \"SMA_20\", \"SMA_50\", \"SMA_200\"]]\n# chart  asset[[\"close\", \"SMA_10\", \"SMA_20\"]]\nchart  asset[[\"close\", \"EMA_8\", \"EMA_21\", \"EMA_50\"]]\nchart.plot(figsize(16, 10), colorcolors(\"BkGrOrRd\"), titleptitle, gridTrue)\nentries.plot(figsize(16, 10), colorcolors(\"FcLi\")[1], marker\"^\", markersize12, alpha0.8)\nexits.plot(figsize(16, 10), colorcolors(\"FcLi\")[0], marker\"v\", markersize12, alpha0.8, gridTrue)\n# Output:\n#   <AxesSubplot:title{'center':'\\nSPY [D for 1y(252 bars)] from Thursday 4-9-2020 to Friday 4-9-2021\\nLast OHLCV: (408.3900, 411.6700, 408.2600, 411.4900, 61060100)\\nSaturday April 10, 2021, NYSE: 5:41:45, Local: 9:41:45 PDT, Day 100/365 (27.0%)'}, xlabel'date'>\n#   <Figure size 1152x720 with 1 Axes>\n\n\"\"\"\n## Active Returns and Cumulative Active Returns\n\"\"\"\n\ntrendy.iloc[:,:2].plot(figsize(16, 3), colorcolors(\"BkBl\")[::-1])\ntrendy.TR_CUMLOGRET_1.plot(figsize(16, 3), kind\"area\", stackedFalse, colorcolors(\"SvGy\")[0], alpha0.25, gridTrue)\n# Output:\n#   <AxesSubplot:xlabel'date'>\n#   <Figure size 1152x216 with 1 Axes>\n\n\"\"\"\n# Total Return\n\"\"\"\n\ncapital  10000\n\ntotal_return  trendy.TR_CUMLOGRET_1.cumsum() * capital\npositive_return  total_return[total_return > 0]\nnegative_return  total_return[total_return < 0]\ntrdf  pd.DataFrame({\"tr+\": positive_return, \"tr-\": negative_return})\ntrdf.plot(figsize(16, 5), colorcolors(), kind\"area\", stackedFalse, alpha0.25, gridTrue)\n# Output:\n#   <AxesSubplot:xlabel'date'>\n#   <Figure size 1152x360 with 1 Axes>\n\n\"\"\"\n## Long and Short Trends\n\"\"\"\n\nlong_trend  (trendy.iloc[:,2] > 0).astype(int)\nshort_trend  (1 - long_trend).astype(int)\n\nlong_trend.plot(figsize(16, 0.85), kind\"area\", stackedTrue, colorcolors()[0], alpha0.25)\nshort_trend.plot(figsize(16, 0.85), kind\"area\", stackedTrue, colorcolors()[1], alpha0.25)\n# Output:\n#   <AxesSubplot:xlabel'date'>\n#   <Figure size 1152x61.2 with 1 Axes>\n\n\"\"\"\n# AI Analysis\n\"\"\"\n\n\"\"\"\n# Disclaimer\n* All investments involve risk, and the past performance of a security, industry, sector, market, financial product, trading strategy, or individual’s trading does not guarantee future results or returns. Investors are fully responsible for any investment decisions they make. Such decisions should be based solely on an evaluation of their financial circumstances, investment objectives, risk tolerance, and liquidity needs.\n\n* Any opinions, news, research, analyses, prices, or other information offered is provided as general market commentary, and does not constitute investment advice. I will not accept liability for any loss or damage, including without limitation any loss of profit, which may arise directly or indirectly from use of or reliance on such information.\n\"\"\"\n\n\n\nexamples/Chande_Kroll_Stop.ipynb\n\nError processing notebook: 'text/plain'\n\n\n",
        "AgentRunResult(output='Este notebook na pasta \"examples\" demonstra o uso de estratégias de análise técnica com a biblioteca Pandas TA. Aborda a criação de estratégias customizadas, uso das estratégias padrão (AllStrategy e CommonStrategy), integração com fontes de dados como AlphaVantage e aplicação via classe personalizada Watchlist. Tecnologias envolvidas: Python, Pandas, Pandas TA, AlphaVantage API.')\nexamples/PandasTA_Strategy_Examples.ipynb - Parte (1/3)\nexamples/PandasTA_Strategy_Examples.ipynb\n\n# Jupyter notebook converted to Python script.\n\n\"\"\"\n# Pandas TA ([pandas_ta](https://github.com/twopirllc/pandas-ta)) Strategies for Custom Technical Analysis\n\n## Topics\n- What is a Pandas TA Strategy?\n    - Builtin Strategies: __AllStrategy__ and __CommonStrategy__\n    - Creating Strategies\n- Watchlist Class\n    - Strategy Management and Execution\n    - **NOTE:** The **watchlist** module is independent of Pandas TA. To easily use it, copy it from your local pandas_ta installation directory into your project directory.\n- Indicator Composition/Chaining for more Complex Strategies\n    - Comprehensive Example: _MACD and RSI Momo with BBANDS and SMAs 50 & 200 and Cumulative Log Returns_\n\"\"\"\n\n%matplotlib inline\nimport datetime as dt\n\nimport pandas as pd\nimport pandas_ta as ta\nfrom alphaVantageAPI.alphavantage import AlphaVantage  # pip install alphaVantage-api\n\nfrom watchlist import Watchlist # Is this failing? If so, copy it locally. See above.\n\nprint(f\"\\nPandas TA v{ta.version}\\nTo install the Latest Version:\\n$ pip install -U git+https://github.com/twopirllc/pandas-ta\\n\")\n%pylab inline\n# Output:\n#   \n\n#   Pandas TA v0.2.64b0\n\n#   To install the Latest Version:\n\n#   $ pip install -U git+https://github.com/twopirllc/pandas-ta\n\n#   \n\n#   Populating the interactive namespace from numpy and matplotlib\n\n\n\"\"\"\n# What is a Pandas TA Strategy?\nA _Strategy_ is a simple way to name and group your favorite TA indicators. Technically, a _Strategy_ is a simple Data Class to contain list of indicators and their parameters. __Note__: _Strategy_ is experimental and subject to change. Pandas TA comes with two basic Strategies: __AllStrategy__ and __CommonStrategy__.\n\n## Strategy Requirements:\n- _name_: Some short memorable string.  _Note_: Case-insensitive \"All\" is reserved.\n- _ta_: A list of dicts containing keyword arguments to identify the indicator and the indicator's arguments\n\n## Optional Requirements:\n- _description_: A more detailed description of what the Strategy tries to capture. Default: None\n- _created_: At datetime string of when it was created. Default: Automatically generated.\n\n### Things to note:\n- A Strategy will __fail__ when consumed by Pandas TA if there is no {\"kind\": \"indicator name\"} attribute.\n\"\"\"\n\n\"\"\"\n# Builtin Examples\n\"\"\"\n\n\"\"\"\n### All\n\"\"\"\n\nAllStrategy  ta.AllStrategy\nprint(\"name \", AllStrategy.name)\nprint(\"description \", AllStrategy.description)\nprint(\"created \", AllStrategy.created)\nprint(\"ta \", AllStrategy.ta)\n# Output:\n#   name  All\n\n#   description  All the indicators with their default settings. Pandas TA default.\n\n#   created  Saturday April 10, 2021, NYSE: 5:39:01, Local: 9:39:01 PDT, Day 100/365 (27.0%)\n\n#   ta  None\n\n\n\"\"\"\n### Common\n\"\"\"\n\nCommonStrategy  ta.CommonStrategy\nprint(\"name \", CommonStrategy.name)\nprint(\"description \", CommonStrategy.description)\nprint(\"created \", CommonStrategy.created)\nprint(\"ta \", CommonStrategy.ta)\n# Output:\n#   name  Common Price and Volume SMAs\n\n#   description  Common Price SMAs: 10, 20, 50, 200 and Volume SMA: 20.\n\n#   created  Saturday April 10, 2021, NYSE: 5:39:01, Local: 9:39:01 PDT, Day 100/365 (27.0%)\n\n#   ta  [{'kind': 'sma', 'length': 10}, {'kind': 'sma', 'length': 20}, {'kind': 'sma', 'length': 50}, {'kind': 'sma', 'length': 200}, {'kind': 'sma', 'close': 'volume', 'length': 20, 'prefix': 'VOL'}]\n\n\n\"\"\"\n# Creating Strategies\n\"\"\"\n\n\"\"\"\n### Simple Strategy A\n\"\"\"\n\ncustom_a  ta.Strategy(name\"A\", ta[{\"kind\": \"sma\", \"length\": 50}, {\"kind\": \"sma\", \"length\": 200}])\ncustom_a\n# Output:\n#   Strategy(name'A', ta[{'kind': 'sma', 'length': 50}, {'kind': 'sma', 'length': 200}], description'TA Description', created'Saturday April 10, 2021, NYSE: 5:39:01, Local: 9:39:01 PDT, Day 100/365 (27.0%)')\n\n\"\"\"\n### Simple Strategy B\n\"\"\"\n\ncustom_b  ta.Strategy(name\"B\", ta[{\"kind\": \"ema\", \"length\": 8}, {\"kind\": \"ema\", \"length\": 21}, {\"kind\": \"log_return\", \"cumulative\": True}, {\"kind\": \"rsi\"}, {\"kind\": \"supertrend\"}])\ncustom_b\n# Output:\n#   Strategy(name'B', ta[{'kind': 'ema', 'length': 8}, {'kind': 'ema', 'length': 21}, {'kind': 'log_return', 'cumulative': True}, {'kind': 'rsi'}, {'kind': 'supertrend'}], description'TA Description', created'Saturday April 10, 2021, NYSE: 5:39:01, Local: 9:39:01 PDT, Day 100/365 (27.0%)')\n\n\"\"\"\n### Bad Strategy. (Misspelled Indicator)\n\"\"\"\n\n# Misspelled indicator, will fail later when ran with Pandas TA\ncustom_run_failure  ta.Strategy(name\"Runtime Failure\", ta[{\"kind\": \"percet_return\"}])\ncustom_run_failure\n# Output:\n#   Strategy(name'Runtime Failure', ta[{'kind': 'percet_return'}], description'TA Description', created'Saturday April 10, 2021, NYSE: 5:39:01, Local: 9:39:01 PDT, Day 100/365 (27.0%)')\n\n\"\"\"\n# Strategy Management and Execution with _Watchlist_\n\"\"\"\n\n\"\"\"\n### Initialize AlphaVantage Data Source\n\"\"\"\n\nAV  AlphaVantage(\n    api_key\"YOUR API KEY\", premiumFalse,\n    output_size'full', cleanTrue,\n    export_path\".\", exportTrue\n)\nAV\n# Output:\n#   AlphaVantage(\n\n#     end_point:str  https://www.alphavantage.co/query,\n\n#     api_key:str  YOUR API KEY,\n\n#     export:bool  True,\n\n#     export_path:str  .,\n\n#     output_size:str  full,\n\n#     output:str  csv,\n\n#     datatype:str  json,\n\n#     clean:bool  True,\n\n#     proxy:dict  {}\n\n#   )\n\n\"\"\"\n### Create Watchlist and set it's 'ds' to AlphaVantage\n\"\"\"\n\ndata_source  \"av\" # Default\n# data_source  \"yahoo\"\nwatch  Watchlist([\"SPY\", \"IWM\"], ds_namedata_source, timedFalse)\n\n\"\"\"\n#### Info about the Watchlist. Note, the default Strategy is \"All\"\n\"\"\"\n\nwatch\n# Output:\n#   Watch(name'Watch: SPY, IWM', ds_name'av', tickers[2]'SPY, IWM', tf'D', strategy[5]'Common Price and Volume SMAs')\n\n\"\"\"\n### Help about Watchlist\n\"\"\"\n\nhelp(Watchlist)\n# Output:\n#   Help on class Watchlist in module watchlist:\n\n#   \n\n#   class Watchlist(builtins.object)\n\n#    |  Watchlist(tickers: list, tf: str  None, name: str  None, strategy: pandas_ta.core.Strategy  None, ds_name: str  'av', **kwargs)\n\n#    |  \n\n#    |  # Watchlist Class (** This is subject to change! **)\n\n#    |  A simple Class to load/download financial market data and automatically\n\n#    |  apply Technical Analysis indicators with a Pandas TA Strategy.\n\n#    |  \n\n#    |  Default Strategy: pandas_ta.CommonStrategy\n\n#    |  \n\n#    |  ## Package Support:\n\n#    |  ### Data Source (Default: AlphaVantage)\n\n#    |  - AlphaVantage (pip install alphaVantage-api).\n\n#    |  - Python Binance (pip install python-binance). # Future Support\n\n#    |  - Yahoo Finance (pip install yfinance). # Almost Supported\n\n#    |  \n\n#    |  # Technical Analysis:\n\n#    |  - Pandas TA (pip install pandas_ta)\n\n#    |  \n\n#    |  ## Required Arguments:\n\n#    |  - tickers: A list of strings containing tickers. Example: [\"SPY\", \"AAPL\"]\n\n#    |  \n\n#    |  Methods defined here:\n\n#    |  \n\n#    |  __init__(self, tickers: list, tf: str  None, name: str  None, strategy: pandas_ta.core.Strategy  None, ds_name: str  'av', **kwargs)\n\n#    |      Initialize self.  See help(type(self)) for accurate signature.\n\n#    |  \n\n#    |  __repr__(self) -> str\n\n#    |      Return repr(self).\n\n#    |  \n\n#    |  indicators(self, *args, **kwargs) -> <built-in function any>\n\n#    |      Returns the list of indicators that are available with Pandas Ta.\n\n#    |  \n\n#    |  load(self, ticker: str  None, tf: str  None, index: str  'date', drop: list  [], plot: bool  False, **kwargs) -> pandas.core.frame.DataFrame\n\n#    |      Loads or Downloads (if a local csv does not exist) the data from the\n\n#    |      Data Source. When successful, it returns a Data Frame for the requested\n\n#    |      ticker. If no tickers are given, it loads all the tickers.\n\n#    |  \n\n#    |  ----------------------------------------------------------------------\n\n#    |  Data descriptors defined here:\n\n#    |  \n\n#    |  __dict__\n\n#    |      dictionary for instance variables (if defined)\n\n#    |  \n\n#    |  __weakref__\n\n#    |      list of weak references to the object (if defined)\n\n#    |  \n\n#    |  data\n\n#    |      When not None, it contains a dictionary of DataFrames keyed by ticker. data  {\"SPY\": pd.DataFrame, ...}\n\n#    |  \n\n#    |  name\n\n#    |      The name of the Watchlist. Default: \"Watchlist: {Watchlist.tickers}\".\n\n#    |  \n\n#    |  strategy\n\n#    |      Sets a valid Strategy. Default: pandas_ta.CommonStrategy\n\n#    |  \n\n#    |  tf\n\n#    |      Alias for timeframe. Default: 'D'\n\n#    |  \n\n#    |  tickers\n\n#    |      tickers\n\n#    |      \n\n#    |      If a string, it it converted to a list. Example: \"AAPL\" -> [\"AAPL\"]\n\n#    |          * Does not accept, comma seperated strings.\n\n#    |      If a list, checks if it is a list of strings.\n\n#    |  \n\n#    |  verbose\n\n#    |      Toggle the verbose property. Default: False\n\n#   \n\n\n\"\"\"\n### Default Strategy is \"Common\"\n\"\"\"\n\n# No arguments loads all the tickers and applies the Strategy to each ticker.\n# The result can be accessed with Watchlist's 'data' property which returns a \n# dictionary keyed by ticker and DataFrames as values \nwatch.load(verboseTrue)\n# Output:\n#   [!] Loading All: SPY, IWM\n\n#   [+] Downloading[av]: SPY[D]\n\n#   [+] Strategy: Common Price and Volume SMAs\n\n#   [i] Indicator arguments: {'timed': False, 'append': True}\n\n#   [i] Multiprocessing 5 indicators with 7 chunks and 8/8 cpus.\n\n#   [i] Total indicators: 5\n\n#   [i] Columns added: 5\n\n#   [i] Last Run: Saturday April 10, 2021, NYSE: 5:39:04, Local: 9:39:04 PDT, Day 100/365 (27.0%)\n\n#   [+] Downloading[av]: IWM[D]\n\n#   [+] Strategy: Common Price and Volume SMAs\n\n#   [i] Indicator arguments: {'timed': False, 'append': True}\n\n#   [i] Multiprocessing 5 indicators with 7 chunks and 8/8 cpus.\n\n#   [i] Total indicators: 5\n\n#   [i] Columns added: 5\n\n#   [i] Last Run: Saturday April 10, 2021, NYSE: 5:39:21, Local: 9:39:21 PDT, Day 100/365 (27.0%)\n\n\nwatch.data\n# Output:\n#   {'SPY':                 open      high       low     close      volume   SMA_10  \\\n\n#    date                                                                      \n\n#    1999-11-01  136.5000  137.0000  135.5625  135.5625   4006500.0      NaN   \n\n#    1999-11-02  135.9687  137.2500  134.5937  134.5937   6516900.0      NaN   \n\n#    1999-11-03  136.0000  136.3750  135.1250  135.5000   7222300.0      NaN   \n\n#    1999-11-04  136.7500  137.3593  135.7656  136.5312   7907500.0      NaN   \n\n#    1999-11-05  138.6250  139.1093  136.7812  137.8750   7431500.0      NaN   \n\n#    ...              ...       ...       ...       ...         ...      ...   \n\n#    2021-04-05  403.4600  406.9400  403.3800  406.3600  91684764.0  394.910   \n\n#    2021-04-06  405.7600  407.2400  405.4000  406.1200  62020953.0  396.263   \n\n#    2021-04-07  405.9400  406.9600  405.4500  406.5900  55836280.0  397.972   \n\n#    2021-04-08  407.9300  408.5800  406.9300  408.5200  57863114.0  400.072   \n\n#    2021-04-09  408.3900  411.6700  408.2600  411.4900  61104559.0  402.251   \n\n#    \n\n#                 SMA_20    SMA_50    SMA_200   VOL_SMA_20  \n\n#    date                                                   \n\n#    1999-11-01      NaN       NaN        NaN          NaN  \n\n#    1999-11-02      NaN       NaN        NaN          NaN  \n\n#    1999-11-03      NaN       NaN        NaN          NaN  \n\n#    1999-11-04      NaN       NaN        NaN          NaN  \n\n#    1999-11-05      NaN       NaN        NaN          NaN  \n\n#    ...             ...       ...        ...          ...  \n\n#    2021-04-05  393.285  388.3778  355.07135  97644589.35  \n\n#    2021-04-06  394.505  388.8426  355.54305  94588174.75  \n\n#    2021-04-07  395.476  389.2866  356.03280  91698310.95  \n\n#    2021-04-08  396.423  389.7812  356.52230  89096496.15  \n\n#    2021-04-09  397.321  390.5228  357.01950  87839472.10  \n\n#    \n\n#    [5394 rows x 10 columns],\n\n#    'IWM':               open     high     low   close      volume   SMA_10    SMA_20  \\\n\n#    date                                                                         \n\n#    2000-05-26   91.06   91.440   90.63   91.44     37400.0      NaN       NaN   \n\n#    2000-05-30   92.75   94.810   92.75   94.81     28800.0      NaN       NaN   \n\n#    2000-05-31   95.13   96.380   95.13   95.75     18000.0      NaN       NaN   \n\n#    2000-06-01   97.11   97.310   97.11   97.31      3500.0      NaN       NaN   \n\n#    2000-06-02  101.70  102.400  101.70  102.40     14700.0      NaN       NaN   \n\n#    ...            ...      ...     ...     ...         ...      ...      ",
        "AgentRunResult(output='Context: Fragmento da parte 2 de 3 do notebook PandasTA_Strategy_Examples.ipynb na pasta examples.  \\nPrincipais tópicos: Demonstração de como carregar e visualizar dados financeiros (como SPY e IWM), aplicar estratégias de análise técnica usando a biblioteca Pandas TA, como SMA, EMA, RSI, Supertrend, retorno logarítmico cumulativo e composição de indicadores. Também são apresentados exemplos de falhas de execução por erro de nome de indicador.')\nexamples/PandasTA_Strategy_Examples.ipynb - Parte (2/3)\n ...   \n\n#    2021-04-05  226.40  226.535  223.57  224.97  27826550.0  219.366  223.9090   \n\n#    2021-04-06  225.00  226.690  223.84  224.31  24907760.0  219.274  224.1875   \n\n#    2021-04-07  224.23  224.370  219.94  220.69  26233700.0  219.637  224.0550   \n\n#    2021-04-08  221.84  222.820  219.39  222.56  23989440.0  220.689  223.8220   \n\n#    2021-04-09  222.49  223.090  221.24  222.59  23267373.0  221.282  223.3405   \n\n#    \n\n#                  SMA_50    SMA_200   VOL_SMA_20  \n\n#    date                                          \n\n#    2000-05-26       NaN        NaN          NaN  \n\n#    2000-05-30       NaN        NaN          NaN  \n\n#    2000-05-31       NaN        NaN          NaN  \n\n#    2000-06-01       NaN        NaN          NaN  \n\n#    2000-06-02       NaN        NaN          NaN  \n\n#    ...              ...        ...          ...  \n\n#    2021-04-05  221.2644  179.31385  34417859.25  \n\n#    2021-04-06  221.4506  179.72680  33632261.05  \n\n#    2021-04-07  221.5686  180.12530  33331582.25  \n\n#    2021-04-08  221.7538  180.52610  32690454.25  \n\n#    2021-04-09  222.0178  180.92405  32590989.45  \n\n#    \n\n#    [5250 rows x 10 columns]}\n\nwatch.data[\"SPY\"]\n# Output:\n#                   open      high       low     close      volume   SMA_10  \\\n\n#   date                                                                      \n\n#   1999-11-01  136.5000  137.0000  135.5625  135.5625   4006500.0      NaN   \n\n#   1999-11-02  135.9687  137.2500  134.5937  134.5937   6516900.0      NaN   \n\n#   1999-11-03  136.0000  136.3750  135.1250  135.5000   7222300.0      NaN   \n\n#   1999-11-04  136.7500  137.3593  135.7656  136.5312   7907500.0      NaN   \n\n#   1999-11-05  138.6250  139.1093  136.7812  137.8750   7431500.0      NaN   \n\n#   ...              ...       ...       ...       ...         ...      ...   \n\n#   2021-04-05  403.4600  406.9400  403.3800  406.3600  91684764.0  394.910   \n\n#   2021-04-06  405.7600  407.2400  405.4000  406.1200  62020953.0  396.263   \n\n#   2021-04-07  405.9400  406.9600  405.4500  406.5900  55836280.0  397.972   \n\n#   2021-04-08  407.9300  408.5800  406.9300  408.5200  57863114.0  400.072   \n\n#   2021-04-09  408.3900  411.6700  408.2600  411.4900  61104559.0  402.251   \n\n#   \n\n#                SMA_20    SMA_50    SMA_200   VOL_SMA_20  \n\n#   date                                                   \n\n#   1999-11-01      NaN       NaN        NaN          NaN  \n\n#   1999-11-02      NaN       NaN        NaN          NaN  \n\n#   1999-11-03      NaN       NaN        NaN          NaN  \n\n#   1999-11-04      NaN       NaN        NaN          NaN  \n\n#   1999-11-05      NaN       NaN        NaN          NaN  \n\n#   ...             ...       ...        ...          ...  \n\n#   2021-04-05  393.285  388.3778  355.07135  97644589.35  \n\n#   2021-04-06  394.505  388.8426  355.54305  94588174.75  \n\n#   2021-04-07  395.476  389.2866  356.03280  91698310.95  \n\n#   2021-04-08  396.423  389.7812  356.52230  89096496.15  \n\n#   2021-04-09  397.321  390.5228  357.01950  87839472.10  \n\n#   \n\n#   [5394 rows x 10 columns]\n\nwatch.load(\"SPY\", plotTrue, masTrue)\n# Output:\n#   [i] Loaded SPY[D]: SPY_D.csv\n\n#                   open      high       low     close      volume   SMA_10  \\\n\n#   date                                                                      \n\n#   1999-11-01  136.5000  137.0000  135.5625  135.5625   4006500.0      NaN   \n\n#   1999-11-02  135.9687  137.2500  134.5937  134.5937   6516900.0      NaN   \n\n#   1999-11-03  136.0000  136.3750  135.1250  135.5000   7222300.0      NaN   \n\n#   1999-11-04  136.7500  137.3593  135.7656  136.5312   7907500.0      NaN   \n\n#   1999-11-05  138.6250  139.1093  136.7812  137.8750   7431500.0      NaN   \n\n#   ...              ...       ...       ...       ...         ...      ...   \n\n#   2021-04-05  403.4600  406.9400  403.3800  406.3600  91684764.0  394.910   \n\n#   2021-04-06  405.7600  407.2400  405.4000  406.1200  62020953.0  396.263   \n\n#   2021-04-07  405.9400  406.9600  405.4500  406.5900  55836280.0  397.972   \n\n#   2021-04-08  407.9300  408.5800  406.9300  408.5200  57863114.0  400.072   \n\n#   2021-04-09  408.3900  411.6700  408.2600  411.4900  61104559.0  402.251   \n\n#   \n\n#                SMA_20    SMA_50    SMA_200   VOL_SMA_20  \n\n#   date                                                   \n\n#   1999-11-01      NaN       NaN        NaN          NaN  \n\n#   1999-11-02      NaN       NaN        NaN          NaN  \n\n#   1999-11-03      NaN       NaN        NaN          NaN  \n\n#   1999-11-04      NaN       NaN        NaN          NaN  \n\n#   1999-11-05      NaN       NaN        NaN          NaN  \n\n#   ...             ...       ...        ...          ...  \n\n#   2021-04-05  393.285  388.3778  355.07135  97644589.35  \n\n#   2021-04-06  394.505  388.8426  355.54305  94588174.75  \n\n#   2021-04-07  395.476  389.2866  356.03280  91698310.95  \n\n#   2021-04-08  396.423  389.7812  356.52230  89096496.15  \n\n#   2021-04-09  397.321  390.5228  357.01950  87839472.10  \n\n#   \n\n#   [5394 rows x 10 columns]\n#   <Figure size 1152x720 with 1 Axes>\n\n\"\"\"\n## Easy to swap Strategies and run them\n\"\"\"\n\n\"\"\"\n### Running Simple Strategy A\n\"\"\"\n\n# Load custom_a into Watchlist and verify\nwatch.strategy  custom_a\n# watch.debug  True\nwatch.strategy\n# Output:\n#   Strategy(name'A', ta[{'kind': 'sma', 'length': 50}, {'kind': 'sma', 'length': 200}], description'TA Description', created'Saturday April 10, 2021, NYSE: 5:39:01, Local: 9:39:01 PDT, Day 100/365 (27.0%)')\n\nwatch.load(\"IWM\")\n# Output:\n#   [i] Loaded IWM[D]: IWM_D.csv\n\n#                 open     high     low   close      volume    SMA_50    SMA_200\n\n#   date                                                                        \n\n#   2000-05-26   91.06   91.440   90.63   91.44     37400.0       NaN        NaN\n\n#   2000-05-30   92.75   94.810   92.75   94.81     28800.0       NaN        NaN\n\n#   2000-05-31   95.13   96.380   95.13   95.75     18000.0       NaN        NaN\n\n#   2000-06-01   97.11   97.310   97.11   97.31      3500.0       NaN        NaN\n\n#   2000-06-02  101.70  102.400  101.70  102.40     14700.0       NaN        NaN\n\n#   ...            ...      ...     ...     ...         ...       ...        ...\n\n#   2021-04-05  226.40  226.535  223.57  224.97  27826550.0  221.2644  179.31385\n\n#   2021-04-06  225.00  226.690  223.84  224.31  24907760.0  221.4506  179.72680\n\n#   2021-04-07  224.23  224.370  219.94  220.69  26233700.0  221.5686  180.12530\n\n#   2021-04-08  221.84  222.820  219.39  222.56  23989440.0  221.7538  180.52610\n\n#   2021-04-09  222.49  223.090  221.24  222.59  23267373.0  222.0178  180.92405\n\n#   \n\n#   [5250 rows x 7 columns]\n\n\"\"\"\n### Running Simple Strategy B\n\"\"\"\n\n# Load custom_b into Watchlist and verify\nwatch.strategy  custom_b\nwatch.strategy\n# Output:\n#   Strategy(name'B', ta[{'kind': 'ema', 'length': 8}, {'kind': 'ema', 'length': 21}, {'kind': 'log_return', 'cumulative': True}, {'kind': 'rsi'}, {'kind': 'supertrend'}], description'TA Description', created'Saturday April 10, 2021, NYSE: 5:39:01, Local: 9:39:01 PDT, Day 100/365 (27.0%)')\n\nwatch.load(\"SPY\")\n# Output:\n#   [i] Loaded SPY[D]: SPY_D.csv\n\n#                   open      high       low     close      volume       EMA_8  \\\n\n#   date                                                                         \n\n#   1999-11-01  136.5000  137.0000  135.5625  135.5625   4006500.0         NaN   \n\n#   1999-11-02  135.9687  137.2500  134.5937  134.5937   6516900.0         NaN   \n\n#   1999-11-03  136.0000  136.3750  135.1250  135.5000   7222300.0         NaN   \n\n#   1999-11-04  136.7500  137.3593  135.7656  136.5312   7907500.0         NaN   \n\n#   1999-11-05  138.6250  139.1093  136.7812  137.8750   7431500.0         NaN   \n\n#   ...              ...       ...       ...       ...         ...         ...   \n\n#   2021-04-05  403.4600  406.9400  403.3800  406.3600  91684764.0  397.751097   \n\n#   2021-04-06  405.7600  407.2400  405.4000  406.1200  62020953.0  399.610853   \n\n#   2021-04-07  405.9400  406.9600  405.4500  406.5900  55836280.0  401.161775   \n\n#   2021-04-08  407.9300  408.5800  406.9300  408.5200  57863114.0  402.796936   \n\n#   2021-04-09  408.3900  411.6700  408.2600  411.4900  61104559.0  404.728728   \n\n#   \n\n#                   EMA_21  CUMLOGRET_1     RSI_14  SUPERT_7_3.0  SUPERTd_7_3.0  \\\n\n#   date                                                                          \n\n#   1999-11-01         NaN          NaN        NaN      0.000000              1   \n\n#   1999-11-02         NaN    -0.007172        NaN           NaN              1   \n\n#   1999-11-03         NaN    -0.000461        NaN           NaN              1   \n\n#   1999-11-04         NaN     0.007120        NaN           NaN              1   \n\n#   1999-11-05         NaN     0.016915        NaN           NaN              1   \n\n#   ...                ...          ...        ...           ...            ...   \n\n#   2021-04-05  393.567248     1.097807  67.670567    390.310373              1   \n\n#   2021-04-06  394.708407     1.097216  67.264341    392.803177              1   \n\n#   2021-04-07  395.788552     1.098373  67.673599    393.972009              1   \n\n#   2021-04-08  396.945956     1.103108  69.367185    396.416722              1   \n\n#   2021-04-09  398.268142     1.110352  71.814343    398.785047              1   \n\n#   \n\n#               SUPERTl_7_3.0  SUPERTs_7_3.0  \n\n#   date                                      \n\n#   1999-11-01            NaN            NaN  \n\n#   1999-11-02            NaN            NaN  \n\n#   1999-11-03            NaN            NaN  \n\n#   1999-11-04            NaN            NaN  \n\n#   1999-11-05            NaN            NaN  \n\n#   ...                   ...            ...  \n\n#   2021-04-05     390.310373            NaN  \n\n#   2021-04-06     392.803177            NaN  \n\n#   2021-04-07     393.972009            NaN  \n\n#   2021-04-08     396.416722            NaN  \n\n#   2021-04-09     398.785047            NaN  \n\n#   \n\n#   [5394 rows x 13 columns]\n\n\"\"\"\n### Running Bad Strategy. (Misspelled indicator)\n\"\"\"\n\n# Load custom_run_failure into Watchlist and verify\nwatch.strategy  custom_run_failure\nwatch.strategy\n# Output:\n#   Strategy(name'Runtime Failure', ta[{'kind': 'percet_return'}], description'TA Description', created'Saturday April 10, 2021, NYSE: 5:39:01, Local: 9:39:01 PDT, Day 100/365 (27.0%)')\n\ntry:\n    iwm  watch.load(\"IWM\")\nexcept AttributeError as error:\n    print(f\"[X] Oops! {error}\")\n# Output:\n#   [i] Loaded IWM[D]: IWM_D.csv\n\n#   [X] Oops! 'AnalysisIndicators' object has no attribute 'percet_return'\n\n\n\"\"\"\n# Indicator Composition/Chaining\n- When you need an indicator to depend on the value of a prior indicator\n- Utilitze _prefix_ or _suffix_ to help identify unique columns or avoid column name clashes.\n\"\"\"\n\n\"\"\"\n### Volume MAs and MA chains\n\"\"\"\n\n# Set EMA's and SMA's 'close' to 'volume' to create Volume MAs, prefix 'volume' MAs with 'VOLUME' so easy to identify the column\n# Take a price EMA and apply LINREG from EMA's output\nvolmas_price_ma_chain  [\n    {\"kind\":\"ema\", \"close\": \"volume\", \"length\": 10, \"prefix\": \"VOLUME\"},\n    {\"kind\":\"sma\", \"close\": \"volume\", \"length\": 20, \"prefix\": \"VOLUME\"},\n    {\"kind\":\"ema\", \"length\": 5},\n    {\"kind\":\"linreg\", \"close\": \"EMA_5\", \"length\": 8, \"prefix\": \"EMA_5\"},\n]\nvp_ma_chain_ta  ta.Strategy(\"Volume MAs and Price MA chain\", volmas_price_ma_chain)\nvp_ma_chain_ta\n# Output:\n#   Strategy(name'Volume MAs and Price MA chain', ta[{'kind': 'ema', 'close': 'volume', 'length': 10, 'prefix': 'VOLUME'}, {'kind': 'sma', 'close': 'volume', 'length': 20, 'prefix': 'VOLUME'}, {'kind': 'ema', 'length': 5}, {'kind': 'linreg', 'close': 'EMA_5', 'length': 8, 'prefix': 'EMA_5'}], description'TA Description', created'Saturday April 10, 2021, NYSE: 5:39:01, Local: 9:39:01 PDT, Day 100/365 (27.0%)')\n\n# Update the Watchlist\nwatch.strategy  vp_ma_chain_ta\nwatch.strategy.name\n# Output:\n#   'Volume MAs and Price MA chain'\n\nspy  watch.load(\"SPY\")\nspy\n# Output:\n#   [i] Loaded SPY[D]: SPY_D.csv\n\n#                   open      high       low     close      volume  VOLUME_EMA_10  \\\n\n#   date                                                                            \n\n#   1999-11-01  136.5000  137.0000  135.5625  135.5625   4006500.0            NaN   \n\n#   1999-11-02  135.9687  137.2500  134.5937  134.5937   6516900.0            NaN   \n\n#   1999-11-03  136.0000  136",
        "AgentRunResult(output='Context: examples/PandasTA_Strategy_Examples.ipynb (part 3 of 3) in the examples folder.  \\nTopics: Strategy creation using pandas-ta; indicators include MACD, BBANDS, RSI, SMA, EMA, and cumulative log returns; advanced parameter customization and column selection.')\nexamples/PandasTA_Strategy_Examples.ipynb - Parte (3/3)\n.3750  135.1250  135.5000   7222300.0            NaN   \n\n#   1999-11-04  136.7500  137.3593  135.7656  136.5312   7907500.0            NaN   \n\n#   1999-11-05  138.6250  139.1093  136.7812  137.8750   7431500.0            NaN   \n\n#   ...              ...       ...       ...       ...         ...            ...   \n\n#   2021-04-05  403.4600  406.9400  403.3800  406.3600  91684764.0   9.904359e+07   \n\n#   2021-04-06  405.7600  407.2400  405.4000  406.1200  62020953.0   9.231221e+07   \n\n#   2021-04-07  405.9400  406.9600  405.4500  406.5900  55836280.0   8.568022e+07   \n\n#   2021-04-08  407.9300  408.5800  406.9300  408.5200  57863114.0   8.062256e+07   \n\n#   2021-04-09  408.3900  411.6700  408.2600  411.4900  61104559.0   7.707384e+07   \n\n#   \n\n#               VOLUME_SMA_20       EMA_5  EMA_5_LR_8  \n\n#   date                                               \n\n#   1999-11-01            NaN         NaN         NaN  \n\n#   1999-11-02            NaN         NaN         NaN  \n\n#   1999-11-03            NaN         NaN         NaN  \n\n#   1999-11-04            NaN         NaN         NaN  \n\n#   1999-11-05            NaN  136.012480         NaN  \n\n#   ...                   ...         ...         ...  \n\n#   2021-04-05    97644589.35  399.857343  397.030535  \n\n#   2021-04-06    94588174.75  401.944895  399.235555  \n\n#   2021-04-07    91698310.95  403.493264  401.232830  \n\n#   2021-04-08    89096496.15  405.168842  403.269982  \n\n#   2021-04-09    87839472.10  407.275895  405.405385  \n\n#   \n\n#   [5394 rows x 9 columns]\n\n\"\"\"\n### MACD BBANDS\n\"\"\"\n\n# MACD is the initial indicator that BBANDS depends on.\n# Set BBANDS's 'close' to MACD's main signal, in this case 'MACD_12_26_9' and add a prefix (or suffix) so it's easier to identify\nmacd_bands_ta  [\n    {\"kind\":\"macd\"},\n    {\"kind\":\"bbands\", \"close\": \"MACD_12_26_9\", \"length\": 20, \"prefix\": \"MACD\"}\n]\nmacd_bands_ta  ta.Strategy(\"MACD BBands\", macd_bands_ta, f\"BBANDS_{macd_bands_ta[1]['length']} applied to MACD\")\nmacd_bands_ta\n# Output:\n#   Strategy(name'MACD BBands', ta[{'kind': 'macd'}, {'kind': 'bbands', 'close': 'MACD_12_26_9', 'length': 20, 'prefix': 'MACD'}], description'BBANDS_20 applied to MACD', created'Saturday April 10, 2021, NYSE: 5:39:01, Local: 9:39:01 PDT, Day 100/365 (27.0%)')\n\n# Update the Watchlist\nwatch.strategy  macd_bands_ta\nwatch.strategy.name\n# Output:\n#   'MACD BBands'\n\nspy  watch.load(\"SPY\")\nspy\n# Output:\n#   [i] Loaded SPY[D]: SPY_D.csv\n\n#                   open      high       low     close      volume  MACD_12_26_9  \\\n\n#   date                                                                           \n\n#   1999-11-01  136.5000  137.0000  135.5625  135.5625   4006500.0           NaN   \n\n#   1999-11-02  135.9687  137.2500  134.5937  134.5937   6516900.0           NaN   \n\n#   1999-11-03  136.0000  136.3750  135.1250  135.5000   7222300.0           NaN   \n\n#   1999-11-04  136.7500  137.3593  135.7656  136.5312   7907500.0           NaN   \n\n#   1999-11-05  138.6250  139.1093  136.7812  137.8750   7431500.0           NaN   \n\n#   ...              ...       ...       ...       ...         ...           ...   \n\n#   2021-04-05  403.4600  406.9400  403.3800  406.3600  91684764.0      3.496649   \n\n#   2021-04-06  405.7600  407.2400  405.4000  406.1200  62020953.0      4.043917   \n\n#   2021-04-07  405.9400  406.9600  405.4500  406.5900  55836280.0      4.464097   \n\n#   2021-04-08  407.9300  408.5800  406.9300  408.5200  57863114.0      4.896384   \n\n#   2021-04-09  408.3900  411.6700  408.2600  411.4900  61104559.0      5.416195   \n\n#   \n\n#               MACDh_12_26_9  MACDs_12_26_9  MACD_BBL_20_2.0  MACD_BBM_20_2.0  \\\n\n#   date                                                                         \n\n#   1999-11-01            NaN            NaN              NaN              NaN   \n\n#   1999-11-02            NaN            NaN              NaN              NaN   \n\n#   1999-11-03            NaN            NaN              NaN              NaN   \n\n#   1999-11-04            NaN            NaN              NaN              NaN   \n\n#   1999-11-05            NaN            NaN              NaN              NaN   \n\n#   ...                   ...            ...              ...              ...   \n\n#   2021-04-05       1.051942       2.444707         0.173035         1.949555   \n\n#   2021-04-06       1.279368       2.764549         0.396500         2.153128   \n\n#   2021-04-07       1.359638       3.104459         0.570354         2.365544   \n\n#   2021-04-08       1.433541       3.462844         0.658913         2.580554   \n\n#   2021-04-09       1.562681       3.853514         0.613266         2.791236   \n\n#   \n\n#               MACD_BBU_20_2.0  MACD_BBB_20_2.0  \n\n#   date                                          \n\n#   1999-11-01              NaN              NaN  \n\n#   1999-11-02              NaN              NaN  \n\n#   1999-11-03              NaN              NaN  \n\n#   1999-11-04              NaN              NaN  \n\n#   1999-11-05              NaN              NaN  \n\n#   ...                     ...              ...  \n\n#   2021-04-05         3.726075       182.248798  \n\n#   2021-04-06         3.909756       163.169877  \n\n#   2021-04-07         4.160734       151.778160  \n\n#   2021-04-08         4.502194       148.932443  \n\n#   2021-04-09         4.969206       156.057773  \n\n#   \n\n#   [5394 rows x 12 columns]\n\n\"\"\"\n# Comprehensive Strategy\n\"\"\"\n\n\"\"\"\n### MACD and RSI Momentum with BBANDS and SMAs and Cumulative Log Returns\n\"\"\"\n\nmomo_bands_sma_ta  [\n    {\"kind\":\"sma\", \"length\": 50},\n    {\"kind\":\"sma\", \"length\": 200},\n    {\"kind\":\"bbands\", \"length\": 20},\n    {\"kind\":\"macd\"},\n    {\"kind\":\"rsi\"},\n    {\"kind\":\"log_return\", \"cumulative\": True},\n    {\"kind\":\"sma\", \"close\": \"CUMLOGRET_1\", \"length\": 5, \"suffix\": \"CUMLOGRET\"},\n]\nmomo_bands_sma_strategy  ta.Strategy(\n    \"Momo, Bands and SMAs and Cumulative Log Returns\", # name\n    momo_bands_sma_ta, # ta\n    \"MACD and RSI Momo with BBANDS and SMAs 50 & 200 and Cumulative Log Returns\" # description\n)\nmomo_bands_sma_strategy\n# Output:\n#   Strategy(name'Momo, Bands and SMAs and Cumulative Log Returns', ta[{'kind': 'sma', 'length': 50}, {'kind': 'sma', 'length': 200}, {'kind': 'bbands', 'length': 20}, {'kind': 'macd'}, {'kind': 'rsi'}, {'kind': 'log_return', 'cumulative': True}, {'kind': 'sma', 'close': 'CUMLOGRET_1', 'length': 5, 'suffix': 'CUMLOGRET'}], description'MACD and RSI Momo with BBANDS and SMAs 50 & 200 and Cumulative Log Returns', created'Saturday April 10, 2021, NYSE: 5:39:01, Local: 9:39:01 PDT, Day 100/365 (27.0%)')\n\n# Update the Watchlist\nwatch.strategy  momo_bands_sma_strategy\nwatch.strategy.name\n# Output:\n#   'Momo, Bands and SMAs and Cumulative Log Returns'\n\nspy  watch.load(\"SPY\")\n# Apply constants to the DataFrame for indicators\nspy.ta.constants(True, [0, 30, 70])\nspy.tail()\n# Output:\n#   [i] Loaded SPY[D]: SPY_D.csv\n\n#                 open    high     low   close      volume    SMA_50    SMA_200  \\\n\n#   date                                                                          \n\n#   2021-04-05  403.46  406.94  403.38  406.36  91684764.0  388.3778  355.07135   \n\n#   2021-04-06  405.76  407.24  405.40  406.12  62020953.0  388.8426  355.54305   \n\n#   2021-04-07  405.94  406.96  405.45  406.59  55836280.0  389.2866  356.03280   \n\n#   2021-04-08  407.93  408.58  406.93  408.52  57863114.0  389.7812  356.52230   \n\n#   2021-04-09  408.39  411.67  408.26  411.49  61104559.0  390.5228  357.01950   \n\n#   \n\n#               BBL_20_2.0  BBM_20_2.0  BBU_20_2.0  BBB_20_2.0  MACD_12_26_9  \\\n\n#   date                                                                       \n\n#   2021-04-05  382.834363     393.285  403.735637    5.314536      3.496649   \n\n#   2021-04-06  384.042695     394.505  404.967305    5.304016      4.043917   \n\n#   2021-04-07  384.334301     395.476  406.617699    5.634577      4.464097   \n\n#   2021-04-08  384.272821     396.423  408.573179    6.129906      4.896384   \n\n#   2021-04-09  383.604942     397.321  411.037058    6.904270      5.416195   \n\n#   \n\n#               MACDh_12_26_9  MACDs_12_26_9     RSI_14  CUMLOGRET_1  \\\n\n#   date                                                               \n\n#   2021-04-05       1.051942       2.444707  67.670567     1.097807   \n\n#   2021-04-06       1.279368       2.764549  67.264341     1.097216   \n\n#   2021-04-07       1.359638       3.104459  67.673599     1.098373   \n\n#   2021-04-08       1.433541       3.462844  69.367185     1.103108   \n\n#   2021-04-09       1.562681       3.853514  71.814343     1.110352   \n\n#   \n\n#               SMA_5_CUMLOGRET  0  30  70  \n\n#   date                                    \n\n#   2021-04-05         1.078874  0  30  70  \n\n#   2021-04-06         1.084032  0  30  70  \n\n#   2021-04-07         1.089953  0  30  70  \n\n#   2021-04-08         1.096012  0  30  70  \n\n#   2021-04-09         1.101371  0  30  70  \n\n\"\"\"\n# Additional Strategy Options\n\"\"\"\n\n\"\"\"\nThe ```params``` keyword takes a _tuple_ as a shorthand to the parameter arguments in order.\n* **Note**: If the indicator arguments change, so will results. Breaking Changes will **always** be posted on the README.\n\nThe ```col_numbers``` keyword takes a _tuple_ specifying which column to return if the result is a DataFrame.\n\"\"\"\n\nparams_ta  [\n    {\"kind\":\"ema\", \"params\": (10,)},\n    # params sets MACD's keyword arguments: fast9, slow19, signal10\n    # and returning the 2nd column: histogram\n    {\"kind\":\"macd\", \"params\": (9, 19, 10), \"col_numbers\": (1,)},\n    # Selects the Lower and Upper Bands and renames them LB and UB, ignoring the MB\n    {\"kind\":\"bbands\", \"col_numbers\": (0,2), \"col_names\": (\"LB\", \"UB\")},\n    {\"kind\":\"log_return\", \"params\": (5, False)},\n]\nparams_ta_strategy  ta.Strategy(\n    \"EMA, MACD History, Outter BBands, Log Returns\", # name\n    params_ta, # ta\n    \"EMA, MACD History, BBands(LB, UB), and Log Returns Strategy\" # description\n)\nparams_ta_strategy\n# Output:\n#   Strategy(name'EMA, MACD History, Outter BBands, Log Returns', ta[{'kind': 'ema', 'params': (10,)}, {'kind': 'macd', 'params': (9, 19, 10), 'col_numbers': (1,)}, {'kind': 'bbands', 'col_numbers': (0, 2), 'col_names': ('LB', 'UB')}, {'kind': 'log_return', 'params': (5, False)}], description'EMA, MACD History, BBands(LB, UB), and Log Returns Strategy', created'Saturday April 10, 2021, NYSE: 5:39:01, Local: 9:39:01 PDT, Day 100/365 (27.0%)')\n\n# Update the Watchlist\nwatch.strategy  params_ta_strategy\nwatch.strategy.name\n# Output:\n#   'EMA, MACD History, Outter BBands, Log Returns'\n\nspy  watch.load(\"SPY\")\nspy.tail()\n# Output:\n#   [i] Loaded SPY[D]: SPY_D.csv\n\n#                 open    high     low   close      volume      EMA_10  \\\n\n#   date                                                                 \n\n#   2021-04-05  403.46  406.94  403.38  406.36  91684764.0  396.789148   \n\n#   2021-04-06  405.76  407.24  405.40  406.12  62020953.0  398.485666   \n\n#   2021-04-07  405.94  406.96  405.45  406.59  55836280.0  399.959181   \n\n#   2021-04-08  407.93  408.58  406.93  408.52  57863114.0  401.515694   \n\n#   2021-04-09  408.39  411.67  408.26  411.49  61104559.0  403.329204   \n\n#   \n\n#               MACDh_9_19_10          LB          UB  LOGRET_5  \n\n#   date                                                         \n\n#   2021-04-05       1.302704  390.173232  407.350768  0.025876  \n\n#   2021-04-06       1.529192  391.193677  410.466323  0.025790  \n\n#   2021-04-07       1.561328  395.008877  411.395123  0.029603  \n\n#   2021-04-08       1.590588  400.329889  410.950111  0.030294  \n\n#   2021-04-09       1.695492  403.766969  411.865031  0.026796  \n\n\"\"\"\n# Disclaimer\n* All investments involve risk, and the past performance of a security, industry, sector, market, financial product, trading strategy, or individual’s trading does not guarantee future results or returns. Investors are fully responsible for any investment decisions they make. Such decisions should be based solely on an evaluation of their financial circumstances, investment objectives, risk tolerance, and liquidity needs.\n\n* Any opinions, news, research, analyses, prices, or other information offered is provided as general market commentary, and does not constitute investment advice. I will not accept liability for any loss or damage, including without limitation any loss of profit, which may arise directly or indirectly from use of or reliance on such information.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Contexto: Este notebook Jupyter está localizado na pasta \"examples\" na raiz do projeto. Ele serve como um exemplo educativo de como utilizar indicadores técnicos da biblioteca pandas_ta, juntamente com ferramentas como AlphaVantageAPI e mplfinance.\\n\\nTópicos principais: Análise técnica com pandas_ta, visualização gráfica de indicadores financeiros, integração com AlphaVantage para obtenção de cotações históricas, uso de matplotlib e mplfinance para plotagens financeiras, construção de estratégias e gráficos com múltiplos indicadores como EMA, RSI, MACD, entre outros.\\n\\nTecnologias: pandas_ta, mplfinance, AlphaVantage API, matplotlib, pandas, numpy, Jupyter notebook.')\nexamples/example.ipynb - Parte (1/2)\nexamples/example.ipynb\n\n# Jupyter notebook converted to Python script.\n\n\"\"\"\n# Technical Analysis with Pandas ([pandas_ta](https://github.com/twopirllc/pandas-ta))\n* Below contains examples of simple charts that can be made from pandas_ta indicators\n* Examples below are for **educational purposes only**\n* **NOTE:** The **watchlist** module is independent of Pandas TA. To easily use it, copy it from your local pandas_ta installation directory into your project directory.\n\"\"\"\n\n%matplotlib inline\nimport datetime as dt\nimport random as rnd\n\nimport numpy as np\nimport pandas as pd\nimport mplfinance as mpf\n\nfrom alphaVantageAPI.alphavantage import AlphaVantage\nimport pandas_ta as ta\n\nfrom watchlist import colors # Is this failing? If so, copy it locally. See above.\n\nprint(f\"\\nPandas TA v{ta.version}\\nTo install the Latest Version:\\n$ pip install -U git+https://github.com/twopirllc/pandas-ta\\n\")\n\n%pylab inline\n# Output:\n#   \n\n#   Pandas TA v0.2.64b0\n\n#   To install the Latest Version:\n\n#   $ pip install -U git+https://github.com/twopirllc/pandas-ta\n\n#   \n\n#   Populating the interactive namespace from numpy and matplotlib\n\n\n\"\"\"\n### List of Indicators (post an [issue](https://github.com/twopirllc/pandas-ta/issues) if the indicator doc needs updating)\n\"\"\"\n\ne  pd.DataFrame()\ne.ta.indicators()\n# Output:\n#   Pandas TA - Technical Analysis Indicators - v0.2.64b0\n\n#   Total Indicators: 134\n\n#   Abbreviations:\n\n#       aberration, above, above_value, accbands, ad, adosc, adx, alma, amat, ao, aobv, apo, aroon, atr, bbands, below, below_value, bias, bop, brar, cci, cdl_doji, cdl_inside, cfo, cg, chop, cksp, cmf, cmo, coppock, cross, cross_value, decay, decreasing, dema, donchian, dpo, ebsw, efi, ema, entropy, eom, er, eri, fisher, fwma, ha, hilo, hl2, hlc3, hma, hwc, hwma, ichimoku, increasing, inertia, kama, kc, kdj, kst, kurtosis, linreg, log_return, long_run, macd, mad, massi, mcgd, median, mfi, midpoint, midprice, mom, natr, nvi, obv, ohlc4, pdist, percent_return, pgo, ppo, psar, psl, pvi, pvo, pvol, pvr, pvt, pwma, qqe, qstick, quantile, rma, roc, rsi, rsx, rvgi, rvi, short_run, sinwma, skew, slope, sma, smi, squeeze, ssf, stdev, stoch, stochrsi, supertrend, swma, t3, td_seq, tema, thermo, trend_return, trima, trix, true_range, tsi, ttm_trend, ui, uo, variance, vidya, vortex, vp, vwap, vwma, wcp, willr, wma, zlma, zscore\n\n\n\"\"\"\n### Individual Indicator help\n\"\"\"\n\nhelp(ta.ema)\n# Output:\n#   Help on function ema in module pandas_ta.overlap.ema:\n\n#   \n\n#   ema(close, lengthNone, offsetNone, **kwargs)\n\n#       Exponential Moving Average (EMA)\n\n#       \n\n#       The Exponential Moving Average is more responsive moving average compared to the\n\n#       Simple Moving Average (SMA).  The weights are determined by alpha which is\n\n#       proportional to it's length.  There are several different methods of calculating\n\n#       EMA.  One method uses just the standard definition of EMA and another uses the\n\n#       SMA to generate the initial value for the rest of the calculation.\n\n#       \n\n#       Sources:\n\n#           https://stockcharts.com/school/doku.php?idchart_school:technical_indicators:moving_averages\n\n#           https://www.investopedia.com/ask/answers/122314/what-exponential-moving-average-ema-formula-and-how-ema-calculated.asp\n\n#       \n\n#       Calculation:\n\n#           Default Inputs:\n\n#               length10, adjustFalse, smaTrue\n\n#           if sma:\n\n#               sma_nth  close[0:length].sum() / length\n\n#               close[:length - 1]  np.NaN\n\n#               close.iloc[length - 1]  sma_nth\n\n#           EMA  close.ewm(spanlength, adjustadjust).mean()\n\n#       \n\n#       Args:\n\n#           close (pd.Series): Series of 'close's\n\n#           length (int): It's period. Default: 10\n\n#           offset (int): How many periods to offset the result. Default: 0\n\n#       \n\n#       Kwargs:\n\n#           adjust (bool, optional): Default: False\n\n#           sma (bool, optional): If True, uses SMA for initial value. Default: True\n\n#           fillna (value, optional): pd.DataFrame.fillna(value)\n\n#           fill_method (value, optional): Type of fill method\n\n#       \n\n#       Returns:\n\n#           pd.Series: New feature generated.\n\n#   \n\n\n\"\"\"\n### Load Daily SPY from [AlphaVantage](http://www.alphavantage.com) and clean it\n\"\"\"\n\ndef farm(ticker  \"SPY\", timeframe\"DA\", cols[\"dividend\", \"split_coefficient\"]):\n    AV  AlphaVantage(api_key\"YOUR API KEY\", premiumFalse, cleanTrue, output_size\"full\")\n    df  AV.data(symbolticker, functiontimeframe)\n    df.set_index(pd.DatetimeIndex(df[\"date\"]), inplaceTrue) if not df.ta.datetime_ordered else None\n    df.drop(cols, axis1, inplaceTrue, errors\"ignore\")\n    df.name  ticker\n    return df\n\ndef ctitle(indicator_name, ticker\"SPY\", length100):\n    return f\"{ticker}: {indicator_name} from {recent_startdate} to {recent_enddate} ({length})\"\n\ndef ta_ylim(series: pd.Series, percent: float  0.1):\n    smin, smax  series.min(), series.max()\n    if isinstance(percent, float) and 0 < float(percent) < 1:\n        y_min  (1 + percent) * smin if smin < 0 else (1 - percent) * smin\n        y_max  (1 - percent) * smax if smax < 0 else (1 + percent) * smax\n        return (y_min, y_max)\n    return (smin, smax)\n\n\"\"\"\n### Initialization\n\"\"\"\n\nprice_size  (16, 8)\nind_size  (16, 3.25)\nticker  \"SPY\"\n# # All Data: 0, Last Four Years: 0.25, Last Two Years: 0.5, This Year: 1, Last Half Year: 2, Last Quarter: 3\n# yearly_divisor  1\n# recent  int(ta.RATE[\"TRADING_DAYS_PER_YEAR\"] / yearly_divisor) if yearly_divisor > 0 else df.shape[0]\n# print(recent)\ndef recent_bars(df, tf: str  \"1y\"):\n    # All Data: 0, Last Four Years: 0.25, Last Two Years: 0.5, This Year: 1, Last Half Year: 2, Last Quarter: 4\n    yearly_divisor  {\"all\": 0, \"10y\": 0.1, \"5y\": 0.2, \"4y\": 0.25, \"3y\": 1./3, \"2y\": 0.5, \"1y\": 1, \"6mo\": 2, \"3mo\": 4}\n    yd  yearly_divisor[tf] if tf in yearly_divisor.keys() else 0\n    return int(ta.RATE[\"TRADING_DAYS_PER_YEAR\"] / yd) if yd > 0 else df.shape[0]\n\n\"\"\"\n### Get Ticker and take a peek\n\"\"\"\n\n# All the Data\ndf  farm(ticker)\nprint(f\"{df.name}{df.shape} from {df.index[0]} to {df.index[-1]}\\n{df.describe()}\")\ndf.head()\n# Output:\n#   SPY(5394, 6) from 1999-11-01 00:00:00 to 2021-04-09 00:00:00\n\n#                 open         high          low        close    adj_close  \\\n\n#   count  5394.000000  5394.000000  5394.000000  5394.000000  5394.000000   \n\n#   mean    168.016118   169.010709   166.920680   168.017344   143.128561   \n\n#   std      70.960074    71.220714    70.662550    70.973501    78.627859   \n\n#   min      67.949997    70.000000    67.099998    68.110001    53.293084   \n\n#   25%     117.114999   117.835000   116.227500   117.000000    86.941066   \n\n#   50%     139.770602   140.650000   138.635002   139.750000   106.548821   \n\n#   75%     208.070005   209.147500   207.190000   208.332500   186.820489   \n\n#   max     408.390000   411.670000   408.260000   411.490000   411.490000   \n\n#   \n\n#                volume  \n\n#   count  5.394000e+03  \n\n#   mean   1.103395e+08  \n\n#   std    9.694148e+07  \n\n#   min    1.708170e+05  \n\n#   25%    4.824947e+07  \n\n#   50%    8.153653e+07  \n\n#   75%    1.469538e+08  \n\n#   max    8.710263e+08  \n\n#                     open        high         low       close  adj_close  \\\n\n#   date                                                                    \n\n#   1999-11-01  136.500000  137.000000  135.562500  135.562500  90.911009   \n\n#   1999-11-02  135.968704  137.250000  134.593704  134.593704  90.261314   \n\n#   1999-11-03  136.000000  136.375000  135.125000  135.500000  90.869095   \n\n#   1999-11-04  136.750000  137.359299  135.765594  136.531204  91.560642   \n\n#   1999-11-05  138.625000  139.109299  136.781204  137.875000  92.461819   \n\n#   \n\n#                  volume  \n\n#   date                   \n\n#   1999-11-01  4006500.0  \n\n#   1999-11-02  6516900.0  \n\n#   1999-11-03  7222300.0  \n\n#   1999-11-04  7907500.0  \n\n#   1999-11-05  7431500.0  \n\n# Recent Data\nrecent_startdate  df.tail(recent_bars(df)).index[0]\nrecent_enddate  df.tail(recent_bars(df)).index[-1]\nprint(f\"{df.name}{df.tail(recent_bars(df)).shape} from {recent_startdate} to {recent_enddate}\\n{df.describe()}\")\ndf.tail(recent_bars(df)).head()\n# Output:\n#   SPY(252, 6) from 2020-04-09 00:00:00 to 2021-04-09 00:00:00\n\n#                 open         high          low        close    adj_close  \\\n\n#   count  5394.000000  5394.000000  5394.000000  5394.000000  5394.000000   \n\n#   mean    168.016118   169.010709   166.920680   168.017344   143.128561   \n\n#   std      70.960074    71.220714    70.662550    70.973501    78.627859   \n\n#   min      67.949997    70.000000    67.099998    68.110001    53.293084   \n\n#   25%     117.114999   117.835000   116.227500   117.000000    86.941066   \n\n#   50%     139.770602   140.650000   138.635002   139.750000   106.548821   \n\n#   75%     208.070005   209.147500   207.190000   208.332500   186.820489   \n\n#   max     408.390000   411.670000   408.260000   411.490000   411.490000   \n\n#   \n\n#                volume  \n\n#   count  5.394000e+03  \n\n#   mean   1.103395e+08  \n\n#   std    9.694148e+07  \n\n#   min    1.708170e+05  \n\n#   25%    4.824947e+07  \n\n#   50%    8.153653e+07  \n\n#   75%    1.469538e+08  \n\n#   max    8.710263e+08  \n\n#                 open    high     low   close   adj_close       volume\n\n#   date                                                               \n\n#   2020-04-09  277.58  281.20  275.47  278.20  273.782855  189948139.0\n\n#   2020-04-13  277.14  277.51  271.41  275.66  271.283184  114353986.0\n\n#   2020-04-14  280.98  284.90  275.51  283.79  279.284099  133510280.0\n\n#   2020-04-15  277.57  283.94  275.46  277.76  273.349841  121155983.0\n\n#   2020-04-16  279.15  280.03  275.76  279.10  274.668565  126144324.0\n\n\"\"\"\n### Aliases\n\"\"\"\n\nopendf  df[\"open\"]\nclosedf  df[\"close\"]\nvolumedf  df[\"volume\"]\n\n\"\"\"\n## DataFrame **constants**: When you need some simple lines for charting\n\"\"\"\n\n# help(df.ta.constants) # for more info\nchart_lines  np.append(np.arange(-5, 6, 1), np.arange(-100, 110, 10))\ndf.ta.constants(True, chart_lines) # Adding the constants for the charts\ndf.ta.constants(False, np.array([-60, -40, 40, 60])) # Removing some constants from the DataFrame\nprint(f\"Columns: {', '.join(list(df.columns))}\")\n# Output:\n#   Columns: open, high, low, close, adj_close, volume, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, -100, -90, -80, -70, -50, -30, -20, -10, 10, 20, 30, 50, 70, 80, 90, 100\n\n\n\"\"\"\n## Example Charting Class utilizing **mplfinance** panels\n\"\"\"\n\nclass Chart(object):\n    def __init__(self, df: pd.DataFrame  None, strategy: ta.Strategy  ta.CommonStrategy, *args, **kwargs):\n        self.verbose  kwargs.pop(\"verbose\", False)\n\n        if isinstance(df, pd.DataFrame) and df.ta.datetime_ordered:\n            self.df  df\n            if self.df.name is not None and self.df.name ! \"\":\n                df_name  str(self.df.name)\n            else:\n                df_name  \"DataFrame\"\n            if self.verbose: print(f\"[i] Loaded {df_name}{self.df.shape}\")\n        else:\n            print(f\"[X] Oops! Missing 'ohlcv' data or index is not datetime ordered.\\n\")\n            return None\n\n        self._validate_ta_strategy(strategy)\n        self._validate_mpf_kwargs(**kwargs)\n        self._validate_chart_kwargs(**kwargs)\n\n        # Build TA and Plot\n        self.df.ta.strategy(self.strategy, verboseself.verbose)\n        self._plot(**kwargs)\n\n    def _validate_ta_strategy(self, strategy):\n        if strategy is not None or isinstance(strategy, ta.Strategy):\n            self.strategy  strategy\n        elif len(self.strategy_ta) > 0:\n            print(f\"[+] Strategy: {self.strategy_name}\")\n        else:\n            self.strategy  ta.CommonStrategy        \n\n    def _validate_chart_kwargs(self, **kwargs):\n        \"\"\"Chart Settings\"\"\"\n        self.config  {}\n        self.config[\"last\"]  kwargs.pop(\"last\", recent_bars(self.df))\n        self.config[\"rpad\"]  kwargs.pop(\"rpad\", 10)\n        self.config[\"title\"]  kwargs.pop(\"title\", \"Asset\")\n        self.config[\"volume\"]  kwargs.pop(\"volume\", True)\n\n    def _validate_mpf_kwargs(self, **kwargs):\n        # mpf global chart settings\n        default_chart  mpf.available_styles()[-1]\n        default_mpf_width  {\n            'candle_linewidth': 0.6,\n            'candle_width': 0.525,\n            'volume_width': 0.525\n        }\n        mpfchart  {}\n\n        mpf_style  kwargs.pop(\"style\", \"\")\n        if mpf_style  \"\" or mpf_style.lower()  \"random\":\n            mpf_styles  mpf.available_styles()\n            mpfchart[\"style\"]  mpf_styles[rnd.randrange(len(mpf_styles))]\n        elif mpf_style.lower() in mpf.available_styles():\n            mpfchart[\"style\"]  mpf_style\n\n        mpfchart[\"figsize\"]  kwargs.pop(\"figsize\", (12, 10))\n        mpfchart[\"non_trading\"]  kwargs.pop(\"nontrading\", False)\n        mpfchart[\"rc\"]  kwargs.pop(\"rc\", {'figure.facecolor': '#EDEDED'})\n        mpfchart[\"plot_ratios\"]  kwargs.pop(\"plot_ratios\", (12, 1.7))\n        mpfchart[\"scale_padding\"]  kwargs.pop(\"scale_padding\", {'left': 1, 'top': 4, 'right': 1, 'bottom': 1})\n        mpfchart[\"tight_layout\"]  kwargs.pop(\"tight_layout\", True)\n        mpfchart[\"type\"]  kwargs.pop(\"type\", \"candle\")\n        mpfchart[\"width_config\"]  kwargs.pop(\"width_config\", default_mpf_width)\n        mpfchart[\"xrotation\"]  kwargs.pop(\"xrotation\", 15)\n        \n        self.mpfchart  mpfchart\n\n    def _attribution(self):\n        print(f\"\\nPandas v: {pd.__version__} [pip install pandas] https://github.com/pandas-dev/pandas\")\n        print(f\"Data from AlphaVantage v: 1.0.19 [pip install alphaVantage-api] http://www.alphavantage.co https://github.com/twopirllc/AlphaVantageAPI\")\n        print(f\"Technical Analysis with Pandas TA v: {ta.version} [pip install pandas_ta] https://github.com/twopirllc/pandas-ta\")\n        print(f\"Charts by Matplotlib Finance v: {mpf.__version__} [pip install mplfinance] https://github.com/matplotlib/mplfinance\\n\")\n\n    def _right_pad_df(self, rpad: int, delta_unit: str  \"D\", range_freq: str  \"B\"):\n        if rpad > 0:\n            dfpad  self.df[-rpad:].copy()\n            dfpad.iloc[:,:]  np.NaN\n\n            df_frequency  self.df.index.value_counts().mode()[0] # Most common frequency\n            freq_delta  pd.Timedelta(df_frequency, unitdelta_unit)\n            new_dr  pd.date_range(startself.df.index[-1] + freq_delta, periodsrpad, freqrange_freq)\n            dfpad.index  new_dr # Update the padded index with new dates\n            self.df  self.df.append(dfpad)\n        \n            \n    def _plot(self, **kwargs):\n        if not isinstance(self.mpfchart[\"plot_ratios\"], tuple):\n            print(f\"[X] plot_ratios must be a tuple\")\n            return\n\n        # Override Chart Title Option\n        chart_title  self.config[\"title\"]\n        if \"title\" in kwargs and isinstance(kwargs[\"title\"], str):\n            chart_title  kwargs.pop(\"title\")\n\n        # Override Right Bar Padding Option\n        rpad  self.config[\"rpad\"]\n        if \"rpad\" in kwargs and kwargs[\"rpad\"] > 0:\n            rpad  int(kwargs[\"rpad\"])\n\n        def cpanel():\n            return len(self.mpfchart['plot_ratios'])\n\n        # Last Second Default TA Indicators\n        linreg  kwargs.pop(\"linreg\", False)\n        linreg_name  self.df.ta.linreg(appendTrue).name if linreg else \"\"\n\n        midpoint  kwargs.pop(\"midpoint\", False)\n        midpoint_name  self.df.ta.midpoint(appendTrue).name if midpoint else \"\"\n\n        ohlc4  kwargs.pop(\"ohlc4\", False)\n        ohlc4_name  self.df.ta.ohlc4(appendTrue).name if ohlc4 else \"\"\n\n        clr  kwargs.pop(\"clr\", False)\n        clr_name  self.df.ta.log_return(cumulativeTrue, appendTrue).name if clr else \"\"\n\n        rsi  kwargs.pop(\"rsi\", False)\n        rsi_length  kwargs.pop(\"rsi_length\", None)\n        if isinstance(rsi_length, int) and rsi_length > 1:\n            rsi_name  self.df.ta.rsi(lengthrsi_length, appendTrue).name\n        elif rsi:\n            rsi_name  self.df.ta.rsi(appendTrue).name\n        else: rsi_name  \"\"\n            \n        zscore  kwargs.pop(\"zscore\", False)\n        zscore_length  kwargs.pop(\"zscore_length\", None)\n        if isinstance(zscore_length, int) and zscore_length > 1:\n            zs_name  self.df.ta.zscore(lengthzscore_length, appendTrue).name\n        elif zscore:\n            zs_name  self.df.ta.zscore(appendTrue).name\n        else: zs_name  \"\"\n\n        macd  kwargs.pop(\"macd\", False)\n        macd_name  \"\"\n        if macd:\n            macds  self.df.ta.macd(appendTrue)\n            macd_name  macds.name\n\n        squeeze  kwargs.pop(\"squeeze\", False)\n        lazybear  kwargs.pop(\"lazybear\", False)\n        squeeze_name  \"\"\n        if squeeze:\n            squeezes  self.df.ta.squeeze(lazybearlazybear, detailedTrue, appendTrue)\n            squeeze_name  squeezes.name\n\n        ama  kwargs.pop(\"archermas\", False)\n        ama_name  \"\"\n        if ama:\n            amas  self.df.ta.amat(appendTrue)\n            ama_name  amas.name\n\n        aobv  kwargs.pop(\"archerobv\", False)\n        aobv_name  \"\"\n        if aobv:\n            aobvs  self.df.ta.aobv(appendTrue)\n            aobv_name  aobvs.name\n\n        treturn  kwargs.pop(\"trendreturn\", False)\n        if treturn:\n            # Long Trend requires Series Comparison (<. <,  >, >)\n            # or Trade Logic that yields trends in binary.\n            default_long  self.df[\"SMA_10\"] > self.df[\"SMA_20\"]\n            long_trend  kwargs.pop(\"long_trend\", default_long)\n            if not isinstance(long_trend, pd.Series):\n                raise(f\"[X] Must be a Series that has boolean values or values of 0s and 1s\")\n            short_trend  ~long_trend # Opposite/Inverse\n            self.df[\"TR\"]  ta.trend_return(self.df[\"close\"], long_trend).iloc[:,1]\n\n        # Pad and trim Chart\n        self._right_pad_df(rpad)\n        mpfdf  self.df.tail(self.config[\"last\"])\n        mpfdf_columns  list(self.df.columns)\n\n        # BEGIN: Custom TA Plots and Panels\n        # Modify the area below \n        taplots  [] # Holds all the additional plots\n\n        # Panel 0: Price Overlay\n        if linreg_name in mpfdf_columns:\n            taplots + [mpf.make_addplot(mpfdf[linreg_name], typekwargs.pop(\"linreg_type\", \"line\"), colorkwargs.pop(\"linreg_color\", \"black\"), linestyle\"-.\", width1.2, panel0)]\n\n        if midpoint_name in mpfdf_columns:\n            taplots + [mpf.make_addplot(mpfdf[midpoint_name], typekwargs.pop(\"midpoint_type\", \"scatter\"), colorkwargs.pop(\"midpoint_color\", \"fuchsia\"), width0.4, panel0)]\n\n        if ohlc4_name in mpfdf_columns:\n            taplots + [mpf.make_addplot(mpfdf[ohlc4_name], ylabelohlc4_name, typekwargs.pop(\"ohlc4_type\", \"scatter\"), colorkwargs.pop(\"ohlc4_color\", \"blue\"), alpha0.85, width0.4, panel0)]\n\n        if self.strategy.name  ta.CommonStrategy.name:\n            total_sma  0 # Check if all the overlap indicators exists before adding plots\n            for c in [\"SMA_10\", \"SMA_20\", \"SMA_50\", \"SMA_200\"]:\n                if c in mpfdf_columns: total_sma ",
        "AgentRunResult(output='Parte final do notebook examples/example.ipynb, localizado na raiz/em examples. Demonstra visualizações com múltiplos indicadores usando pandas-ta e mplfinance: MACD, RSI, SMA, OBV, ZScore, Squeeze, Trend Return.')\nexamples/example.ipynb - Parte (2/2)\n+ 1\n                else: print(f\"[X] Indicator: {c} missing!\")\n            if total_sma  4:\n                ta_smas  [\n                    mpf.make_addplot(mpfdf[\"SMA_10\"], color\"green\", width1.5, panel0),\n                    mpf.make_addplot(mpfdf[\"SMA_20\"], color\"orange\", width2, panel0),\n                    mpf.make_addplot(mpfdf[\"SMA_50\"], color\"red\", width2, panel0),\n                    mpf.make_addplot(mpfdf[\"SMA_200\"], color\"maroon\", width3, panel0),\n                ]\n                taplots + ta_smas\n\n        if len(ama_name):\n            amat_sr_  mpfdf[amas.columns[-1]][mpfdf[amas.columns[-1]] > 0]\n            amat_sr  amat_sr_.index.to_list()\n        else:\n            amat_sr  None\n\n        # Panel 1: If volumeTrue, the add the VOL MA. Since we know there is only one, we immediately pop it.\n        if self.config[\"volume\"]:\n            volma  [x for x in list(self.df.columns) if x.startswith(\"VOL_\")].pop()\n            max_vol  mpfdf[\"volume\"].max()\n            ta_volume  [mpf.make_addplot(mpfdf[volma], color\"red\", width2, panel1, ylim(-.2 * max_vol, 1.5 * max_vol))]\n            taplots + ta_volume\n\n        # Panels 2 - 9\n        common_plot_ratio  (3,)\n\n        if len(aobv_name):\n            _p  kwargs.pop(\"aobv_percenty\", 0.2)\n            aobv_ylim  ta_ylim(mpfdf[aobvs.columns[0]], _p)\n            taplots + [\n                mpf.make_addplot(mpfdf[aobvs.columns[0]], ylabelaobv_name, color\"black\", width1.5, panelcpanel(), ylimaobv_ylim),\n                mpf.make_addplot(mpfdf[aobvs.columns[2]], color\"silver\", width1, panelcpanel(), ylimaobv_ylim),\n                mpf.make_addplot(mpfdf[aobvs.columns[3]], color\"green\", width1, panelcpanel(), ylimaobv_ylim),\n                mpf.make_addplot(mpfdf[aobvs.columns[4]], color\"red\", width1.2, panelcpanel(), ylimaobv_ylim),\n            ]\n            self.mpfchart[\"plot_ratios\"] + common_plot_ratio # Required to add a new Panel\n\n        if clr_name in mpfdf_columns:\n            _p  kwargs.pop(\"clr_percenty\", 0.1)\n            clr_ylim  ta_ylim(mpfdf[clr_name], _p)\n\n            taplots + [mpf.make_addplot(mpfdf[clr_name], ylabelclr_name, color\"black\", width1.5, panelcpanel(), ylimclr_ylim)]\n            if (1 - _p) * mpfdf[clr_name].min() < 0 and (1 + _p) * mpfdf[clr_name].max() > 0:\n                taplots + [mpf.make_addplot(mpfdf[\"0\"], color\"gray\", width1.2, panelcpanel(), ylimclr_ylim)]\n            self.mpfchart[\"plot_ratios\"] + common_plot_ratio # Required to add a new Panel\n\n        if rsi_name in mpfdf_columns:\n            rsi_ylim  (0, 100)\n            taplots + [\n                mpf.make_addplot(mpfdf[rsi_name], ylabelrsi_name, colorkwargs.pop(\"rsi_color\", \"black\"), width1.5, panelcpanel(), ylimrsi_ylim),\n                mpf.make_addplot(mpfdf[\"20\"], color\"green\", width1, panelcpanel(), ylimrsi_ylim),\n                mpf.make_addplot(mpfdf[\"50\"], color\"gray\", width0.8, panelcpanel(), ylimrsi_ylim),\n                mpf.make_addplot(mpfdf[\"80\"], color\"red\", width1, panelcpanel(), ylimrsi_ylim),\n            ]\n            self.mpfchart[\"plot_ratios\"] + common_plot_ratio # Required to add a new Panel\n        \n        if macd_name in mpfdf_columns:\n            _p  kwargs.pop(\"macd_percenty\", 0.15)\n            macd_ylim  ta_ylim(mpfdf[macd_name], _p)\n            taplots + [\n                mpf.make_addplot(mpfdf[macd_name], ylabelmacd_name, color\"black\", width1.5, panelcpanel()),#, ylimmacd_ylim),\n                mpf.make_addplot(mpfdf[macds.columns[-1]], color\"blue\", width1.1, panelcpanel()),#, ylimmacd_ylim),\n                mpf.make_addplot(mpfdf[macds.columns[1]], type\"bar\", alpha0.8, color\"dimgray\", width0.8, panelcpanel()),#, ylimmacd_ylim),\n                mpf.make_addplot(mpfdf[\"0\"], color\"black\", width1.2, panelcpanel()),#, ylimmacd_ylim),\n            ]\n            self.mpfchart[\"plot_ratios\"] + common_plot_ratio # Required to add a new Panel            \n\n        if zs_name in mpfdf_columns:\n            _p  kwargs.pop(\"zascore_percenty\", 0.2)\n            zs_ylim  ta_ylim(mpfdf[zs_name], _p)\n            taplots + [\n                mpf.make_addplot(mpfdf[zs_name], ylabelzs_name, color\"black\", width1.5, panelcpanel(), ylimzs_ylim),\n                mpf.make_addplot(mpfdf[\"-3\"], color\"red\", width1.2, panelcpanel(), ylimzs_ylim),\n                mpf.make_addplot(mpfdf[\"-2\"], color\"orange\", width1, panelcpanel(), ylimzs_ylim),\n                mpf.make_addplot(mpfdf[\"-1\"], color\"silver\", width1, panelcpanel(), ylimzs_ylim),\n                mpf.make_addplot(mpfdf[\"0\"], color\"black\", width1.2, panelcpanel(), ylimzs_ylim),\n                mpf.make_addplot(mpfdf[\"1\"], color\"silver\", width1, panelcpanel(), ylimzs_ylim),\n                mpf.make_addplot(mpfdf[\"2\"], color\"orange\", width1, panelcpanel(), ylimzs_ylim),\n                mpf.make_addplot(mpfdf[\"3\"], color\"red\", width1.2, panelcpanel(), ylimzs_ylim)\n            ]\n            self.mpfchart[\"plot_ratios\"] + common_plot_ratio # Required to add a new Panel\n\n        if squeeze_name in mpfdf_columns:\n            _p  kwargs.pop(\"squeeze_percenty\", 0.6)\n            sqz_ylim  ta_ylim(mpfdf[squeeze_name], _p)\n            taplots + [\n                mpf.make_addplot(mpfdf[squeezes.columns[-4]], type\"bar\", color\"lime\", alpha0.65, width0.8, panelcpanel(), ylimsqz_ylim),\n                mpf.make_addplot(mpfdf[squeezes.columns[-3]], type\"bar\", color\"green\", alpha0.65, width0.8, panelcpanel(), ylimsqz_ylim),\n                mpf.make_addplot(mpfdf[squeezes.columns[-2]], type\"bar\", color\"maroon\", alpha0.65, width0.8, panelcpanel(), ylimsqz_ylim),\n                mpf.make_addplot(mpfdf[squeezes.columns[-1]], type\"bar\", color\"red\", alpha0.65, width0.8, panelcpanel(), ylimsqz_ylim),\n                mpf.make_addplot(mpfdf[\"0\"], color\"black\", width1.2, panelcpanel(), ylimsqz_ylim),\n                mpf.make_addplot(mpfdf[squeezes.columns[4]], ylabelsqueeze_name, color\"green\", width2, panelcpanel(), ylimsqz_ylim),\n                mpf.make_addplot(mpfdf[squeezes.columns[5]], color\"red\", width1.8, panelcpanel(), ylimsqz_ylim),\n            ]\n            self.mpfchart[\"plot_ratios\"] + common_plot_ratio # Required to add a new Panel\n\n        if treturn:\n            _p  kwargs.pop(\"treturn_percenty\", 0.33)\n            treturn_ylim  ta_ylim(mpfdf[\"TR\"], _p)\n            taplots + [\n                mpf.make_addplot(mpfdf[\"TR\"], ylabel\"Trend Return\", type\"bar\", color\"green\", alpha0.45, width0.8, panelcpanel(), ylimtreturn_ylim),\n                mpf.make_addplot(mpfdf[\"TR\"], color\"black\", width1.3, panelcpanel(), ylimtreturn_ylim),\n                mpf.make_addplot(mpfdf[\"0\"], color\"black\", width1, panelcpanel(), ylimtreturn_ylim),\n            ]\n            self.mpfchart[\"plot_ratios\"] + common_plot_ratio # Required to add a new Panel\n\n            _p  kwargs.pop(\"cstreturn_percenty\", 0.33)\n#             trcs  mpfdf[\"TR\"].cumsum()\n            trcs  mpfdf[\"close\"] / mpfdf[\"close\"].iloc[0]\n            treturncs_ylim  ta_ylim(trcs, _p)\n            taplots + [\n                mpf.make_addplot(trcs, ylabel\"Trend B&H\", type\"bar\", color\"green\", alpha0.45, width0.8, panelcpanel(), ylimtreturncs_ylim),\n                mpf.make_addplot(mpfdf[\"0\"], color\"black\", width1, panelcpanel(), ylimtreturncs_ylim),\n            ]\n            self.mpfchart[\"plot_ratios\"] + common_plot_ratio # Required to add a new Panel\n\n        # END: Custom TA Plots and Panels\n\n        if self.verbose:\n            additional_ta  []\n            chart_title   f\"{chart_title} [{self.strategy.name}] (last {self.config['last']} bars)\"\n            chart_title + f\"\\nSince {mpfdf.index[0]} till {mpfdf.index[-1]}\"\n            if len(linreg_name) > 0: additional_ta.append(linreg_name)\n            if len(midpoint_name) > 0: additional_ta.append(midpoint_name)\n            if len(ohlc4_name) > 0: additional_ta.append(ohlc4_name)\n            if len(additional_ta) > 0:\n                chart_title + f\"\\nIncluding: {', '.join(additional_ta)}\"\n\n        if amat_sr:\n            vlines_  dict(vlinesamat_sr, alpha0.1, colors\"red\")\n        else:\n            # Hidden because vlines needs valid arguments even if None \n            vlines_  dict(vlinesmpfdf.index[0], alpha0, colors\"white\")\n\n        # Create Final Plot\n        mpf.plot(mpfdf,\n            titlechart_title,\n            typeself.mpfchart[\"type\"],\n            styleself.mpfchart[\"style\"],\n            datetime_format\"%-m/%-d/%Y\",\n            volumeself.config[\"volume\"],\n            figsizeself.mpfchart[\"figsize\"],\n            tight_layoutself.mpfchart[\"tight_layout\"],\n            scale_paddingself.mpfchart[\"scale_padding\"],\n            panel_ratiosself.mpfchart[\"plot_ratios\"], # This key needs to be update above if adding more panels\n            xrotationself.mpfchart[\"xrotation\"],\n            update_width_configself.mpfchart[\"width_config\"],\n            show_nontradingself.mpfchart[\"non_trading\"],\n            vlinesvlines_,\n            addplottaplots\n        )\n        \n        self._attribution()\n\n\"\"\"\n### Charting Example\n#### Play with the parameters to see different charts and results\n* This is an example chart so it's not perfect. Enough to get started with common and uncommon plots.\n* There is a maximum of 10 Panels. In this example, panels 0 and 1 are reserved for Price and Volume respectively.\n    * \n\"\"\"\n\n# Used for example Trend Return Long Trend Below\nmacd_  ta.macd(closedf)\nmacdh  macd_[macd_.columns[1]]\n\nChart(df,\n    # style: which mplfinance chart style to use. Added \"random\" as an option.\n    # rpad: how many bars to leave empty on the right of the chart\n    style\"yahoo\", titleticker, lastrecent_bars(df), rpad10,\n    \n    # Overlap Indicators\n    linregTrue, midpointFalse, ohlc4False, archermasTrue,\n    \n    # Example Indicators with default parameters\n    volumeTrue, rsiTrue, clrTrue, macdTrue, zscoreFalse, squeezeFalse, lazybearFalse,\n\n    # Archer OBV and OBV MAs (https://www.tradingview.com/script/Co1ksara-Trade-Archer-On-balance-Volume-Moving-Averages-v1/)\n    archerobvFalse,\n\n    # Create trends and see their returns\n    trendreturnFalse,\n    # Example Trends or create your own. Trend must yield Booleans\n    long_trendta.sma(closedf,10) > ta.sma(closedf,20), # trend: sma(close,10) > sma(close,20) [Default Example]\n#     long_trendclosedf > ta.ema(closedf,5), # trend: close > ema(close,5)\n#     long_trendta.sma(closedf,10) > ta.ema(closedf,50), # trend: sma(close,10) > ema(close,50)\n#     long_trendmacdh > 0, # trend: macd hist > 0\n#     long_trendta.increasing(ta.sma(ta.rsi(closedf), 10), 5, asintFalse), # trend: rising sma(rsi, 10) for the previous 5 periods\n    show_nontradingFalse, # Intraday use if needed\n    verboseTrue, # More detail\n)\n# Output:\n#   [i] Loaded SPY(5394, 33)\n\n#   [+] Strategy: Common Price and Volume SMAs\n\n#   [i] Indicator arguments: {'append': True}\n\n#   [i] Multiprocessing 5 indicators with 7 chunks and 8/8 cpus.\n\n#   [i] Total indicators: 5\n\n#   [i] Columns added: 5\n\n#   [i] Last Run: Saturday April 10, 2021, NYSE: 5:38:28, Local: 9:38:28 PDT, Day 100/365 (27.0%)\n\n#   <Figure size 1200x1000 with 10 Axes>\n#   \n\n#   Pandas v: 1.2.2 [pip install pandas] https://github.com/pandas-dev/pandas\n\n#   Data from AlphaVantage v: 1.0.19 [pip install alphaVantage-api] http://www.alphavantage.co https://github.com/twopirllc/AlphaVantageAPI\n\n#   Technical Analysis with Pandas TA v: 0.2.64b0 [pip install pandas_ta] https://github.com/twopirllc/pandas-ta\n\n#   Charts by Matplotlib Finance v: 0.12.7a5 [pip install mplfinance] https://github.com/matplotlib/mplfinance\n\n#   \n\n#   <__main__.Chart at 0x12ffc83d0>\n\n\"\"\"\n## Indicator Examples\n* Examples of simple and complex indicators.  Most indicators return a Series, while a few return DataFrames.\n* All indicators can be called one of three ways. Either way, they return the result.\n\n### Three ways to use pandas_ta\n1. Stand Alone like TA-Lib  ta.**indicator**(*kwargs*).\n2. As a DataFrame Extension like df.ta.**indicator**(*kwargs*).  Where df is a DataFrame with columns named \"open\", \"high\", \"low\", \"close, \"volume\" for simplicity.\n3. Similar to #2, but by calling: df.ta(kind\"**indicator**\", *kwargs*).\n\"\"\"\n\n\"\"\"\n### Cumulative Log Return\n\"\"\"\n\nclr_ma_length  8\nclrdf  df.ta.log_return(cumulativeTrue, appendTrue)\nclrmadf  ta.ema(clrdf, lengthclr_ma_length)\nclrxdf  pd.DataFrame({f\"{clrdf.name}\": clrdf, f\"{clrmadf.name}({clrdf.name})\": clrmadf})\nclrxdf.tail(recent_bars(df)).plot(figsizeind_size, colorcolors(\"BkBl\"), linewidth1, titlectitle(clrdf.name, tickerticker, lengthrecent_bars(df)), gridTrue)\n# Output:\n#   <AxesSubplot:title{'center':'SPY: CUMLOGRET_1 from 2020-04-09 00:00:00 to 2021-04-09 00:00:00 (252)'}, xlabel'date'>\n#   <Figure size 1600x325 with 1 Axes>\n\n\"\"\"\n### MACD\n\"\"\"\n\nmacddf  df.ta.macd(fast8, slow21, signal9, min_periodsNone, appendTrue)\nmacddf[[macddf.columns[0], macddf.columns[2]]].tail(recent_bars(df)).plot(figsize(16, 2), colorcolors(\"BkBl\"), linewidth1.3)\nmacddf[macddf.columns[1]].tail(recent_bars(df)).plot.area(figsizeind_size, stackedFalse, color[\"silver\"], linewidth1, titlectitle(macddf.name, tickerticker, lengthrecent_bars(df)), gridTrue).axhline(y0, color\"black\", lw1.1)\n# Output:\n#   <matplotlib.lines.Line2D at 0x130be2700>\n#   <Figure size 1600x325 with 1 Axes>\n\n\"\"\"\n### ZScore\n\"\"\"\n\nzscoredf  df.ta.zscore(length30, appendTrue)\nzcolors  [\"darkgreen\", \"green\", \"silver\", \"silver\", \"red\", \"maroon\", \"black\"]\nzcols  df[[\"-4\", \"-3\", \"-2\", \"2\", \"3\", \"4\", zscoredf.name]].tail(recent_bars(df))\nzcols.plot(figsizeind_size, colorzcolors, linewidth1.2, titlectitle(zscoredf.name, tickerticker, lengthrecent_bars(df)), gridTrue).axhline(y0, color\"black\", lw1.1)\n# Output:\n#   <matplotlib.lines.Line2D at 0x1308b2cd0>\n#   <Figure size 1600x325 with 1 Axes>\n\n# Now Volume Z Score\nzvscoredf  df.ta.zscore(close\"volume\", length30, prefix\"VOL\", appendTrue)\nzcolors  [\"darkgreen\", \"green\", \"silver\", \"silver\", \"red\", \"maroon\", \"black\"]\nzvcols  df[[\"-4\", \"-3\", \"-2\", \"2\", \"3\", \"4\", zvscoredf.name]].tail(recent_bars(df))\nzvcols.plot(figsizeind_size, colorzcolors, linewidth1.2, titlectitle(zvscoredf.name, tickerticker, lengthrecent_bars(df)), gridTrue).axhline(y0, color\"black\", lw1.1)\n# Output:\n#   <matplotlib.lines.Line2D at 0x130cb4580>\n#   <Figure size 1600x325 with 1 Axes>\n\n\"\"\"\n# New Features\n\"\"\"\n\n\"\"\"\n## Squeeze Indicator (John Carter and Lazybear Versions)\nSqueeze Indicator (__squeeze__)\n\"\"\"\n\n# help(ta.squeeze)\n\nChart(df, style\"yahoo\", titleticker, verboseFalse,\n    lastrecent_bars(df), rpad10, clrTrue, squeezeTrue,\n    show_nontradingFalse, # Intraday use if needed\n)\n# Output:\n#   <Figure size 1200x1000 with 8 Axes>\n#   \n\n#   Pandas v: 1.2.2 [pip install pandas] https://github.com/pandas-dev/pandas\n\n#   Data from AlphaVantage v: 1.0.19 [pip install alphaVantage-api] http://www.alphavantage.co https://github.com/twopirllc/AlphaVantageAPI\n\n#   Technical Analysis with Pandas TA v: 0.2.64b0 [pip install pandas_ta] https://github.com/twopirllc/pandas-ta\n\n#   Charts by Matplotlib Finance v: 0.12.7a5 [pip install mplfinance] https://github.com/matplotlib/mplfinance\n\n#   \n\n#   <__main__.Chart at 0x130ceb6d0>\n\n\"\"\"\n### Lazybear's TradingView Squeeze\n\"\"\"\n\nChart(df, style\"yahoo\", titleticker, verboseFalse,\n    lastrecent_bars(df), rpad10, clrTrue, squeezeTrue, lazybearTrue,\n    show_nontradingFalse, # Intraday use if needed\n)\n# Output:\n#   <Figure size 1200x1000 with 8 Axes>\n#   \n\n#   Pandas v: 1.2.2 [pip install pandas] https://github.com/pandas-dev/pandas\n\n#   Data from AlphaVantage v: 1.0.19 [pip install alphaVantage-api] http://www.alphavantage.co https://github.com/twopirllc/AlphaVantageAPI\n\n#   Technical Analysis with Pandas TA v: 0.2.64b0 [pip install pandas_ta] https://github.com/twopirllc/pandas-ta\n\n#   Charts by Matplotlib Finance v: 0.12.7a5 [pip install mplfinance] https://github.com/matplotlib/mplfinance\n\n#   \n\n#   <__main__.Chart at 0x130d2f190>\n\n\"\"\"\n### Archer Moving Averages Trends\nArcher Moving Average Trends (__amat__) returns the long and short run trends of fast and slow moving averages.\n* The _pink_ background, on the Price chart, is when Archer MAs are bearish. Conversely, a _white_ background is bullish\n\"\"\"\n\nChart(df, style\"yahoo\", titleticker, verboseFalse,\n    lastrecent_bars(df), rpad10,\n    volumeTrue, midpointFalse, ohlc4False,\n    rsiFalse, clrTrue, macdFalse, zscoreFalse, squeezeFalse, lazybearFalse,\n    archermasTrue, archerobvFalse,\n    show_nontradingFalse, # Intraday use if needed\n)\n# Output:\n#   <Figure size 1200x1000 with 6 Axes>\n#   \n\n#   Pandas v: 1.2.2 [pip install pandas] https://github.com/pandas-dev/pandas\n\n#   Data from AlphaVantage v: 1.0.19 [pip install alphaVantage-api] http://www.alphavantage.co https://github.com/twopirllc/AlphaVantageAPI\n\n#   Technical Analysis with Pandas TA v: 0.2.64b0 [pip install pandas_ta] https://github.com/twopirllc/pandas-ta\n\n#   Charts by Matplotlib Finance v: 0.12.7a5 [pip install mplfinance] https://github.com/matplotlib/mplfinance\n\n#   \n\n#   <__main__.Chart at 0x13147fd30>\n\n\"\"\"\n### Archer On Balance Volume\nArcher On Balance Volume (__aobv__) returns a DataFrame of OBV, OBV min and max, fast and slow MAs of OBV, and the long and short run trends of the two OBV MAs.\n* On the chart below, only **OBV**, **OBV min**, _fast_ and _slow_ **OBV MAs**.\n* Not on the chart are: **OBV LR** and **OBV SR** trends.\n\"\"\"\n\nChart(df, style\"yahoo\", titleticker, verboseFalse,\n    lastrecent_bars(df), rpad10,\n    volumeTrue, midpointFalse, ohlc4False,\n    rsiFalse, clrTrue, macdFalse, zscoreFalse, squeezeFalse, lazybearFalse,\n    archermasFalse, archerobvTrue,\n    show_nontradingFalse, # Intraday use if needed\n)\n# Output:\n#   <Figure size 1200x1000 with 8 Axes>\n#   \n\n#   Pandas v: 1.2.2 [pip install pandas] https://github.com/pandas-dev/pandas\n\n#   Data from AlphaVantage v: 1.0.19 [pip install alphaVantage-api] http://www.alphavantage.co https://github.com/twopirllc/AlphaVantageAPI\n\n#   Technical Analysis with Pandas TA v: 0.2.64b0 [pip install pandas_ta] https://github.com/twopirllc/pandas-ta\n\n#   Charts by Matplotlib Finance v: 0.12.7a5 [pip install mplfinance] https://github.com/matplotlib/mplfinance\n\n#   \n\n#   <__main__.Chart at 0x130136f70>\n\n\"\"\"\n# Disclaimer\n* All investments involve risk, and the past performance of a security, industry, sector, market, financial product, trading strategy, or individual’s trading does not guarantee future results or returns. Investors are fully responsible for any investment decisions they make. Such decisions should be based solely on an evaluation of their financial circumstances, investment objectives, risk tolerance, and liquidity needs.\n\n* Any opinions, news, research, analyses, prices, or other information offered is provided as general market commentary, and does not constitute investment advice. I will not accept liability for any loss or damage, including without limitation any loss of profit, which may arise directly or indirectly from use of or reliance on such information.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Este arquivo está localizado em `examples/watchlist.py` e fornece uma implementação de exemplo da classe `Watchlist`, usada para baixar, armazenar e aplicar análise técnica a dados financeiros de ativos como ações. Ele utiliza bibliotecas como `pandas`, `pandas_ta`, `alphaVantageAPI`, `yfinance`, entre outras. O conteúdo cobre tópicos como definição de estratégias de análise técnica, download de dados de fontes como AlphaVantage e Yahoo Finance, manipulação de DataFrames e visualização de gráficos.')\nexamples/watchlist.py\n\n# -*- coding: utf-8 -*-\nimport datetime as dt\n\nfrom pathlib import Path\nfrom random import random\nfrom typing import Tuple\n\nimport pandas as pd  # pip install pandas\nfrom pandas_datareader import data as pdr\nimport yfinance as yf\n\nyf.pdr_override() # < that's all it takes :-)\n\nfrom numpy import arange as npArange\nfrom numpy import append as npAppend\nfrom numpy import array as npArray\n\nimport alphaVantageAPI as AV # pip install alphaVantage-api\nimport pandas_ta as ta # pip install pandas_ta\n\n\ndef colors(colors: str  None, default: str  \"GrRd\"):\n    aliases  {\n        # Pairs\n        \"GrRd\": [\"green\", \"red\"],\n        \"RdGr\": [\"red\", \"green\"],\n        \"BkGy\": [\"black\", \"gray\"],\n        \"BkSv\": [\"black\", \"silver\"],\n        \"BkPr\": [\"black\", \"purple\"],\n        \"BkBl\": [\"black\", \"blue\"],\n        \"GyBk\": [\"gray\", \"black\"],\n        \"GySv\": [\"gray\", \"silver\"],\n        \"GyPr\": [\"gray\", \"purple\"],\n        \"GyBl\": [\"gray\", \"blue\"],\n        \"SvGy\": [\"silver\", \"gray\"],\n        \"FcLi\": [\"fuchsia\", \"lime\"],\n        # Triples\n        \"BkGrRd\": [\"black\", \"green\", \"red\"],\n        \"BkBlPr\": [\"black\", \"blue\", \"purple\"],\n        \"GrOrRd\": [\"green\", \"orange\", \"red\"],\n        \"RdOrGr\": [\"red\", \"orange\", \"green\"],\n        # Quads\n        \"BkGrOrRd\": [\"black\", \"green\", \"orange\", \"red\"],\n        # Quints\n        \"BkGrOrRdMr\": [\"black\", \"green\", \"orange\", \"red\", \"maroon\"],\n        # Indicators\n        \"bbands\": [\"blue\", \"navy\", \"blue\"],\n        \"kc\": [\"purple\", \"fuchsia\", \"purple\"],\n    }\n    aliases[\"default\"]  aliases[default]\n    if colors in aliases.keys():\n        return aliases[colors]\n    return aliases[\"default\"]\n\n\nclass Watchlist(object):\n    \"\"\"\n    # Watchlist Class (** This is subject to change! **)\n    A simple Class to load/download financial market data and automatically\n    apply Technical Analysis indicators with a Pandas TA Strategy.\n\n    Default Strategy: pandas_ta.CommonStrategy\n\n    ## Package Support:\n    ### Data Source (Default: AlphaVantage)\n    - AlphaVantage (pip install alphaVantage-api).\n    - Python Binance (pip install python-binance). # Future Support\n    - Yahoo Finance (pip install yfinance). # Almost Supported\n\n    # Technical Analysis:\n    - Pandas TA (pip install pandas_ta)\n\n    ## Required Arguments:\n    - tickers: A list of strings containing tickers. Example: [\"SPY\", \"AAPL\"]\n    \"\"\"\n\n    def __init__(self,\n        tickers: list, tf: str  None, name: str  None,\n        strategy: ta.Strategy  None, ds_name: str  \"av\", **kwargs,\n    ):\n        self.verbose  kwargs.pop(\"verbose\", False)\n        self.debug  kwargs.pop(\"debug\", False)\n        self.timed  kwargs.pop(\"timed\", False)\n\n        self.tickers  tickers\n        self.tf  tf\n        self.name  name if isinstance(name, str) else f\"Watch: {', '.join(tickers)}\"\n        self.data  None\n        self.kwargs  kwargs\n        self.strategy  strategy\n\n        self._init_data_source(ds_name)\n\n\n    def _init_data_source(self, ds: str) -> None:\n        self.ds_name  ds.lower() if isinstance(ds, str) else \"av\"\n\n        # Default: AlphaVantage\n        AVkwargs  {\"api_key\": \"YOUR API KEY\", \"clean\": True, \"export\": True, \"output_size\": \"full\", \"premium\": False}\n        self.av_kwargs  self.kwargs.pop(\"av_kwargs\", AVkwargs)\n        self.ds  AV.AlphaVantage(**self.av_kwargs)\n        self.file_path  self.ds.export_path\n\n        if self.ds_name  \"yahoo\":\n            self.ds  yf\n\n    def _drop_columns(self, df: pd.DataFrame, cols: list  None) -> pd.DataFrame:\n        if cols is None or not isinstance(cols, list):\n            cols  [\"Unnamed: 0\", \"date\", \"split_coefficient\", \"dividend\"]\n        else: cols\n        \"\"\"Helper methods to drop columns silently.\"\"\"\n        df_columns  list(df.columns)\n        if any(_ in df_columns for _ in cols):\n            if self.debug:\n                print(f\"[i] Possible columns dropped: {', '.join(cols)}\")\n            df  df.drop(cols, axis1, errors\"ignore\")\n        return df\n\n    def _load_all(self, **kwargs) -> dict:\n        \"\"\"Updates the Watchlist's data property with a dictionary of DataFrames\n        keyed by ticker.\"\"\"\n        if (self.tickers is not None and isinstance(self.tickers, list) and\n                len(self.tickers)):\n            self.data  {ticker: self.load(ticker, **kwargs) for ticker in self.tickers}\n            return self.data\n\n    def _plot(self, df, mas:bool  True, constants:bool  False, **kwargs) -> None:\n\n        if constants:\n            chart_lines  npAppend(npArange(-5, 6, 1), npArange(-100, 110, 10))\n            df.ta.constants(True, chart_lines) # Adding the constants for the charts\n            df.ta.constants(False, npArray([-60, -40, 40, 60])) # Removing some constants from the DataFrame\n            if self.verbose: print(f\"[i] {df.ticker} constants added.\")\n\n        if ta.Imports[\"matplotlib\"]:\n            _exchange  kwargs.pop(\"exchange\", \"NYSE\")\n            _time  ta.get_time(_exchange, to_stringTrue)\n            _kind  kwargs.pop(\"plot_kind\", None)\n            _figsize  kwargs.pop(\"figsize\", (16, 10))\n            _colors  kwargs.pop(\"figsize\", [\"black\", \"green\", \"orange\", \"red\", \"maroon\"])\n            _grid  kwargs.pop(\"grid\", True)\n            _alpha  kwargs.pop(\"alpha\", 1)\n            _last  kwargs.pop(\"last\", 252)\n            _title  kwargs.pop(\"title\", f\"{df.ticker}   {_time}   [{self.ds_name}]\")\n\n            col  kwargs.pop(\"close\", \"close\")\n            if mas:\n                # df.ta.strategy(self.strategy, appendTrue)\n                price  df[[col, \"SMA_10\", \"SMA_20\", \"SMA_50\", \"SMA_200\"]]\n            else:\n                price  df[col]\n\n            if _kind is None:\n                price.tail(_last).plot(figsize_figsize, color_colors, linewidth2, title_title, grid_grid, alpha_alpha)\n            else:\n                print(f\"[X] Plot kind not implemented\")\n                return\n\n\n    def load(self,\n        ticker: str  None, tf: str  None, index: str  \"date\",\n        drop: list  [], plot: bool  False, **kwargs\n    ) -> pd.DataFrame:\n        \"\"\"Loads or Downloads (if a local csv does not exist) the data from the\n        Data Source. When successful, it returns a Data Frame for the requested\n        ticker. If no tickers are given, it loads all the tickers.\"\"\"\n\n        tf  self.tf if tf is None else tf.upper()\n        if ticker is not None and isinstance(ticker, str):\n            ticker  str(ticker).upper()\n        else:\n            print(f\"[!] Loading All: {', '.join(self.tickers)}\")\n            self._load_all(**kwargs)\n            return\n\n        filename_  f\"{ticker}_{tf}.csv\"\n        current_file  Path(self.file_path) / filename_\n\n        # Load local or from Data Source\n        if current_file.exists():\n            file_loaded  f\"[i] Loaded {ticker}[{tf}]: {filename_}\"\n            # if self.ds_name  \"av\":\n            if self.ds_name in [\"av\", \"yahoo\"]:\n                df  pd.read_csv(current_file, index_col0)\n                if not df.ta.datetime_ordered:\n                    df  df.set_index(pd.DatetimeIndex(df.index))\n                print(file_loaded)\n            else:\n                print(f\"[X] {filename_} not found in {Path(self.file_path)}\")\n                return\n        else:\n            print(f\"[+] Downloading[{self.ds_name}]: {ticker}[{tf}]\")\n            if self.ds_name  \"av\":\n                df  self.ds.data(ticker, tf)\n                if not df.ta.datetime_ordered:\n                    df  df.set_index(pd.DatetimeIndex(df[index]))\n            if self.ds_name  \"yahoo\":\n                yf_data  self.ds.Ticker(ticker)\n                df  yf_data.history(period\"max\")\n                to_save  f\"{self.file_path}/{ticker}_{tf}.csv\"\n                print(f\"[+] Saving: {to_save}\")\n                df.to_csv(to_save)\n\n        # Remove select columns\n        df  self._drop_columns(df, drop)\n\n        if kwargs.pop(\"analyze\", True):\n            if self.debug: print(f\"[+] TA[{len(self.strategy.ta)}]: {self.strategy.name}\")\n            df.ta.strategy(self.strategy, timedself.timed, **kwargs)\n\n        df.ticker  ticker # Attach ticker to the DataFrame\n        df.tf  tf\n\n        if plot: self._plot(df, **kwargs)\n        return df\n\n    @property\n    def data(self) -> dict:\n        \"\"\"When not None, it contains a dictionary of DataFrames keyed by ticker. data  {\"SPY\": pd.DataFrame, ...}\"\"\"\n        return self._data\n\n    @data.setter\n    def data(self, value: dict) -> None:\n        # Later check dict has string keys and DataFrame values\n        if value is not None and isinstance(value, dict):\n            if self.verbose:\n                print(f\"[+] New data\")\n            self._data  value\n        else:\n            self._data  None\n\n    @property\n    def name(self) -> str:\n        \"\"\"The name of the Watchlist. Default: \"Watchlist: {Watchlist.tickers}\".\"\"\"\n        return self._name\n\n    @name.setter\n    def name(self, value: str) -> None:\n        if isinstance(value, str):\n            self._name  str(value)\n        else:\n            self._name  f\"Watchlist: {', '.join(self.tickers)}\"\n\n    @property\n    def strategy(self) -> ta.Strategy:\n        \"\"\"Sets a valid Strategy. Default: pandas_ta.CommonStrategy\"\"\"\n        return self._strategy\n\n    @strategy.setter\n    def strategy(self, value: ta.Strategy) -> None:\n        if value is not None and isinstance(value, ta.Strategy):\n            self._strategy  value\n        else:\n            self._strategy  ta.CommonStrategy\n\n    @property\n    def tf(self) -> str:\n        \"\"\"Alias for timeframe. Default: 'D'\"\"\"\n        return self._tf\n\n    @tf.setter\n    def tf(self, value: str) -> None:\n        if isinstance(value, str):\n            value  str(value)\n            self._tf  value\n        else:\n            self._tf  \"D\"\n\n    @property\n    def tickers(self) -> list:\n        \"\"\"tickers\n\n        If a string, it it converted to a list. Example: \"AAPL\" -> [\"AAPL\"]\n            * Does not accept, comma seperated strings.\n        If a list, checks if it is a list of strings.\n        \"\"\"\n        return self._tickers\n\n    @tickers.setter\n    def tickers(self, value: Tuple[list, str]) -> None:\n        if value is None:\n            print(f\"[X] {value} is not a value in Watchlist ticker.\")\n            return\n        elif isinstance(value, list) and [isinstance(_, str) for _ in value]:\n            self._tickers  list(map(str.upper, value))\n        elif isinstance(value, str):\n            self._tickers  [value.upper()]\n        self.name  self._tickers\n\n    @property\n    def verbose(self) -> bool:\n        \"\"\"Toggle the verbose property. Default: False\"\"\"\n        return self._verbose\n\n    @verbose.setter\n    def verbose(self, value: bool) -> None:\n        if isinstance(value, bool):\n            self._verbose  bool(value)\n        else:\n            self._verbose  False\n\n    def indicators(self, *args, **kwargs) -> any:\n        \"\"\"Returns the list of indicators that are available with Pandas Ta.\"\"\"\n        pd.DataFrame().ta.indicators(*args, **kwargs)\n\n    def __repr__(self) -> str:\n        s  f\"Watch(name'{self.name}', ds_name'{self.ds_name}', tickers[{len(self.tickers)}]'{', '.join(self.tickers)}', tf'{self.tf}', strategy[{self.strategy.total_ta()}]'{self.strategy.name}'\"\n        if self.data is not None:\n            s + f\", data[{len(self.data.keys())}])\"\n            return s\n        return s + \")\"\n\n\n\n\n"
    ],
    "setup.py": [
        "AgentRunResult(output='This is the root setup.py file that defines packaging and metadata for the Pandas TA library. It configures modules, dependencies, and classifiers for a technical analysis extension for pandas.')\nsetup.py\n\n# -*- coding: utf-8 -*-\nfrom distutils.core import setup\n\nlong_description  \"An easy to use Python 3 Pandas Extension with 130+ Technical Analysis Indicators. Can be called from a Pandas DataFrame or standalone like TA-Lib. Correlation tested with TA-Lib.\"\n\nsetup(\n    name\"pandas_ta\",\n    packages[\n        \"pandas_ta\",\n        \"pandas_ta.candles\",\n        \"pandas_ta.cycles\",\n        \"pandas_ta.momentum\",\n        \"pandas_ta.overlap\",\n        \"pandas_ta.performance\",\n        \"pandas_ta.statistics\",\n        \"pandas_ta.trend\",\n        \"pandas_ta.utils\",\n        \"pandas_ta.volatility\",\n        \"pandas_ta.volume\"\n    ],\n    version\".\".join((\"0\", \"2\", \"67b\")),\n    descriptionlong_description,\n    long_descriptionlong_description,\n    author\"Kevin Johnson\",\n    author_email\"appliedmathkj@gmail.com\",\n    url\"https://github.com/twopirllc/pandas-ta\",\n    maintainer\"Kevin Johnson\",\n    maintainer_email\"appliedmathkj@gmail.com\",\n    # install_requires[\"pandas\"],\n    download_url\"https://github.com/twopirllc/pandas-ta.git\",\n    keywords[\"technical analysis\", \"trading\", \"python3\", \"pandas\"],\n    license\"The MIT License (MIT)\",\n    classifiers[\n        \"Development Status :: 4 - Beta\",\n        \"Programming Language :: Python :: 3.6\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Operating System :: OS Independent\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Natural Language :: English\",\n        \"Intended Audience :: Developers\",\n        \"Intended Audience :: Financial and Insurance Industry\",\n        \"Intended Audience :: Science/Research\",\n        \"Topic :: Office/Business :: Financial\",\n        \"Topic :: Office/Business :: Financial :: Investment\",\n        \"Topic :: Scientific/Engineering\",\n        \"Topic :: Scientific/Engineering :: Information Analysis\",\n    ],\n    package_data{\n        \"data\": [\"data/*.csv\"],\n    },\n    install_requires[\"pandas\"],\n    # List additional groups of dependencies here (e.g. development dependencies).\n    # You can install these using the following syntax, for example:\n    # $ pip install -e .[dev,test]\n    extras_require{\n        \"dev\": [\n            \"alphaVantage-api\", \"matplotlib\", \"mplfinance\", \"scipy\",\n            \"sklearn\", \"statsmodels\", \"stochastic\",\n            \"talib\", \"tqdm\", \"vectorbt\", \"yfinance\",\n        ],\n        \"test\": [\"ta-lib\"],\n    },\n)\n\n\n"
    ],
    "README.md": [
        "AgentRunResult(output='Context: Root README.md. This is the main documentation file for the Pandas TA project, a Python 3 library for technical analysis using Pandas.\\n\\nTopics/Technologies: Technical indicators (SMA, MACD, Bollinger Bands, etc.), installation/setup, usage examples, strategy creation with pandas-ta.Strategy class, DataFrame extensions, multiprocessing support, community contributions.')\nREADME.md - Parte (1/2)\nREADME.md\n\n<p align\"center\">\n  <a href\"https://github.com/twopirllc/pandas_ta\">\n    <img src\"images/logo.png\" alt\"Pandas TA\">\n  </a>\n</p>\n\nPandas TA - A Technical Analysis Library in Python 3\n\n\n[![Python Version](https://img.shields.io/pypi/pyversions/pandas_ta.svg)](https://pypi.org/project/pandas_ta/)\n[![PyPi Version](https://img.shields.io/pypi/v/pandas_ta.svg)](https://pypi.org/project/pandas_ta/)\n[![Package Status](https://img.shields.io/pypi/status/pandas_ta.svg)](https://pypi.org/project/pandas_ta/)\n[![Downloads](https://img.shields.io/pypi/dm/pandas_ta.svg?styleflat)](https://pypistats.org/packages/pandas_ta)\n[![Contributors](https://img.shields.io/badge/contributors-19-orange.svg?styleflat)](#contributors-)\n![Example Chart](/images/TA_Chart.png)\n\n\n_Pandas Technical Analysis_ (**Pandas TA**) is an easy to use library that leverages the Pandas library with more than 130 Indicators and Utility functions. Many commonly used indicators are included, such as: _Simple Moving Average_ (**sma**) _Moving Average Convergence Divergence_ (**macd**), _Hull Exponential Moving Average_ (**hma**), _Bollinger Bands_ (**bbands**), _On-Balance Volume_ (**obv**), _Aroon & Aroon Oscillator_ (**aroon**), _Squeeze_ (**squeeze**) and **_many more_**.\n\n<br/>\n\n# **Table of contents**\n\n<!--ts-->\n* [Features](#features)\n* [Installation](#installation)\n    * [Stable](#stable)\n    * [Latest Version](#latest-version)\n    * [Cutting Edge](#cutting-edge)\n* [Quick Start](#quick-start)\n* [Help](#help)\n* [Issues and Contributions](#issues-and-contributions)\n* [Programming Conventions](#programming-conventions)\n* [Pandas TA Strategies](#pandas-ta-strategies)\n    * [Types of Strategies](#types-of-strategies)\n* [DataFrame Properties](#dataframe-properties)\n* [DataFrame Methods](#dataframe-methods)\n* [Indicators by Category](#indicators-by-category)\n    * [Candles](#candles-3)\n    * [Cycles](#cycles-1)\n    * [Momentum](#momentum-37)\n    * [Overlap](#overlap-31)\n    * [Performance](#performance-4)\n    * [Statistics](#statistics-9)\n    * [Trend](#trend-15)\n    * [Utility](#utility-5)\n    * [Volatility](#volatility-13)\n    * [Volume](#volume-14)\n* [Performance Metrics](#performance-metrics)\n* [Changes](#changes)\n    * [General](#general)\n    * [Breaking Indicators](#breaking-indicators)\n    * [New Indicators](#new-indicators)\n    * [Updated Indicators](#updated-indicators)\n<!--te-->\n\n<!-- * [Specifying Strategies in **Pandas TA**](#specifying-strategies-in-pandas-ta) -->\n<!-- * [Multiprocessing](#multiprocessing) -->\n\n\n<br/>\n\n# **Features**\n\n* Has 130+ indicators and utility functions.\n* Indicators are tightly correlated with the de facto [TA Lib](https://mrjbq7.github.io/ta-lib/) if they share common indicators.\n* Have the need for speed? By using the DataFrame _strategy_ method, you get **multiprocessing** for free!\n* Easily add _prefixes_ or _suffixes_ or both to columns names. Useful for Custom Chained Strategies.\n* Example Jupyter Notebooks under the [examples](https://github.com/twopirllc/pandas-ta/tree/master/examples) directory, including how to create Custom Strategies using the new [__Strategy__ Class](https://github.com/twopirllc/pandas-ta/tree/master/examples/PandaTA_Strategy_Examples.ipynb)\n* Potential Data Leaks: **ichimoku** and **dpo**. See indicator list below for details.\n* **UNDER DEVELOPMENT:** Performance Metrics\n* **UNDER DEVELOPMENT:** Easy Downloading of _ohlcv_ data using [yfinance](https://github.com/ranaroussi/yfinance). See ```help(ta.ticker)``` and ```help(ta.yf)```\n\n<br/>\n\n**Installation**\n\n\nStable\n------\nThe ```pip``` version is the last most stable release. Version: *0.2.45b*\n```sh\n$ pip install pandas_ta\n```\n\nLatest Version\n--------------\nBest choice! Version: *0.2.67b*\n```sh\n$ pip install -U git+https://github.com/twopirllc/pandas-ta\n```\n\nCutting Edge\n------------\nThis is the _Development Version_ which could have bugs and other undesireable side effects. Use at own risk!\n```sh\n$ pip install -U git+https://github.com/twopirllc/pandas-ta.git@development\n```\n\n<br/>\n\n # **Quick Start**\n```python\nimport pandas as pd\nimport pandas_ta as ta\n\ndf  pd.DataFrame() # Empty DataFrame\n\n# Load data\ndf  pd.read_csv(\"path/to/symbol.csv\", sep\",\")\n# OR if you have yfinance installed\ndf  df.ta.ticker(\"aapl\")\n\n# VWAP requires the DataFrame index to be a DatetimeIndex.\n# Replace \"datetime\" with the appropriate column from your DataFrame\ndf.set_index(pd.DatetimeIndex(df[\"datetime\"]), inplaceTrue)\n\n# Calculate Returns and append to the df DataFrame\ndf.ta.log_return(cumulativeTrue, appendTrue)\ndf.ta.percent_return(cumulativeTrue, appendTrue)\n\n# New Columns with results\ndf.columns\n\n# Take a peek\ndf.tail()\n\n# vv Continue Post Processing vv\n```\n\n<br/>\n\n# **Help**\n```python\nimport pandas as pd\nimport pandas_ta as ta\n\n# Create a DataFrame so 'ta' can be used.\ndf  pd.DataFrame()\n\n# Help about this, 'ta', extension\nhelp(df.ta)\n\n# List of all indicators\ndf.ta.indicators()\n\n# Help about an indicator such as bbands\nhelp(ta.bbands)\n```\n<br/>\n\n# **Issues and Contributions**\n\nThanks for using **Pandas TA**!\n<br/>\n\n* ### [Comments and Feedback](https://github.com/twopirllc/pandas-ta/issues)\n    * Have you read **_this_** document?\n    * Are you running the latest version?\n        * ```$ pip install -U git+https://github.com/twopirllc/pandas-ta```\n    * Have you tried the [Examples](https://github.com/twopirllc/pandas-ta/tree/master/examples/)?\n        * Did they help?\n        * What is missing?\n        * Could you help improve them?\n    * Did you know you can easily build _Custom Strategies_ with the **[Strategy](https://github.com/twopirllc/pandas-ta/blob/master/examples/PandasTA_Strategy_Examples.ipynb) Class**?\n    * Documentation could _always_ be improved. Can you help contribute?\n\n* ### [Bugs, Indicators or Feature Requests](https://github.com/twopirllc/pandas-ta/issues)\n    * First, search the _Closed_ Issues **before** you _Open_ a new Issue; it may have already been solved.\n    * Please be as **detailed** as possible _with_ reproducible code, links if any, applicable screenshots, errors, logs, and data samples. You **will** be asked again if you provide nothing.\n        * You want a new indicator not currently listed.\n        * You want an alternate version of an existing indicator.\n        * The indicator does not match another website, library, broker platform, language, et al.\n            * Do you have correlation analysis to back your claim?\n            * Can you contribute?\n    * You will be asked to fill out an Issue even if you email my personal email address.\n\n\n<br/>\n\n**Contributors**\n\n\n_Thank you for your contributions!_\n\n[alexonab](https://github.com/alexonab) | [allahyarzadeh](https://github.com/allahyarzadeh) | [codesutras](https://github.com/codesutras) | [DrPaprikaa](https://github.com/DrPaprikaa) | [daikts](https://github.com/daikts) | [dorren](https://github.com/dorren) | [edwardwang1](https://github.com/edwardwang1) | [ffhirata](https://github.com/ffhirata) | [FGU1](https://github.com/FGU1) | [lluissalord](https://github.com/lluissalord) | [luisbarrancos](https://github.com/luisbarrancos) |[M6stafa](https://github.com/M6stafa) | [maxdignan](https://github.com/maxdignan) | [mchant](https://github.com/mchant) | [moritzgun](https://github.com/moritzgun) | [NkosenhleDuma](https://github.com/NkosenhleDuma) | [pbrumblay](https://github.com/pbrumblay) | [RajeshDhalange](https://github.com/RajeshDhalange) | [rengel8](https://github.com/rengel8) | [rluong003](https://github.com/rluong003) | [SoftDevDanial](https://github.com/SoftDevDanial) | [tg12](https://github.com/tg12) | [twrobel](https://github.com/twrobel) | [whubsch](https://github.com/whubsch) | [witokondoria](https://github.com/witokondoria) | [wouldayajustlookatit](https://github.com/wouldayajustlookatit) | [YuvalWein](https://github.com/YuvalWein)\n\n<br/>\n\n**Programming Conventions**\n\n\n**Pandas TA** has three primary \"styles\" of processing Technical Indicators for your use case and/or requirements. They are: _Standard_, _DataFrame Extension_, and the _Pandas TA Strategy_. Each with increasing levels of abstraction for ease of use. As you become more familiar with **Pandas TA**, the simplicity and speed of using a _Pandas TA Strategy_ may become more apparent. Furthermore, you can create your own indicators through Chaining or Composition. Lastly, each indicator either returns a _Series_ or a _DataFrame_ in Uppercase Underscore format regardless of style.\n\n<br/>\n\n_Standard_\n\nYou explicitly define the input columns and take care of the output.\n\n* ```sma10  ta.sma(df[\"Close\"], length10)```\n    * Returns a Series with name: ```SMA_10```\n* ```donchiandf  ta.donchian(df[\"HIGH\"], df[\"low\"], lower_length10, upper_length15)```\n    * Returns a DataFrame named ```DC_10_15``` and column names: ```DCL_10_15, DCM_10_15, DCU_10_15```\n* ```ema10_ohlc4  ta.ema(ta.ohlc4(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"]), length10)```\n    * Chaining indicators is possible but you have to be explicit.\n    * Since it returns a Series named ```EMA_10```. If needed, you may need to uniquely name it.\n\n<br/>\n\n_Pandas TA DataFrame Extension_\n\n\nCalling ```df.ta``` will automatically lowercase _OHLCVA_ to _ohlcva_: _open, high, low, close, volume_, _adj_close_. By default, ```df.ta``` will use the _ohlcva_ for the indicator arguments removing the need to specify input columns directly.\n* ```sma10  df.ta.sma(length10)```\n    * Returns a Series with name: ```SMA_10```\n* ```ema10_ohlc4  df.ta.ema(closedf.ta.ohlc4(), length10, suffix\"OHLC4\")```\n    * Returns a Series with name: ```EMA_10_OHLC4```\n    * Chaining Indicators _require_ specifying the input like: ```closedf.ta.ohlc4()```.\n* ```donchiandf  df.ta.donchian(lower_length10, upper_length15)```\n    * Returns a DataFrame named ```DC_10_15``` and column names: ```DCL_10_15, DCM_10_15, DCU_10_15```\n\nSame as the last three examples, but appending the results directly to the DataFrame ```df```.\n* ```df.ta.sma(length10, appendTrue)```\n    * Appends to ```df``` column name: ```SMA_10```.\n* ```df.ta.ema(closedf.ta.ohlc4(appendTrue), length10, suffix\"OHLC4\", appendTrue)```\n    * Chaining Indicators _require_ specifying the input like: ```closedf.ta.ohlc4()```.\n* ```df.ta.donchian(lower_length10, upper_length15, appendTrue)```\n    * Appends to ```df``` with column names: ```DCL_10_15, DCM_10_15, DCU_10_15```.\n\n<br/>\n\n_Pandas TA Strategy_\n\n\nA **Pandas TA** Strategy is a named group of indicators to be run by the _strategy_ method. All Strategies use **mulitprocessing** _except_ when using the ```col_names``` parameter (see [below](#multiprocessing)). There are different types of _Strategies_ listed in the following section.\n\n<br/>\n\n### Here are the previous _Styles_ implemented using a Strategy Class:\n```python\n# (1) Create the Strategy\nMyStrategy  ta.Strategy(\n    name\"DCSMA10\",\n    ta[\n        {\"kind\": \"ohlc4\"},\n        {\"kind\": \"sma\", \"length\": 10},\n        {\"kind\": \"donchian\", \"lower_length\": 10, \"upper_length\": 15},\n        {\"kind\": \"ema\", \"close\": \"OHLC4\", \"length\": 10, \"suffix\": \"OHLC4\"},\n    ]\n)\n\n# (2) Run the Strategy\ndf.ta.strategy(MyStrategy, **kwargs)\n```\n\n<br/><br/>\n\n# **Pandas TA** _Strategies_\n\nThe _Strategy_ Class is a simple way to name and group your favorite TA Indicators by using a _Data Class_. **Pandas TA** comes with two prebuilt basic Strategies to help you get started: __AllStrategy__ and __CommonStrategy__. A _Strategy_ can be as simple as the __CommonStrategy__ or as complex as needed using Composition/Chaining.\n\n* When using the _strategy_ method, **all** indicators will be automatically appended to the DataFrame ```df```.\n* You are using a Chained Strategy when you have the output of one indicator as input into one or more indicators in the same _Strategy_.\n* **Note:** Use the 'prefix' and/or 'suffix' keywords to distinguish the composed indicator from it's default Series.\n\nSee the [Pandas TA Strategy Examples Notebook](https://github.com/twopirllc/pandas-ta/tree/master/examples/PandasTA_Strategy_Examples.ipynb) for examples including _Indicator Composition/Chaining_.\n\nStrategy Requirements\n---------------------\n- _name_: Some short memorable string.  _Note_: Case-insensitive \"All\" is reserved.\n- _ta_: A list of dicts containing keyword arguments to identify the indicator and the indicator's arguments\n- **Note:** A Strategy will fail when consumed by Pandas TA if there is no ```{\"kind\": \"indicator name\"}``` attribute. _Remember_ to check your spelling.\n\nOptional Parameters\n-------------------\n- _description_: A more detailed description of what the Strategy tries to capture. Default: None\n- _created_: At datetime string of when it was created. Default: Automatically generated.\n\n<br/>\n\nTypes of Strategies\n\n\n## _Builtin_\n```python\n# Running the Builtin CommonStrategy as mentioned above\ndf.ta.strategy(ta.CommonStrategy)\n\n# The Default Strategy is the ta.AllStrategy. The following are equivalent:\ndf.ta.strategy()\ndf.ta.strategy(\"All\")\ndf.ta.strategy(ta.AllStrategy)\n```\n\n## _Categorical_\n```python\n# List of indicator categories\ndf.ta.categories\n\n# Running a Categorical Strategy only requires the Category name\ndf.ta.strategy(\"Momentum\") # Default values for all Momentum indicators\ndf.ta.strategy(\"overlap\", length42) # Override all Overlap 'length' attributes\n```\n\n## _Custom_\n```python\n# Create your own Custom Strategy\nCustomStrategy  ta.Strategy(\n    name\"Momo and Volatility\",\n    description\"SMA 50,200, BBANDS, RSI, MACD and Volume SMA 20\",\n    ta[\n        {\"kind\": \"sma\", \"length\": 50},\n        {\"kind\": \"sma\", \"length\": 200},\n        {\"kind\": \"bbands\", \"length\": 20},\n        {\"kind\": \"rsi\"},\n        {\"kind\": \"macd\", \"fast\": 8, \"slow\": 21},\n        {\"kind\": \"sma\", \"close\": \"volume\", \"length\": 20, \"prefix\": \"VOLUME\"},\n    ]\n)\n# To run your \"Custom Strategy\"\ndf.ta.strategy(CustomStrategy)\n```\n\n<br/>\n\n**Multiprocessing**\n\n\nThe **Pandas TA** _strategy_ method utilizes **multiprocessing** for bulk indicator processing of all Strategy types with **ONE EXCEPTION!** When using the ```col_names``` parameter to rename resultant column(s), the indicators in ```ta``` array will be ran in order.\n\n```python\n# VWAP requires the DataFrame index to be a DatetimeIndex.\n# * Replace \"datetime\" with the appropriate column from your DataFrame\ndf.set_index(pd.DatetimeIndex(df[\"datetime\"]), inplaceTrue)\n\n# Runs and appends all indicators to the current DataFrame by default\n# The resultant DataFrame will be large.\ndf.ta.strategy()\n# Or the string \"all\"\ndf.ta.strategy(\"all\")\n# Or the ta.AllStrategy\ndf.ta.strategy(ta.AllStrategy)\n\n# Use verbose if you want to make sure it is running.\ndf.ta.strategy(verboseTrue)\n\n# Use timed if you want to see how long it takes to run.\ndf.ta.strategy(timedTrue)\n\n# Choose the number of cores to use. Default is all available cores.\n# For no multiprocessing, set this value to 0.\ndf.ta.cores  4\n\n# Maybe you do not want certain indicators.\n# Just exclude (a list of) them.\ndf.ta.strategy(exclude[\"bop\", \"mom\", \"percent_return\", \"wcp\", \"pvi\"], verboseTrue)\n\n# Perhaps you want to use different values for indicators.\n# This will run ALL indicators that have fast or slow as parameters.\n# Check your results and exclude as necessary.\ndf.ta.strategy(fast10, slow50, verboseTrue)\n\n# Sanity check. Make sure all the columns are there\ndf.columns\n```\n\n<br/>\n\n## Custom Strategy without Multiprocessing\n**Remember** These will not be utilizing **multiprocessing** \n```python\nNonMPStrategy  ta.Strategy(\n    name\"EMAs, BBs, and MACD\",\n    description\"Non Multiprocessing Strategy by rename Columns\",\n    ta[\n ",
        "AgentRunResult(output='Continuação do README.md da raiz do projeto \"pandas-ta\", uma biblioteca Python para análise técnica com o Pandas. Abrange propriedades e métodos da extensão DataFrame, categorias e listas de indicadores técnicos (momentum, tendência, volume, etc.), métricas de performance beta e mudanças na biblioteca. Tecnologias: Python, Pandas, análise técnica, yfinance.')\nREADME.md - Parte (2/2)\n       {\"kind\": \"ema\", \"length\": 8},\n        {\"kind\": \"ema\", \"length\": 21},\n        {\"kind\": \"bbands\", \"length\": 20, \"col_names\": (\"BBL\", \"BBM\", \"BBU\")},\n        {\"kind\": \"macd\", \"fast\": 8, \"slow\": 21, \"col_names\": (\"MACD\", \"MACD_H\", \"MACD_S\")}\n    ]\n)\n# Run it\ndf.ta.strategy(NonMPStrategy)\n```\n\n<br/><br/>\n\n\n# **DataFrame Properties**\n\n## **adjusted**\n\n```python\n# Set ta to default to an adjusted column, 'adj_close', overriding default 'close'.\ndf.ta.adjusted  \"adj_close\"\ndf.ta.sma(length10, appendTrue)\n\n# To reset back to 'close', set adjusted back to None.\ndf.ta.adjusted  None\n```\n\n## **categories**\n\n```python\n# List of Pandas TA categories.\ndf.ta.categories\n```\n\n## **cores**\n\n```python\n# Set the number of cores to use for strategy multiprocessing\n# Defaults to the number of cpus you have.\ndf.ta.cores  4\n\n# Set the number of cores to 0 for no multiprocessing.\ndf.ta.cores  0\n\n# Returns the number of cores you set or your default number of cpus.\ndf.ta.cores\n```\n\n## **datetime_ordered**\n\n```python\n# The 'datetime_ordered' property returns True if the DataFrame\n# index is of Pandas datetime64 and df.index[0] < df.index[-1].\n# Otherwise it returns False.\ndf.ta.datetime_ordered\n```\n\n## **exchange**\n\n```python\n# Sets the Exchange to use when calculating the last_run property. Default: \"NYSE\"\ndf.ta.exchange\n\n# Set the Exchange to use.\n# Available Exchanges: \"ASX\", \"BMF\", \"DIFX\", \"FWB\", \"HKE\", \"JSE\", \"LSE\", \"NSE\", \"NYSE\", \"NZSX\", \"RTS\", \"SGX\", \"SSE\", \"TSE\", \"TSX\"\ndf.ta.exchange  \"LSE\"\n```\n\n## **last_run**\n\n```python\n# Returns the time Pandas TA was last run as a string.\ndf.ta.last_run\n```\n\n## **reverse**\n\n```python\n# The 'reverse' is a helper property that returns the DataFrame\n# in reverse order.\ndf.ta.reverse\n```\n\n## **prefix & suffix**\n\n```python\n# Applying a prefix to the name of an indicator.\nprehl2  df.ta.hl2(prefix\"pre\")\nprint(prehl2.name)  # \"pre_HL2\"\n\n# Applying a suffix to the name of an indicator.\nendhl2  df.ta.hl2(suffix\"post\")\nprint(endhl2.name)  # \"HL2_post\"\n\n# Applying a prefix and suffix to the name of an indicator.\nbothhl2  df.ta.hl2(prefix\"pre\", suffix\"post\")\nprint(bothhl2.name)  # \"pre_HL2_post\"\n```\n\n## **time_range**\n\n```python\n# Returns the time range of the DataFrame as a float.\n# By default, it returns the time in \"years\"\ndf.ta.time_range\n\n# Available time_ranges include: \"years\", \"months\", \"weeks\", \"days\", \"hours\", \"minutes\". \"seconds\"\ndf.ta.time_range  \"days\"\ndf.ta.time_range # prints DataFrame time in \"days\" as float\n```\n\n## **to_utc**\n\n```python\n# Sets the DataFrame index to UTC format.\ndf.ta.to_utc\n```\n\n<br/><br/>\n\n\n# **DataFrame Methods**\n\n## **constants**\n\n```python\nimport numpy as np\n\n# Add constant '1' to the DataFrame\ndf.ta.constants(True, [1])\n# Remove constant '1' to the DataFrame\ndf.ta.constants(False, [1])\n\n# Adding constants for charting\nimport numpy as np\nchart_lines  np.append(np.arange(-4, 5, 1), np.arange(-100, 110, 10))\ndf.ta.constants(True, chart_lines)\n# Removing some constants from the DataFrame\ndf.ta.constants(False, np.array([-60, -40, 40, 60]))\n```\n\n## **indicators**\n\n```python\n# Prints the indicators and utility functions\ndf.ta.indicators()\n\n# Returns a list of indicators and utility functions\nind_list  df.ta.indicators(as_listTrue)\n\n# Prints the indicators and utility functions that are not in the excluded list\ndf.ta.indicators(exclude[\"cg\", \"pgo\", \"ui\"])\n# Returns a list of the indicators and utility functions that are not in the excluded list\nsmaller_list  df.ta.indicators(exclude[\"cg\", \"pgo\", \"ui\"], as_listTrue)\n```\n\n## **ticker**\n\n```python\n# Download Chart history using yfinance. (pip install yfinance) https://github.com/ranaroussi/yfinance\n# It uses the same keyword arguments as yfinance (excluding start and end)\ndf  df.ta.ticker(\"aapl\") # Default ticker is \"SPY\"\n\n# Period is used instead of start/end\n# Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n# Default: \"max\"\ndf  df.ta.ticker(\"aapl\", period\"1y\") # Gets this past year\n\n# History by Interval by interval (including intraday if period < 60 days)\n# Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n# Default: \"1d\"\ndf  df.ta.ticker(\"aapl\", period\"1y\", interval\"1wk\") # Gets this past year in weeks\ndf  df.ta.ticker(\"aapl\", period\"1mo\", interval\"1h\") # Gets this past month in hours\n\n# BUT WAIT!! THERE'S MORE!!\nhelp(ta.yf)\n```\n\n<br/><br/>\n\n# **Indicators** (_by Category_)\n### **Candles** (3)\n\n* _Doji_: **cdl_doji**\n* _Inside Bar_: **cdl_inside**\n* _Heikin-Ashi_: **ha**\n<br/>\n\n\n### **Cycles** (1)\n\n* _Even Better Sinewave_: **ebsw**\n<br/>\n\n### **Momentum** (37)\n\n* _Awesome Oscillator_: **ao**\n* _Absolute Price Oscillator_: **apo**\n* _Bias_: **bias**\n* _Balance of Power_: **bop**\n* _BRAR_: **brar**\n* _Commodity Channel Index_: **cci**\n* _Chande Forecast Oscillator_: **cfo**\n* _Center of Gravity_: **cg**\n* _Chande Momentum Oscillator_: **cmo**\n* _Coppock Curve_: **coppock**\n* _Efficiency Ratio_: **er**\n* _Elder Ray Index_: **eri**\n* _Fisher Transform_: **fisher**\n* _Inertia_: **inertia**\n* _KDJ_: **kdj**\n* _KST Oscillator_: **kst**\n* _Moving Average Convergence Divergence_: **macd**\n* _Momentum_: **mom**\n* _Pretty Good Oscillator_: **pgo**\n* _Percentage Price Oscillator_: **ppo**\n* _Psychological Line_: **psl**\n* _Percentage Volume Oscillator_: **pvo**\n* _Quantitative Qualitative Estimation_: **qqe**\n* _Rate of Change_: **roc**\n* _Relative Strength Index_: **rsi**\n* _Relative Strength Xtra_: **rsx**\n* _Relative Vigor Index_: **rvgi**\n* _Slope_: **slope**\n* _SMI Ergodic_ **smi**\n* _Squeeze_: **squeeze**\n    * Default is John Carter's. Enable Lazybear's with ```lazybearTrue```\n* _Stochastic Oscillator_: **stoch**\n* _Stochastic RSI_: **stochrsi**\n* _TD Sequential_: **td_seq**\n    * Excluded from ```df.ta.strategy()```.\n* _Trix_: **trix**\n* _True strength index_: **tsi**\n* _Ultimate Oscillator_: **uo**\n* _Williams %R_: **willr**\n\n\n| _Moving Average Convergence Divergence_ (MACD) |\n|:--------:|\n| ![Example MACD](/images/SPY_MACD.png) |\n<br/>\n\n### **Overlap** (31)\n\n* _Arnaud Legoux Moving Average_: **alma**\n* _Double Exponential Moving Average_: **dema**\n* _Exponential Moving Average_: **ema**\n* _Fibonacci's Weighted Moving Average_: **fwma**\n* _Gann High-Low Activator_: **hilo**\n* _High-Low Average_: **hl2**\n* _High-Low-Close Average_: **hlc3**\n    * Commonly known as 'Typical Price' in Technical Analysis literature\n* _Hull Exponential Moving Average_: **hma**\n* _Holt-Winter Moving Average_: **hwma**\n* _Ichimoku Kinkō Hyō_: **ichimoku**\n    * Use: help(ta.ichimoku). Returns two DataFrames.\n    * Drop the Chikou Span Column, the final column of the first resultant DataFrame, remove potential data leak.\n* _Kaufman's Adaptive Moving Average_: **kama**\n* _Linear Regression_: **linreg**\n* _McGinley Dynamic_: **mcgd**\n* _Midpoint_: **midpoint**\n* _Midprice_: **midprice**\n* _Open-High-Low-Close Average_: **ohlc4**\n* _Pascal's Weighted Moving Average_: **pwma**\n* _WildeR's Moving Average_: **rma**\n* _Sine Weighted Moving Average_: **sinwma**\n* _Simple Moving Average_: **sma**\n* _Ehler's Super Smoother Filter_: **ssf**\n* _Supertrend_: **supertrend**\n* _Symmetric Weighted Moving Average_: **swma**\n* _T3 Moving Average_: **t3**\n* _Triple Exponential Moving Average_: **tema**\n* _Triangular Moving Average_: **trima**\n* _Variable Index Dynamic Average_: **vidya**\n* _Volume Weighted Average Price_: **vwap**\n    * **Requires** the DataFrame index to be a DatetimeIndex\n* _Volume Weighted Moving Average_: **vwma**\n* _Weighted Closing Price_: **wcp**\n* _Weighted Moving Average_: **wma**\n* _Zero Lag Moving Average_: **zlma**\n\n| _Simple Moving Averages_ (SMA) and _Bollinger Bands_ (BBANDS) |\n|:--------:|\n| ![Example Chart](/images/TA_Chart.png) |\n<br/>\n\n\n### **Performance** (4)\n\nUse parameter: cumulative**True** for cumulative results.\n\n* _Draw Down_: **drawdown**\n* _Log Return_: **log_return**\n* _Percent Return_: **percent_return**\n* _Trend Return_: **trend_return**\n\n| _Percent Return_ (Cumulative) with _Simple Moving Average_ (SMA) |\n|:--------:|\n| ![Example Cumulative Percent Return](/images/SPY_CumulativePercentReturn.png) |\n<br/>\n\n### **Statistics** (9)\n\n* _Entropy_: **entropy**\n* _Kurtosis_: **kurtosis**\n* _Mean Absolute Deviation_: **mad**\n* _Median_: **median**\n* _Quantile_: **quantile**\n* _Skew_: **skew**\n* _Standard Deviation_: **stdev**\n* _Variance_: **variance**\n* _Z Score_: **zscore**\n\n| _Z Score_ |\n|:--------:|\n| ![Example Z Score](/images/SPY_ZScore.png) |\n<br/>\n\n### **Trend** (15)\n\n* _Average Directional Movement Index_: **adx**\n    * Also includes **dmp** and **dmn** in the resultant DataFrame.\n* _Archer Moving Averages Trends_: **amat**\n* _Aroon & Aroon Oscillator_: **aroon**\n* _Choppiness Index_: **chop**\n* _Chande Kroll Stop_: **cksp**\n* _Decay_: **decay**\n    * Formally: **linear_decay**\n* _Decreasing_: **decreasing**\n* _Detrended Price Oscillator_: **dpo**\n    * Set ```centeredFalse``` to remove potential data leak.\n* _Increasing_: **increasing**\n* _Long Run_: **long_run**\n* _Parabolic Stop and Reverse_: **psar**\n* _Q Stick_: **qstick**\n* _Short Run_: **short_run**\n* _TTM Trend_: **ttm_trend**\n* _Vortex_: **vortex**\n\n| _Average Directional Movement Index_ (ADX) |\n|:--------:|\n| ![Example ADX](/images/SPY_ADX.png) |\n\n### **Utility** (5)\n\n* _Above_: **above**\n* _Above Value_: **above_value**\n* _Below_: **below**\n* _Below Value_: **below_value**\n* _Cross_: **cross**\n\n### **Volatility** (13)\n\n* _Aberration_: **aberration**\n* _Acceleration Bands_: **accbands**\n* _Average True Range_: **atr**\n* _Bollinger Bands_: **bbands**\n* _Donchian Channel_: **donchian**\n* _Keltner Channel_: **kc**\n* _Mass Index_: **massi**\n* _Normalized Average True Range_: **natr**\n* _Price Distance_: **pdist**\n* _Relative Volatility Index_: **rvi**\n* _Elder's Thermometer_: **thermo**\n* _True Range_: **true_range**\n* _Ulcer Index_: **ui**\n\n| _Average True Range_ (ATR) |\n|:--------:|\n| ![Example ATR](/images/SPY_ATR.png) |\n\n### **Volume** (14)\n\n* _Accumulation/Distribution Index_: **ad**\n* _Accumulation/Distribution Oscillator_: **adosc**\n* _Archer On-Balance Volume_: **aobv**\n* _Chaikin Money Flow_: **cmf**\n* _Elder's Force Index_: **efi**\n* _Ease of Movement_: **eom**\n* _Money Flow Index_: **mfi**\n* _Negative Volume Index_: **nvi**\n* _On-Balance Volume_: **obv**\n* _Positive Volume Index_: **pvi**\n* _Price-Volume_: **pvol**\n* _Price Volume Rank_: **pvr**\n* _Price Volume Trend_: **pvt**\n* _Volume Profile_: **vp**\n\n| _On-Balance Volume_ (OBV) |\n|:--------:|\n| ![Example OBV](/images/SPY_OBV.png) |\n\n<br/><br/>\n\n# **Performance Metrics** &nbsp; _BETA_\n_Performance Metrics_ are a **new** addition to the package and consequentially are likely unreliable. **Use at your own risk.** These metrics return a _float_ and are _not_ part of the _DataFrame_ Extension. They are called the Standard way. For Example:\n\n```python\nimport pandas_ta as ta\nresult  ta.cagr(df.close)\n```\n\n### Available Metrics\n* _Compounded Annual Growth Rate_: **cagr**\n* _Calmar Ratio_: **calmar_ratio**\n* _Downside Deviation_: **downside_deviation**\n* _Jensen's Alpha_: **jensens_alpha**\n* _Log Max Drawdown_: **log_max_drawdown**\n* _Max Drawdown_: **max_drawdown**\n* _Pure Profit Score_: **pure_profit_score**\n* _Sharpe Ratio_: **sharpe_ratio**\n* _Sortino Ratio_: **sortino_ratio**\n* _Volatility_: **volatility**\n\n\n<br/><br/>\n\n# **Changes**\n## **General**\n* A __Strategy__ Class to help name and group your favorite indicators.\n* Some indicators have had their ```mamode``` _kwarg_ updated with more _moving average_ choices with the **Moving Average Utility** function ```ta.ma()```. For simplicity, all _choices_ are single source _moving averages_. This is primarily an internal utility used by indicators that have a ```mamode``` _kwarg_. This includes indicators: _accbands_, _amat_, _aobv_, _atr_, _bbands_, _bias_, _efi_, _hilo_, _kc_, _natr_, _qqe_, _rvi_, and _thermo_; the default ```mamode``` parameters have not changed. However, ```ta.ma()``` can be used by the user as well if needed. For more information: ```help(ta.ma)```\n    * **Moving Average Choices**: dema, ema, fwma, hma, linreg, midpoint, pwma, rma, sinwma, sma, swma, t3, tema, trima, vidya, wma, zlma.\n* An _experimental_ and independent __Watchlist__ Class located in the [Examples](https://github.com/twopirllc/pandas-ta/tree/master/examples/watchlist.py) Directory that can be used in conjunction with the new __Strategy__ Class.\n* _Linear Regression_ (**linear_regression**) is a new utility method for Simple Linear Regression using _Numpy_ or _Scikit Learn_'s implementation.\n* Added utility/convience function, ```to_utc```, to convert the DataFrame index to UTC. See: ```help(ta.to_utc)``` **Now** as a Pandas TA DataFrame Property to easily convert the DataFrame index to UTC.\n\n<br />\n\n## **Breaking Indicators**\n* _Trend Return_ (**trend_return**) when given a trend Series like ```close > sma(close, 50)``` it now returns by default log and cumulative log returns of the trend as well as the Trends, Trades, Trade Entries and Trade Exits of that trend. Now compatible with [**vectorbt**](https://github.com/polakowo/vectorbt) by setting ```asboolTrue``` to get boolean Trade Entries and Exits. See: ```help(ta.trend_return)```\n\n## **New Indicators**\n* _Arnaud Legoux Moving Average_ (**alma**) uses the curve of the Normal (Gauss) distribution to allow regulating the smoothness and high sensitivity of the indicator. See: ```help(ta.alma)```\ntrading account, or fund. See: ```help(ta.drawdown)```\n* _Even Better Sinewave_ (**ebsw**) measures market cycles and uses a low pass filter to remove noise. See: ```help(ta.ebsw)```\n* _Tom DeMark's Sequential_ (**td_seq**) attempts to identify a price point where an uptrend or a downtrend exhausts itself and reverses. Currently exlcuded from ```df.ta.strategy()``` for performance reasons. See: ```help(ta.td_seq)```\n<br/>\n\n## **Updated Indicators**\n* _ADX_ (**adx**): Added ```mamode``` with default \"**RMA**\" and with the same ```mamode``` options as TradingView. See ```help(ta.adx)```.\n* _Average True Range_ (**atr**): The default ```mamode``` is now \"**RMA**\" and with the same ```mamode``` options as TradingView. See ```help(ta.atr)```.\n* _Bollinger Bands_ (**bbands**): New argument ```ddoff``` to control the Degrees of Freedom. Default is 0.  See ```help(ta.bbands)```.\n* _Chande Kroll Stop_ (**cksp**): Added ```tvmode``` with default ```True```. When ```tvmodeFalse```, **cksp** implements “The New Technical Trader” with default values. See ```help(ta.cksp)```.\n* _Decreasing_ (**decreasing**): New argument ```strict``` checks if the series is continuously decreasing over period ```length```. Default: ```False```. See ```help(ta.decreasing)```.\n* _Increasing_ (**increasing**): New argument ```strict``` checks if the series is continuously increasing over period ```length```. Default: ```False```. See ```help(ta.increasing)```.\n* _Volume Weighted Average Price_ (**vwap**) Added a new parameter called ```anchor```. Default: \"D\" for \"Daily\". See [Timeseries Offset Aliases](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases) for additional options. **Requires** the DataFrame index to be a DatetimeIndex\n\n<br />\n\n# **Sources**\n[Original TA-LIB](http://ta-lib.org/) | [TradingView](http://www.tradingview.com) | [Sierra Chart](https://search.sierrachart.com/?Queryindicators&submittedtrue) | [MQL5](https://www.mql5.com) | [FM Labs](https://www.fmlabs.com/reference/default.htm) | [Pro Real Code](https://www.prorealcode.com/prorealtime-indicators) | [User 42](https://user42.tuxfamily.org/chart/manual/index.html)\n\n\n"
    ],
    "CODE_OF_CONDUCT.md": [
        "AgentRunResult(output='This is the root-level CODE_OF_CONDUCT.md file, outlining community standards, inclusive behavior expectations, enforcement policies, and contributor responsibilities using the Contributor Covenant.')\nCODE_OF_CONDUCT.md\n\n# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at appliedmathkj@gmail.com. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n\n\n\n"
    ],
    "LICENSE": [
        "AgentRunResult(output='This is the LICENSE file at the project root. It defines the MIT License terms for the \"pandas-ta\" library, granting permissions and disclaiming warranties for software use and distribution.')\nLICENSE\n\nThe MIT License (MIT)\n\nCopyright (c) 2020 pandas-ta\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n\n\n"
    ],
    "_config.yml": [
        "AgentRunResult(output='Arquivo de configuração do Jekyll localizado na raiz do projeto. Define o tema do site como \"jekyll-theme-slate\". Trata-se de um site estático provavelmente hospedado via GitHub Pages.')\n_config.yml\n\ntheme: jekyll-theme-slate\n\n\n"
    ],
    "pandas_ta": [
        "AgentRunResult(output='Context: Root package initialization for the `pandas_ta` technical analysis library.\\n\\nTopics: Library metadata, optional dependency checks, category registry of technical indicators (e.g., momentum, trend, volume), default aggregation configs, and timezone/rate constants.')\npandas_ta/__init__.py\n\nname  \"pandas_ta\"\n\"\"\"\n.. moduleauthor:: Kevin Johnson\n\"\"\"\nfrom importlib.util import find_spec\nfrom pkg_resources import get_distribution, DistributionNotFound\nimport os.path\n\n\n_dist  get_distribution(\"pandas_ta\")\ntry:\n    # Normalize case for Windows systems\n    dist_loc  os.path.normcase(_dist.location)\n    here  os.path.normcase(__file__)\n    if not here.startswith(os.path.join(dist_loc, \"pandas_ta\")):\n        # not installed, but there is another version that *is*\n        raise DistributionNotFound\nexcept DistributionNotFound:\n    __version__  \"Please install this project with setup.py\"\n\nversion  __version__  _dist.version\n\n\nImports  {\n    \"alphaVantage-api\": find_spec(\"alphaVantageAPI\") is not None,\n    \"matplotlib\": find_spec(\"matplotlib\") is not None,\n    \"mplfinance\": find_spec(\"mplfinance\") is not None,\n    \"scipy\": find_spec(\"scipy\") is not None,\n    \"sklearn\": find_spec(\"sklearn\") is not None,\n    \"statsmodels\": find_spec(\"statsmodels\") is not None,\n    \"stochastic\": find_spec(\"stochastic\") is not None,\n    \"talib\": find_spec(\"talib\") is not None,\n    \"tqdm\": find_spec(\"tqdm\") is not None,\n    \"vectorbt\": find_spec(\"vectorbt\") is not None,\n    \"yfinance\": find_spec(\"yfinance\") is not None,\n}\n\n# Not ideal and not dynamic but it works.\n# Will find a dynamic solution later.\nCategory  {\n    # Candles\n    \"candles\": [\n        \"cdl_doji\", \"cdl_inside\", \"ha\"\n    ],\n    # Cycles\n    \"cycles\": [\"ebsw\"],\n    # Momentum\n    \"momentum\": [\n        \"ao\", \"apo\", \"bias\", \"bop\", \"brar\", \"cci\", \"cfo\", \"cg\", \"cmo\",\n        \"coppock\", \"er\", \"eri\", \"fisher\", \"inertia\", \"kdj\", \"kst\", \"macd\",\n        \"mom\", \"pgo\", \"ppo\", \"psl\", \"pvo\", \"qqe\", \"roc\", \"rsi\", \"rsx\", \"rvgi\",\n        \"slope\", \"smi\", \"squeeze\", \"stoch\", \"stochrsi\", \"td_seq\", \"trix\", \"tsi\", \"uo\",\n        \"willr\"\n    ],\n    # Overlap\n    \"overlap\": [\n        \"alma\", \"dema\", \"ema\", \"fwma\", \"hilo\", \"hl2\", \"hlc3\", \"hma\", \"ichimoku\",\n        \"kama\", \"linreg\", \"mcgd\", \"midpoint\", \"midprice\", \"ohlc4\", \"pwma\", \"rma\",\n        \"sinwma\", \"sma\", \"ssf\", \"supertrend\", \"swma\", \"t3\", \"tema\", \"trima\",\n        \"vidya\", \"vwap\", \"vwma\", \"wcp\", \"wma\", \"zlma\"\n    ],\n    # Performance\n    \"performance\": [\"log_return\", \"percent_return\", \"trend_return\"],\n    # Statistics\n    \"statistics\": [\n        \"entropy\", \"kurtosis\", \"mad\", \"median\", \"quantile\", \"skew\", \"stdev\",\n        \"variance\", \"zscore\"\n    ],\n    # Trend\n    \"trend\": [\n        \"adx\", \"amat\", \"aroon\", \"chop\", \"cksp\", \"decay\", \"decreasing\", \"dpo\",\n        \"increasing\", \"long_run\", \"psar\", \"qstick\", \"short_run\", \"ttm_trend\",\n        \"vortex\"\n    ],\n    # Volatility\n    \"volatility\": [\n        \"aberration\", \"accbands\", \"atr\", \"bbands\", \"donchian\", \"hwc\", \"kc\", \"massi\",\n        \"natr\", \"pdist\", \"rvi\", \"thermo\", \"true_range\", \"ui\"\n    ],\n\n    # Volume, \"vp\" or \"Volume Profile\" is unique\n    \"volume\": [\n        \"ad\", \"adosc\", \"aobv\", \"cmf\", \"efi\", \"eom\", \"mfi\", \"nvi\", \"obv\", \"pvi\",\n        \"pvol\", \"pvr\", \"pvt\"\n    ],\n}\n\nCANGLE_AGG  {\n    \"open\": \"first\",\n    \"high\": \"max\",\n    \"low\": \"min\",\n    \"close\": \"last\",\n    \"volume\": \"sum\"\n}\n\n# https://www.worldtimezone.com/markets24.php\nEXCHANGE_TZ  {\n    \"NZSX\": 12, \"ASX\": 11,\n    \"TSE\": 9, \"HKE\": 8, \"SSE\": 8, \"SGX\": 8,\n    \"NSE\": 5.5, \"DIFX\": 4, \"RTS\": 3,\n    \"JSE\": 2, \"FWB\": 1, \"LSE\": 1,\n    \"BMF\": -2, \"NYSE\": -4, \"TSX\": -4\n}\n\nRATE  {\n    \"DAYS_PER_MONTH\": 21,\n    \"MINUTES_PER_HOUR\": 60,\n    \"MONTHS_PER_YEAR\": 12,\n    \"QUARTERS_PER_YEAR\": 4,\n    \"TRADING_DAYS_PER_YEAR\": 252,  # Keep even\n    \"TRADING_HOURS_PER_DAY\": 6.5,\n    \"WEEKS_PER_YEAR\": 52,\n    \"YEARLY\": 1,\n}\n\nfrom pandas_ta.core import *\n\n\n\n",
        "AgentRunResult(output='Context: This is part 1 of 4 of the file `pandas_ta/core.py` in the `pandas_ta` root directory. It contains foundational classes and logic for handling technical analysis strategies and indicator registration in pandas.\\n\\nMain topics and technologies: Defines the `Strategy` data class and the `AnalysisIndicators` class used to extend pandas DataFrames via a `.ta` accessor, enabling computation of technical indicators. Covers handling custom strategies, multiprocessing, column manipulation, dataframe validation, and internal utility methods. Technologies include pandas and multiprocessing.')\npandas_ta/core.py - Parte (1/4)\npandas_ta/core.py\n\n# -*- coding: utf-8 -*-\nfrom dataclasses import dataclass, field\nfrom multiprocessing import cpu_count, Pool\nfrom time import perf_counter\nfrom typing import List, Tuple\n\nimport pandas as pd\nfrom numpy import log10 as npLog10\nfrom numpy import ndarray as npNdarray\nfrom pandas.core.base import PandasObject\n\nfrom pandas_ta import Category, version\nfrom pandas_ta.candles import *\nfrom pandas_ta.cycles import *\nfrom pandas_ta.momentum import *\nfrom pandas_ta.overlap import *\nfrom pandas_ta.performance import *\nfrom pandas_ta.statistics import *\nfrom pandas_ta.trend import *\nfrom pandas_ta.volatility import *\nfrom pandas_ta.volume import *\nfrom pandas_ta.utils import *\n\n\ndf  pd.DataFrame()\n\n# Strategy DataClass\n@dataclass\nclass Strategy:\n    \"\"\"Strategy DataClass\n    A way to name and group your favorite indicators\n\n    Args:\n        name (str): Some short memorable string.  Note: Case-insensitive \"All\" is reserved.\n        ta (list of dicts): A list of dicts containing keyword arguments where \"kind\" is the indicator.\n        description (str): A more detailed description of what the Strategy tries to capture. Default: None\n        created (str): At datetime string of when it was created. Default: Automatically generated. *Subject to change*\n\n    Example TA:\n    ta  [\n        {\"kind\": \"sma\", \"length\": 200},\n        {\"kind\": \"sma\", \"close\": \"volume\", \"length\": 50},\n        {\"kind\": \"bbands\", \"length\": 20},\n        {\"kind\": \"rsi\"},\n        {\"kind\": \"macd\", \"fast\": 8, \"slow\": 21},\n        {\"kind\": \"sma\", \"close\": \"volume\", \"length\": 20, \"prefix\": \"VOLUME\"},\n    ]\n    \"\"\"\n\n    name: str  #  None # Required.\n    ta: List  field(default_factorylist)  # Required.\n    # Helpful. More descriptive version or notes or w/e.\n    description: str  \"TA Description\"\n    # Optional. Gets Exchange Time and Local Time execution time\n    created: str  get_time(to_stringTrue)\n\n    def __post_init__(self):\n        has_name  True\n        is_ta  False\n        required_args  [\"[X] Strategy requires the following argument(s):\"]\n\n        name_is_str  isinstance(self.name, str)\n        ta_is_list  isinstance(self.ta, list)\n\n        if self.name is None or not name_is_str:\n            required_args.append(' - name. Must be a string. Example: \"My TA\". Note: \"all\" is reserved.')\n            has_name ! has_name\n\n        if self.ta is None:\n            self.ta  None\n        elif self.ta is not None and ta_is_list and self.total_ta() > 0:\n            # Check that all elements of the list are dicts.\n            # Does not check if the dicts values are valid indicator kwargs\n            # User must check indicator documentation for all indicators args.\n            is_ta  all([isinstance(_, dict) and len(_.keys()) > 0 for _ in self.ta])\n        else:\n            s  \" - ta. Format is a list of dicts. Example: [{'kind': 'sma', 'length': 10}]\"\n            s + \"\\n       Check the indicator for the correct arguments if you receive this error.\"\n            required_args.append(s)\n\n        if len(required_args) > 1:\n            [print(_) for _ in required_args]\n            return None\n\n    def total_ta(self):\n        return len(self.ta) if self.ta is not None else 0\n\n\n# All Default Strategy\nAllStrategy  Strategy(\n    name\"All\",\n    description\"All the indicators with their default settings. Pandas TA default.\",\n    taNone,\n)\n\n# Default (Example) Strategy.\nCommonStrategy  Strategy(\n    name\"Common Price and Volume SMAs\",\n    description\"Common Price SMAs: 10, 20, 50, 200 and Volume SMA: 20.\",\n    ta[\n        {\"kind\": \"sma\", \"length\": 10},\n        {\"kind\": \"sma\", \"length\": 20},\n        {\"kind\": \"sma\", \"length\": 50},\n        {\"kind\": \"sma\", \"length\": 200},\n        {\"kind\": \"sma\", \"close\": \"volume\", \"length\": 20, \"prefix\": \"VOL\"}\n    ]\n)\n\n\n# Base Class for extending a Pandas DataFrame\nclass BasePandasObject(PandasObject):\n    \"\"\"Simple PandasObject Extension\n\n    Ensures the DataFrame is not empty and has columns.\n    It would be a sad Panda otherwise.\n\n    Args:\n        df (pd.DataFrame): Extends Pandas DataFrame\n    \"\"\"\n\n    def __init__(self, df, **kwargs):\n        if df.empty: return\n        if len(df.columns) > 0:\n            common_names  {\n                \"Date\": \"date\",\n                \"Time\": \"time\",\n                \"Timestamp\": \"timestamp\",\n                \"Datetime\": \"datetime\",\n                \"Open\": \"open\",\n                \"High\": \"high\",\n                \"Low\": \"low\",\n                \"Close\": \"close\",\n                \"Adj Close\": \"adj_close\",\n                \"Volume\": \"volume\",\n                \"Dividends\": \"dividends\",\n                \"Stock Splits\": \"split\",\n            }\n            # Preemptively drop the rows that are all NaNs\n            # Might need to be moved to AnalysisIndicators.__call__() to be\n            #   toggleable via kwargs.\n            # df.dropna(axis0, inplaceTrue)\n            # Preemptively rename columns to lowercase\n            df.rename(columnscommon_names, errors\"ignore\", inplaceTrue)\n\n            # Preemptively lowercase the index\n            index_name  df.index.name\n            if index_name is not None:\n                df.index.rename(index_name.lower(), inplaceTrue)\n\n            self._df  df\n        else:\n            raise AttributeError(f\"[X] No columns!\")\n\n    def __call__(self, kind, *args, **kwargs):\n        raise NotImplementedError()\n\n\n# Pandas TA - DataFrame Analysis Indicators\n@pd.api.extensions.register_dataframe_accessor(\"ta\")\nclass AnalysisIndicators(BasePandasObject):\n    \"\"\"\n    This Pandas Extension is named 'ta' for Technical Analysis. In other words,\n    it is a Numerical Time Series Feature Generator where the Time Series data\n    is biased towards Financial Market data; typical data includes columns\n    named :\"open\", \"high\", \"low\", \"close\", \"volume\".\n\n    This TA Library hopefully allows you to apply familiar and unique Technical\n    Analysis Indicators easily with the DataFrame Extension named 'ta'. Even\n    though 'ta' is a Pandas DataFrame Extension, you can still call Technical\n    Analysis indicators individually if you are more comfortable with that\n    approach or it allows you to easily and automatically apply the indicators\n    with the strategy method. See: help(ta.strategy).\n\n    By default, the 'ta' extension uses lower case column names: open, high,\n    low, close, and volume. You can override the defaults by providing the it's\n    replacement name when calling the indicator. For example, to call the\n    indicator hl2().\n\n    With 'default' columns: open, high, low, close, and volume.\n    >>> df.ta.hl2()\n    >>> df.ta(kind\"hl2\")\n\n    With DataFrame columns: Open, High, Low, Close, and Volume.\n    >>> df.ta.hl2(high\"High\", low\"Low\")\n    >>> df.ta(kind\"hl2\", high\"High\", low\"Low\")\n\n    If you do not want to use a DataFrame Extension, just call it normally.\n    >>> sma10  ta.sma(df[\"Close\"]) # Default length10\n    >>> sma50  ta.sma(df[\"Close\"], length50)\n    >>> ichimoku, span  ta.ichimoku(df[\"High\"], df[\"Low\"], df[\"Close\"])\n\n    Args:\n        kind (str, optional): Default: None. Kind is the 'name' of the indicator.\n            It converts kind to lowercase before calling.\n        timed (bool, optional): Default: False. Curious about the execution\n            speed?\n        kwargs: Extension specific modifiers.\n            append (bool, optional): Default: False. When True, it appends the\n            resultant column(s) to the DataFrame.\n\n    Returns:\n        Most Indicators will return a Pandas Series. Others like MACD, BBANDS,\n        KC, et al will return a Pandas DataFrame. Ichimoku on the other hand\n        will return two DataFrames, the Ichimoku DataFrame for the known period\n        and a Span DataFrame for the future of the Span values.\n\n    Let's get started!\n\n    1. Loading the 'ta' module:\n    >>> import pandas as pd\n    >>> import ta as ta\n\n    2. Load some data:\n    >>> df  pd.read_csv(\"AAPL.csv\", index_col\"date\", parse_datesTrue)\n\n    3. Help!\n    3a. General Help:\n    >>> help(df.ta)\n    >>> df.ta()\n    3b. Indicator Help:\n    >>> help(ta.apo)\n    3c. Indicator Extension Help:\n    >>> help(df.ta.apo)\n\n    4. Ways of calling an indicator.\n    4a. Standard: Calling just the APO indicator without \"ta\" DataFrame extension.\n    >>> ta.apo(df[\"close\"])\n    4b. DataFrame Extension: Calling just the APO indicator with \"ta\" DataFrame extension.\n    >>> df.ta.apo()\n    4c. DataFrame Extension (kind): Calling APO using 'kind'\n    >>> df.ta(kind\"apo\")\n    4d. Strategy:\n    >>> df.ta.strategy(\"All\") # Default\n    >>> df.ta.strategy(ta.Strategy(\"My Strat\", ta[{\"kind\": \"apo\"}])) # Custom\n\n    5. Working with kwargs\n    5a. Append the result to the working df.\n    >>> df.ta.apo(appendTrue)\n    5b. Timing an indicator.\n    >>> apo  df.ta(kind\"apo\", timedTrue)\n    >>> print(apo.timed)\n    \"\"\"\n\n    _adjusted  None\n    _cores  cpu_count()\n    _df  DataFrame()\n    _exchange  \"NYSE\"\n    _time_range  \"years\"\n    _last_run  get_time(_exchange, to_stringTrue)\n\n    # def __init__(self, pandas_obj):\n    #     # self._validate(pandas_obj)\n    #     self._df  pandas_obj\n    #     self._last_run  get_time(self._exchange, to_stringTrue)\n\n    # @staticmethod\n    # def _validate(df: Tuple[pd.DataFrame, pd.Series]):\n    #     if isinstance(df, pd.Series) or isinstance(df, pd.DataFrame):\n    #         raise AttributeError(\"[X] Must be either a Pandas Series or DataFrame.\")\n\n    # DataFrame Behavioral Methods\n    def __call__(\n            self, kind: str  None,\n            timed: bool  False, version: bool  False, **kwargs\n        ):\n        if version: print(f\"Pandas TA - Technical Analysis Indicators - v{self.version}\")\n        try:\n            if isinstance(kind, str):\n                kind  kind.lower()\n                fn  getattr(self, kind)\n\n                if timed:\n                    stime  perf_counter()\n\n                # Run the indicator\n                result  fn(**kwargs)  #  getattr(self, kind)(**kwargs)\n                self._last_run  get_time(self.exchange, to_stringTrue) # Save when it completed it's run\n\n                if timed:\n                    result.timed  final_time(stime)\n                    print(f\"[+] {kind}: {result.timed}\")\n\n                return result\n            else:\n                self.help()\n\n        except BaseException:\n            pass\n\n    # Public Get/Set DataFrame Properties\n    @property\n    def adjusted(self) -> str:\n        \"\"\"property: df.ta.adjusted\"\"\"\n        return self._adjusted\n\n    @adjusted.setter\n    def adjusted(self, value: str) -> None:\n        \"\"\"property: df.ta.adjusted  'adj_close'\"\"\"\n        if value is not None and isinstance(value, str):\n            self._adjusted  value\n        else:\n            self._adjusted  None\n\n    @property\n    def cores(self) -> str:\n        \"\"\"Returns the categories.\"\"\"\n        return self._cores\n\n    @cores.setter\n    def cores(self, value: int) -> None:\n        \"\"\"property: df.ta.cores  integer\"\"\"\n        cpus  cpu_count()\n        if value is not None and isinstance(value, int):\n            self._cores  int(value) if 0 < value < cpus else cpus\n        else:\n            self._cores  cpus\n\n    @property\n    def exchange(self) -> str:\n        \"\"\"Returns the current Exchange. Default: \"NYSE\".\"\"\"\n        return self._exchange\n\n    @exchange.setter\n    def exchange(self, value: str) -> None:\n        \"\"\"property: df.ta.exchange  \"LSE\" \"\"\"\n        if value is not None and isinstance(value, str) and value in EXCHANGE_TZ.keys():\n            self._exchange  value\n\n    @property\n    def last_run(self) -> str:\n        \"\"\"Returns the time when the DataFrame was last run.\"\"\"\n        return self._last_run\n\n    # Public Get DataFrame Properties\n    @property\n    def categories(self) -> str:\n        \"\"\"Returns the categories.\"\"\"\n        return list(Category.keys())\n\n    @property\n    def datetime_ordered(self) -> bool:\n        \"\"\"Returns True if the index is a datetime and ordered.\"\"\"\n        hasdf  hasattr(self, \"_df\")\n        if hasdf:\n            return is_datetime_ordered(self._df)\n        return hasdf\n\n    @property\n    def reverse(self) -> pd.DataFrame:\n        \"\"\"Reverses the DataFrame. Simply: df.iloc[::-1]\"\"\"\n        return self._df.iloc[::-1]\n\n    @property\n    def time_range(self) -> float:\n        \"\"\"Returns the time ranges of the DataFrame as a float. Default is in \"years\". help(ta.toal_time)\"\"\"\n        return total_time(self._df, self._time_range)\n\n    @time_range.setter\n    def time_range(self, value: str) -> None:\n        \"\"\"property: df.ta.time_range  \"years\" (Default)\"\"\"\n        if value is not None and isinstance(value, str):\n            self._time_range  value\n        else:\n            self._time_range  \"years\"\n\n    @property\n    def to_utc(self) -> None:\n        \"\"\"Sets the DataFrame index to UTC format\"\"\"\n        self._df  to_utc(self._df)\n\n    @property\n    def version(self) -> str:\n        \"\"\"Returns the version.\"\"\"\n        return version\n\n    # Private DataFrame Methods\n    def _add_prefix_suffix(self, resultNone, **kwargs) -> None:\n        \"\"\"Add prefix and/or suffix to the result columns\"\"\"\n        if result is None:\n            return\n        else:\n            prefix  suffix  \"\"\n            delimiter  kwargs.setdefault(\"delimiter\", \"_\")\n\n            if \"prefix\" in kwargs:\n                prefix  f\"{kwargs['prefix']}{delimiter}\"\n            if \"suffix\" in kwargs:\n                suffix  f\"{delimiter}{kwargs['suffix']}\"\n\n            if isinstance(result, pd.Series):\n                result.name  prefix + result.name + suffix\n            else:\n                result.columns  [prefix + column + suffix for column in result.columns]\n\n    def _append(self, resultNone, **kwargs) -> None:\n        \"\"\"Appends a Pandas Series or DataFrame columns to self._df.\"\"\"\n        if \"append\" in kwargs and kwargs[\"append\"]:\n            df  self._df\n            if df is None or result is None: return\n            else:\n                if isinstance(result, pd.DataFrame):\n                    # If specified in kwargs, rename the columns.\n                    # If not, use the default names.\n                    if \"col_names\" in kwargs and isinstance(kwargs[\"col_names\"], tuple):\n                        if len(kwargs[\"col_names\"]) > len(result.columns):\n                            for col, ind_name in zip(result.columns, kwargs[\"col_names\"]):\n                                df[ind_name]  result.loc[:, col]\n                        else:\n                            print(f\"Not enough col_names were specified : got {len(kwargs['col_names'])}, expected {len(result.columns)}.\")\n                            return\n                    else:\n                        for i, column in enumerate(result.columns):\n                            df[column]  result.iloc[:, i]\n                else:\n                    ind_name  (\n                        kwargs[\"col_names\"][0] if \"col_names\" in kwargs and\n                        isinstance(kwargs[\"col_names\"], tuple) else result.name\n                    )\n                    df[ind_name]  result\n\n    def _check_na_columns(self, stdout: bool  True):\n        \"\"\"Returns the columns in which all it's values are na.\"\"\"\n        return [x for x in self._df.columns if all(self._df[x].isna())]\n\n    def _get_column(self, series):\n        \"\"\"Attempts to get the correct series or 'column' and return it.\"\"\"\n        df  self._df\n        if df is None: return\n\n        # Explicitly passing a pd.Series to override default.\n        if isinstance(series, pd.Series):\n            return series\n        # Apply default if no series nor a default.\n        elif series is None:\n            return df[self.adjusted] if self.adjusted is not None else None\n        # Ok.  So it's a str.\n        elif isinstance(series, str):\n            # Return the df column since it's in there.\n            if series in df.columns:\n                return df[series]\n            else:\n                # Attempt to match the 'series' because it was likely\n                # misspelled.\n                matches  df.columns.str.match(series, caseFalse)\n                match  [i for i, x in enumerate(matches) if x]\n                # If found, awesome.  Return it or return the 'series'.\n                cols  \", \".join(list(df.columns))\n                NOT_FOUND  f\"[X] Ooops!!!: It's {series not in df.columns}, the series '{series}' was not found in {cols}\"\n                return df.iloc[:, match[0]] if len(match) else print(NOT_FOUND)\n\n    def _indicators_by_category(self, name: str) -> list:\n        \"\"\"Returns indicators by Categorical name.\"\"\"\n        return Category[name] if name in self.categories else None\n\n    def _mp_worker(self, arguments: tuple):\n        \"\"\"Multiprocessing Worker to handle different Methods.\"\"\"\n        method, args, kwargs  arguments\n\n        if method ! \"ichimoku\":\n            return getattr(self, method)(*args, **kwargs)\n        else:\n            return getattr(self, method)(*args, **kwargs)[0]\n\n    def _post_process(self, result, **kwargs) -> Tuple[pd.Series, pd.DataFrame]:\n        \"\"\"Applies any additional modifications to the DataFrame\n        * Applies prefixes and/or suffixes\n        * Appends the result to main DataFrame\n        \"\"\"\n        verbose  kwargs.pop(\"verbose\", False)\n        if not isinstance(result, (pd.Series, pd.DataFrame)):\n            if verbose:\n                print(f\"[X] Oops! The result was not a Series or DataFrame.\")\n            return self._df\n        else:\n            # Append only specific columns to the dataframe (via\n            # 'col_numbers':(0,1,3) for example)\n            result  (result.iloc[:, [int(n) for n in kwargs[\"col_numbers\"]]]\n                      if isinstance(result, pd.DataFrame) and\n                      \"col_numbers\" in kwargs and\n                      kwargs[\"col_numbers\"] is not None else result)\n            # Add prefix/suffix and append to the dataframe\n            self._add_prefix_suffix(resultresult, **kwargs)\n            self._append(resultresult, **kwargs)\n        return result\n\n    def _strategy_mode(self, *args) -> tuple:\n        \"\"\"Helper method to determine the mode and name of the strategy. Returns tuple: (name:str, mode:dict)\"\"\"\n        name  \"All\"\n        mode  {\"all\": False, \"category\": False, \"custom\": False}\n\n        if len(args)  0:\n            mode[\"all\"]  True\n        else:\n            if isinstance(args[0], str):\n                if args[0].lower()  \"all\":\n                    name, mode[\"all\"]  name, True\n                if args[0].lower() in self.categories:\n                    name, mode[\"category\"]  args[0], True\n\n            if isinstance(args[0], Strategy):\n                strategy_  args[0]\n                if strategy_.ta is None or strategy_.name.lower()  \"all\":\n                    name, mode[\"all\"]  name, True\n                elif strategy_.name.lower() in self.categories:\n                    name, mode[\"category\"]  strategy_.name, True\n                else:\n                    name, mode[\"custom\"]  strategy_.name, True\n\n        return name, mode\n\n    # Public DataFrame Methods\n    def constants(self, append: bool, values: list):\n        \"\"\"Constants\n\n        Add or remove constants to the DataFrame easily with Numpy's arrays or\n        lists. Useful when you need easily accessible horizontal lines for\n        charting.\n\n        Add constant '1' to the DataFrame\n        >>> df.ta.constants(True, [1])\n        Remove c",
        "AgentRunResult(output='Parte do arquivo pandas_ta/core.py (parte 2 de 4), no diretório raíz pandas_ta. Define métodos para gerenciar constantes, listar e executar indicadores, aplicar estratégias e carregar dados com yfinance.')\npandas_ta/core.py - Parte (2/4)\nonstant '1' to the DataFrame\n        >>> df.ta.constants(False, [1])\n\n        Adding constants for charting\n        >>> import numpy as np\n        >>> chart_lines  np.append(np.arange(-4, 5, 1), np.arange(-100, 110, 10))\n        >>> df.ta.constants(True, chart_lines)\n        Removing some constants from the DataFrame\n        >>> df.ta.constants(False, np.array([-60, -40, 40, 60]))\n\n        Args:\n            append (bool): If True, appends a Numpy range of constants to the\n                working DataFrame.  If False, it removes the constant range from\n                the working DataFrame. Default: None.\n\n        Returns:\n            Returns the appended constants\n            Returns nothing to the user.  Either adds or removes constant ranges\n            from the working DataFrame.\n        \"\"\"\n        if isinstance(values, npNdarray) or isinstance(values, list):\n            if append:\n                for x in values:\n                    self._df[f\"{x}\"]  x\n                return self._df[self._df.columns[-len(values):]]\n            else:\n                for x in values:\n                    del self._df[f\"{x}\"]\n\n    def indicators(self, **kwargs):\n        \"\"\"List of Indicators\n\n        kwargs:\n            as_list (bool, optional): When True, it returns a list of the\n                indicators. Default: False.\n            exclude (list, optional): The passed in list will be excluded\n                from the indicators list. Default: None.\n\n        Returns:\n            Prints the list of indicators. If as_listTrue, then a list.\n        \"\"\"\n        as_list  kwargs.setdefault(\"as_list\", False)\n        # Public non-indicator methods\n        helper_methods  [\"constants\", \"indicators\", \"strategy\"]\n        # Public df.ta.properties\n        ta_properties  [\n            \"adjusted\",\n            \"categories\",\n            \"cores\",\n            \"datetime_ordered\",\n            \"exchange\",\n            \"last_run\",\n            \"reverse\",\n            \"ticker\",\n            \"time_range\",\n            \"to_utc\",\n            \"version\",\n        ]\n\n        # Public non-indicator methods\n        ta_indicators  list((x for x in dir(pd.DataFrame().ta) if not x.startswith(\"_\") and not x.endswith(\"_\")))\n\n        # Add Pandas TA methods and properties to be removed\n        removed  helper_methods + ta_properties\n\n        # Add user excluded methods to be removed\n        user_excluded  kwargs.setdefault(\"exclude\", [])\n        if isinstance(user_excluded, list) and len(user_excluded) > 0:\n            removed + user_excluded\n\n        # Remove the unwanted indicators\n        [ta_indicators.remove(x) for x in removed]\n\n        # If as a list, immediately return\n        if as_list:\n            return ta_indicators\n\n        total_indicators  len(ta_indicators)\n        header  f\"Pandas TA - Technical Analysis Indicators - v{self.version}\"\n        s  f\"{header}\\nTotal Indicators: {total_indicators}\\n\"\n        if total_indicators > 0:\n            print(f\"{s}Abbreviations:\\n    {', '.join(ta_indicators)}\")\n        else:\n            print(s)\n\n    def strategy(self, *args, **kwargs):\n        \"\"\"Strategy Method\n\n        An experimental method that by default runs all applicable indicators.\n        Future implementations will allow more specific indicator generation\n        with possibly as json, yaml config file or an sqlite3 table.\n\n\n        Kwargs:\n            chunksize (bool): Adjust the chunksize for the Multiprocessing Pool.\n                Default: Number of cores of the OS\n            exclude (list): List of indicator names to exclude. Some are\n                excluded by default for various reasons; they require additional\n                sources, performance (td_seq), not a ohlcv chart (vp) etc.\n            name (str): Select all indicators or indicators by\n                Category such as: \"candles\", \"cycles\", \"momentum\", \"overlap\",\n                \"performance\", \"statistics\", \"trend\", \"volatility\", \"volume\", or\n                \"all\". Default: \"all\"\n            ordered (bool): Whether to run \"all\" in order. Default: True\n            timed (bool): Show the process time of the strategy().\n                Default: False\n            verbose (bool): Provide some additional insight on the progress of\n                the strategy() execution. Default: False\n        \"\"\"\n        # cpus  cpu_count()\n        # Ensure indicators are appended to the DataFrame\n        kwargs[\"append\"]  True\n        all_ordered  kwargs.pop(\"ordered\", True)\n        mp_chunksize  kwargs.pop(\"chunksize\", self.cores)\n\n        # Initialize\n        initial_column_count  len(self._df.columns)\n        excluded  [\n            \"above\",\n            \"above_value\",\n            \"below\",\n            \"below_value\",\n            \"cross\",\n            \"cross_value\",\n            # \"data\", # reserved\n            \"long_run\",\n            \"short_run\",\n            \"trend_return\",\n            \"td_seq\", # Performance exclusion\n            \"vp\",\n        ]\n\n        # Get the Strategy Name and mode\n        name, mode  self._strategy_mode(*args)\n\n        # If All or a Category, exclude user list if any\n        user_excluded  kwargs.pop(\"exclude\", [])\n        if mode[\"all\"] or mode[\"category\"]:\n            excluded + user_excluded\n\n        # Collect the indicators, remove excluded or include kwarg[\"append\"]\n        if mode[\"category\"]:\n            ta  self._indicators_by_category(name.lower())\n            [ta.remove(x) for x in excluded if x in ta]\n        elif mode[\"custom\"]:\n            ta  args[0].ta\n            for kwds in ta:\n                kwds[\"append\"]  True\n        elif mode[\"all\"]:\n            ta  self.indicators(as_listTrue, excludeexcluded)\n        else:\n            print(f\"[X] Not an available strategy.\")\n            return None\n\n        # Remove Custom indicators with \"length\" keyword when larger than the DataFrame\n        # Possible to have other indicator main window lengths to be included\n        removal  []\n        for kwds in ta:\n            _  False\n            if \"length\" in kwds and kwds[\"length\"] > self._df.shape[0]: _  True\n            if _: removal.append(kwds)\n        if len(removal) > 0: [ta.remove(x) for x in removal]\n\n        verbose  kwargs.pop(\"verbose\", False)\n        if verbose:\n            print(f\"[+] Strategy: {name}\\n[i] Indicator arguments: {kwargs}\")\n            if mode[\"all\"] or mode[\"category\"]:\n                excluded_str  \", \".join(excluded)\n                print(f\"[i] Excluded[{len(excluded)}]: {excluded_str}\")\n\n        timed  kwargs.pop(\"timed\", False)\n        results  []\n        use_multiprocessing  True if self.cores > 0 else False\n        has_col_names  False\n\n        if timed:\n            stime  perf_counter()\n\n        if use_multiprocessing and mode[\"custom\"]:\n            # Determine if the Custom Model has 'col_names' parameter\n            has_col_names  (True if len([\n                True for x in ta\n                if \"col_names\" in x and isinstance(x[\"col_names\"], tuple)\n            ]) else False)\n\n            if has_col_names:\n                use_multiprocessing  False\n\n        if use_multiprocessing:\n            _total_ta  len(ta)\n            pool  Pool(self.cores)\n            # Some magic to optimize chunksize for speed based on total ta indicators\n            _chunksize  mp_chunksize - 1 if mp_chunksize > _total_ta else int(npLog10(_total_ta)) + 1\n            if verbose:\n                print(f\"[i] Multiprocessing {_total_ta} indicators with {_chunksize} chunks and {self.cores}/{cpu_count()} cpus.\")\n\n            results  None\n            if mode[\"custom\"]:\n                # Create a list of all the custom indicators into a list\n                custom_ta  [(\n                    ind[\"kind\"],\n                    ind[\"params\"] if \"params\" in ind and isinstance(ind[\"params\"], tuple) else (),\n                    {**ind, **kwargs},\n                ) for ind in ta]\n                # Custom multiprocessing pool. Must be ordered for Chained Strategies\n                # May fix this to cpus if Chaining/Composition if it remains\n                results  pool.imap(self._mp_worker, custom_ta, _chunksize)\n            else:\n                default_ta  [(ind, tuple(), kwargs) for ind in ta]\n                # All and Categorical multiprocessing pool.\n                if all_ordered:\n                    results  pool.imap(self._mp_worker, default_ta, _chunksize) # Order over Speed\n                else:\n                    results  pool.imap_unordered(self._mp_worker, default_ta, _chunksize) # Speed over Order\n            if results is None:\n                print(f\"[X] ta.strategy('{name}') has no results.\")\n                return\n\n            pool.close()\n            pool.join()\n            self._last_run  get_time(self.exchange, to_stringTrue)\n\n        else:\n            # Without multiprocessing:\n            if verbose:\n                if has_col_names:\n                    print(f\"[i] No mulitproccessing support for 'col_names' option.\")\n                else:\n                    print(f\"[i] No mulitproccessing (cores  0).\")\n\n            if mode[\"custom\"]:\n                for ind in ta:\n                    params  ind[\"params\"] if \"params\" in ind and isinstance(ind[\"params\"], tuple) else tuple()\n                    getattr(self, ind[\"kind\"])(*params, **{**ind, **kwargs})\n            else:\n                for ind in ta:\n                    getattr(self, ind)(*tuple(), **kwargs)\n\n        # Apply prefixes/suffixes and appends indicator results to the\n        # DataFrame\n        [self._post_process(r, **kwargs) for r in results]\n\n        if verbose:\n            print(f\"[i] Total indicators: {len(ta)}\")\n            print(f\"[i] Columns added: {len(self._df.columns) - initial_column_count}\")\n            print(f\"[i] Last Run: {self._last_run}\")\n        if timed:\n            print(f\"[i] Runtime: {final_time(stime)}\")\n\n    def ticker(self, ticker: str, **kwargs):\n        \"\"\"ticker\n\n        This method downloads Historical Data if the package yfinance is installed.\n        Additionally it can run a ta.Strategy; Builtin or Custom. It returns a\n        DataFrame if there the DataFrame is not empty, otherwise it exits. For\n        additional yfinance arguments, use help(ta.yf).\n\n        Historical Data\n        >>> df  df.ta.ticker(\"aapl\")\n        More specifically\n        >>> df  df.ta.ticker(\"aapl\", period\"max\", interval\"1d\", kindNone)\n\n        Changing the period of Historical Data\n        Period is used instead of start/end\n        >>> df  df.ta.ticker(\"aapl\", period\"1y\")\n\n        Changing the period and interval of Historical Data\n        Retrieves the past year in weeks\n        >>> df  df.ta.ticker(\"aapl\", period\"1y\", interval\"1wk\")\n        Retrieves the past month in hours\n        >>> df  df.ta.ticker(\"aapl\", period\"1mo\", interval\"1h\")\n\n        Show everything\n        >>> df  df.ta.ticker(\"aapl\", kind\"all\")\n\n        Args:\n            ticker (str): Any string for a ticker you would use with yfinance.\n                Default: \"SPY\"\n        Kwargs:\n            kind (str): Options see above. Default: \"history\"\n            ds (str): Data Source to use. Default: \"yahoo\"\n            strategy (str | ta.Strategy): Which strategy to apply after\n                downloading chart history. Default: None\n\n            See help(ta.yf) for additional kwargs\n\n        Returns:\n            Exits if the DataFrame is empty or None\n            Otherwise it returns a DataFrame\n        \"\"\"\n        ds  kwargs.pop(\"ds\", \"yahoo\")\n        strategy  kwargs.pop(\"strategy\", None)\n\n        # Fetch the Data\n        ds  ds.lower() is not None and isinstance(ds, str)\n        # df  av(ticker, **kwargs) if ds and ds  \"av\" else yf(ticker, **kwargs)\n        df  yf(ticker, **kwargs)\n\n        if df is None: return\n        elif df.empty:\n            print(f\"[X] DataFrame is empty: {df.shape}\")\n            return\n        else:\n            if kwargs.pop(\"lc_input\", False):\n                df.index.name  df.index.name.lower()\n                df.columns  df.columns.str.lower()\n            self._df  df\n\n        if strategy is not None: self.strategy(strategy, **kwargs)\n        return df\n\n\n    # Public DataFrame Methods: Indicators and Utilities\n    # Candles\n    def cdl_doji(self, offsetNone, **kwargs):\n        open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  cdl_doji(open_open_, highhigh, lowlow, closeclose, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def cdl_inside(self, offsetNone, **kwargs):\n        open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  cdl_inside(open_open_, highhigh, lowlow, closeclose, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def ha(self, offsetNone, **kwargs):\n        open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  ha(open_open_, highhigh, lowlow, closeclose, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    # Cycles\n    def ebsw(self, closeNone, lengthNone, barsNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  ebsw(closeclose, lengthlength, barsbars, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    # Momentum\n    def ao(self, fastNone, slowNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        result  ao(highhigh, lowlow, fastfast, slowslow, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def apo(self, fastNone, slowNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  apo(closeclose, fastfast, slowslow, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def bias(self, lengthNone, mamodeNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  bias(closeclose, lengthlength, mamodemamode, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def bop(self, percentageFalse, offsetNone, **kwargs):\n        open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  bop(open_open_, highhigh, lowlow, closeclose, percentagepercentage, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def brar(self, lengthNone, scalarNone, driftNone, offsetNone, **kwargs):\n        open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  brar(open_open_, highhigh, lowlow, closeclose, lengthlength, scalarscalar, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def cci(self, lengthNone, cNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  cci(highhigh, lowlow, closeclose, lengthlength, cc, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def cfo(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  cfo(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def cg(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  cg(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def cmo(self, lengthNone, scalarNone, driftNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  cmo(closeclose, lengthlength, scalarscalar, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def coppock(self, lengthNone, fastNone, slowNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  coppock(closeclose, lengthlength, fastfast, slowslow, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def er(self, lengthNone, driftNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  er(closeclose, lengthlength, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def eri(self, lengthNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  eri(highhigh, lowlow, closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def fisher(self, lengthNone, signalNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        result  fisher(highhigh, lowlow, lengthlength, signalsignal, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def inertia(self, lengthNone, rvi_lengthNone, scalarNone, refinedNone, thirdsNone, mamodeNone, driftNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        if refined is not None or thirds is not None:\n            high  self._get_column(kwargs.pop(\"high\", \"high\"))\n            low  self._get_column(kwargs.pop(\"low\", \"low\"))\n            result  inertia(closeclose, highhigh, lowlow, lengthlength, rvi_lengthrvi_length, scalarscalar, refinedrefined, thirdsthirds, mamodemamode, driftdrift, offsetoffset, **kwargs)\n        else:\n            result  inertia(closeclose, lengthlength, rvi_lengthrvi_length, scalarscalar, refinedrefined, thirdsthirds, mamodemamode, driftdrift, offsetoffset, **kwargs)\n\n        return self._post_process(result, **kwargs)\n\n    def kdj(self, lengthNone, signalNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  kdj(highhigh, lowlow, closeclose, lengthlength, signalsignal, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def kst(self, roc1None, roc2None, roc3None, roc4None, sma1None, sma2None, sma3None, sma4None, signalNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  kst(closeclose, roc1roc1, roc2roc2, roc3roc3, ",
        "AgentRunResult(output='Terceira parte do arquivo `core.py` na pasta `pandas_ta`, que implementa métodos para calcular indicadores técnicos como MACD, RSI, EMA, Ichimoku, VWAP e estatísticas como entropia e kurtosis.')\npandas_ta/core.py - Parte (3/4)\nroc4roc4, sma1sma1, sma2sma2, sma3sma3, sma4sma4, signalsignal, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def macd(self, fastNone, slowNone, signalNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  macd(closeclose, fastfast, slowslow, signalsignal, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def mom(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  mom(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def pgo(self, lengthNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  pgo(highhigh, lowlow, closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def ppo(self, fastNone, slowNone, scalarNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  ppo(closeclose, fastfast, slowslow, scalarscalar, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def psl(self, open_None, lengthNone, scalarNone, driftNone, offsetNone, **kwargs):\n        if open_ is not None:\n            open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  psl(closeclose, open_open_, lengthlength, scalarscalar, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def pvo(self, fastNone, slowNone, signalNone, scalarNone, offsetNone, **kwargs):\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  pvo(volumevolume, fastfast, slowslow, signalsignal, scalarscalar, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def qqe(self, lengthNone, smoothNone, factorNone, mamodeNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  qqe(closeclose, lengthlength, smoothsmooth, factorfactor, mamodemamode, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def roc(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  roc(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def rsi(self, lengthNone, scalarNone, driftNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  rsi(closeclose, lengthlength, scalarscalar, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def rsx(self, lengthNone, driftNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  rsx(closeclose, lengthlength, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def rvgi(self, lengthNone, swma_lengthNone, offsetNone, **kwargs):\n        open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  rvgi(open_open_, highhigh, lowlow, closeclose, lengthlength, swma_lengthswma_length, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def slope(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  slope(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def smi(self, fastNone, slowNone, signalNone, scalarNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  smi(closeclose, fastfast, slowslow, signalsignal, scalarscalar, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def squeeze(self, bb_lengthNone, bb_stdNone, kc_lengthNone, kc_scalarNone, mom_lengthNone, mom_smoothNone, use_trNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  squeeze(highhigh, lowlow, closeclose, bb_lengthbb_length, bb_stdbb_std, kc_lengthkc_length, kc_scalarkc_scalar, mom_lengthmom_length, mom_smoothmom_smooth, use_truse_tr, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def stoch(self, fast_kNone, slow_kNone, slow_dNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  stoch(highhigh, lowlow, closeclose, fast_kfast_k, slow_kslow_k, slow_dslow_d, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def stochrsi(self, lengthNone, rsi_lengthNone, kNone, dNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  stochrsi(highhigh, lowlow, closeclose, lengthlength, rsi_lengthrsi_length, kk, dd, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def td_seq(self, asintNone, offsetNone, show_allNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  td_seq(closeclose, asintasint, offsetoffset, show_allshow_all, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def trix(self, lengthNone, signalNone, scalarNone, driftNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  trix(closeclose, lengthlength, signalsignal, scalarscalar, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def tsi(self, fastNone, slowNone, driftNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  tsi(closeclose, fastfast, slowslow, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def uo(self, fastNone, mediumNone, slowNone, fast_wNone, medium_wNone, slow_wNone, driftNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  uo(highhigh, lowlow, closeclose, fastfast, mediummedium, slowslow, fast_wfast_w, medium_wmedium_w, slow_wslow_w, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def willr(self, lengthNone, percentageTrue, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  willr(highhigh, lowlow, closeclose, lengthlength, percentagepercentage, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    # Overlap\n    def alma(self, lengthNone, sigmaNone, distribution_offsetNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  alma(closeclose, lengthlength, sigmasigma, distribution_offsetdistribution_offset, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def dema(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  dema(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def ema(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  ema(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def fwma(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  fwma(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def hilo(self, high_lengthNone, low_lengthNone, mamodeNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  hilo(highhigh, lowlow, closeclose, high_lengthhigh_length, low_lengthlow_length, mamodemamode, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def hl2(self, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        result  hl2(highhigh, lowlow, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def hlc3(self, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  hlc3(highhigh, lowlow, closeclose, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def hma(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  hma(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def hwma(self, naNone, nbNone, ncNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  hwma(closeclose, nana, nbnb, ncnc, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def kama(self, lengthNone, fastNone, slowNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  kama(closeclose, lengthlength, fastfast, slowslow, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def ichimoku(self, tenkanNone, kijunNone, senkouNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result, span  ichimoku(highhigh, lowlow, closeclose, tenkantenkan, kijunkijun, senkousenkou, offsetoffset, **kwargs)\n        self._add_prefix_suffix(result, **kwargs)\n        self._add_prefix_suffix(span, **kwargs)\n        self._append(result, **kwargs)\n        # return self._post_process(result, **kwargs), span\n        return result, span\n\n    def linreg(self, lengthNone, offsetNone, adjustNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  linreg(closeclose, lengthlength, offsetoffset, adjustadjust, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def mcgd(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  mcgd(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def midpoint(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  midpoint(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def midprice(self, lengthNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        result  midprice(highhigh, lowlow, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def ohlc4(self, offsetNone, **kwargs):\n        open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  ohlc4(open_open_, highhigh, lowlow, closeclose, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def pwma(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  pwma(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def rma(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  rma(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def sinwma(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  sinwma(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def sma(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  sma(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def ssf(self, lengthNone, polesNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  ssf(closeclose, lengthlength, polespoles, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def supertrend(self, lengthNone, multiplierNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  supertrend(highhigh, lowlow, closeclose, lengthlength, multipliermultiplier, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def swma(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  swma(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def t3(self, lengthNone, aNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  t3(closeclose, lengthlength, aa, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def tema(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  tema(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def trima(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  trima(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def vidya(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  vidya(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def vwap(self, anchorNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n\n        if not self.datetime_ordered:\n            volume.index  self._df.index\n\n        result  vwap(highhigh, lowlow, closeclose, volumevolume, anchoranchor, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def vwma(self, volumeNone, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  vwma(closeclose, volumeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def wcp(self, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  wcp(highhigh, lowlow, closeclose, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def wma(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  wma(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def zlma(self, lengthNone, mamodeNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  zlma(closeclose, lengthlength, mamodemamode, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    # Performance\n    def log_return(self, lengthNone, cumulativeFalse, percentFalse, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  log_return(closeclose, lengthlength, cumulativecumulative, percentpercent, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def percent_return(self, lengthNone, cumulativeFalse, percentFalse, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  percent_return(closeclose, lengthlength, cumulativecumulative, percentpercent, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def trend_return(self, trendNone, logTrue, asboolNone, offsetNone, trend_resetNone, **kwargs):\n        if trend is None:\n            return self._df\n        else:\n            close  self._get_column(kwargs.pop(\"close\", \"close\"))\n            result  trend_return(closeclose, trendtrend, loglog, asboolasbool, offsetoffset, trend_resettrend_reset, **kwargs)\n            return self._post_process(result, **kwargs)\n\n    # Statistics\n    def entropy(self, lengthNone, baseNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  entropy(closeclose, lengthlength, basebase, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def kurtosis(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  kurtosis(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def mad(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  mad(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def median(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  median(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def quantile(self, lengthNone, qNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  quantile(closeclose, lengthlength, qq, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def skew(self, lengthNone, offsetNo",
        "AgentRunResult(output='Parte final do arquivo pandas_ta/core.py, localizado na raiz/pandas_ta. Contém métodos que implementam indicadores técnicos de tendência, volatilidade, volume e utilitários para análise técnica.')\npandas_ta/core.py - Parte (4/4)\nne, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  skew(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def stdev(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  stdev(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def variance(self, lengthNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  variance(closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def zscore(self, lengthNone, stdNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  zscore(closeclose, lengthlength, stdstd, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    # Trend\n    def adx(self, lengthNone, scalarNone, driftNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  adx(highhigh, lowlow, closeclose, lengthlength, scalarscalar, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def amat(self, fastNone, slowNone, mamodeNone, lookbackNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  amat(closeclose, fastfast, slowslow, mamodemamode, lookbacklookback, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def aroon(self, lengthNone, scalarNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        result  aroon(highhigh, lowlow, lengthlength, scalarscalar, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def chop(self, lengthNone, atr_lengthNone, scalarNone, driftNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  chop(highhigh, lowlow, closeclose, lengthlength, atr_lengthatr_length, scalarscalar, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def cksp(self, pNone, xNone, qNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  cksp(highhigh, lowlow, closeclose, pp, xx, qq, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def decay(self, lengthNone, modeNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  decay(closeclose, lengthlength, modemode, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def decreasing(self, lengthNone, strictNone, asintNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  decreasing(closeclose, lengthlength, strictstrict, asintasint, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def dpo(self, lengthNone, centeredTrue, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  dpo(closeclose, lengthlength, centeredcentered, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def increasing(self, lengthNone, strictNone, asintNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  increasing(closeclose, lengthlength, strictstrict, asintasint, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def long_run(self, fastNone, slowNone, lengthNone, offsetNone, **kwargs):\n        if fast is None and slow is None:\n            return self._df\n        else:\n            result  long_run(fastfast, slowslow, lengthlength, offsetoffset, **kwargs)\n            return self._post_process(result, **kwargs)\n\n    def psar(self, afNone, max_afNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", None))\n        result  psar(highhigh, lowlow, closeclose, afaf, max_afmax_af, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def qstick(self, lengthNone, offsetNone, **kwargs):\n        open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  qstick(open_open_, closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def short_run(self, fastNone, slowNone, lengthNone, offsetNone, **kwargs):\n        if fast is None and slow is None:\n            return self._df\n        else:\n            result  short_run(fastfast, slowslow, lengthlength, offsetoffset, **kwargs)\n            return self._post_process(result, **kwargs)\n\n    def supertrend(self, periodNone, multiplierNone, mamodeNone, driftNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  supertrend(highhigh, lowlow, closeclose, periodperiod, multipliermultiplier, mamodemamode, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def ttm_trend(self, lengthNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  ttm_trend(highhigh, lowlow, closeclose, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def vortex(self, driftNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  vortex(highhigh, lowlow, closeclose, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    # Utility\n    def above(self, asintTrue, offsetNone, **kwargs):\n        a  self._get_column(kwargs.pop(\"close\", \"a\"))\n        b  self._get_column(kwargs.pop(\"close\", \"b\"))\n        result  above(series_aa, series_bb, asintasint, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def above_value(self, valueNone, asintTrue, offsetNone, **kwargs):\n        a  self._get_column(kwargs.pop(\"close\", \"a\"))\n        result  above_value(series_aa, valuevalue, asintasint, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def below(self, asintTrue, offsetNone, **kwargs):\n        a  self._get_column(kwargs.pop(\"close\", \"a\"))\n        b  self._get_column(kwargs.pop(\"close\", \"b\"))\n        result  below(series_aa, series_bb, asintasint, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def below_value(self, valueNone, asintTrue, offsetNone, **kwargs):\n        a  self._get_column(kwargs.pop(\"close\", \"a\"))\n        result  below_value(series_aa, valuevalue, asintasint, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def cross(self, aboveTrue, asintTrue, offsetNone, **kwargs):\n        a  self._get_column(kwargs.pop(\"close\", \"a\"))\n        b  self._get_column(kwargs.pop(\"close\", \"b\"))\n        result  cross(series_aa, series_bb, aboveabove, asintasint, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def cross_value(self, valueNone, aboveTrue, asintTrue, offsetNone, **kwargs):\n        a  self._get_column(a, f\"{a}\")\n        result  cross_value(series_aa, valuevalue, aboveabove, asintasint, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    # Volatility\n    def aberration(self, lengthNone, atr_lengthNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  aberration(highhigh, lowlow, closeclose, lengthlength, atr_lengthatr_length, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def accbands(self, lengthNone, cNone, mamodeNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  accbands(highhigh, lowlow, closeclose, lengthlength, cc, mamodemamode, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def atr(self, lengthNone, mamodeNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  atr(highhigh, lowlow, closeclose, lengthlength, mamodemamode, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def bbands(self, lengthNone, stdNone, mamodeNone, offsetNone, **kwargs):\n        close   self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  bbands(closeclose, lengthlength, stdstd, mamodemamode, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def donchian(self, lower_lengthNone, upper_lengthNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        result  donchian(highhigh, lowlow, lower_lengthlower_length, upper_lengthupper_length, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def hwc(self, naNone, nbNone, ncNone, ndNone, scalarNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  hwc(closeclose, nana, nbnb, ncnc, ndnd, scalarscalar, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def kc(self, lengthNone, scalarNone, mamodeNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  kc(highhigh, lowlow, closeclose, lengthlength, scalarscalar, mamodemamode, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def massi(self, fastNone, slowNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        result  massi(highhigh, lowlow, fastfast, slowslow, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def natr(self, lengthNone, mamodeNone, scalarNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  natr(highhigh, lowlow, closeclose, lengthlength, mamodemamode, scalarscalar, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def pdist(self, driftNone, offsetNone, **kwargs):\n        open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  pdist(open_open_, highhigh, lowlow, closeclose, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def rvi(self, lengthNone, scalarNone, refinedNone, thirdsNone, mamodeNone, driftNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  rvi(highhigh, lowlow, closeclose, lengthlength, scalarscalar, refinedrefined, thirdsthirds, mamodemamode, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def thermo(self, longNone, short None, lengthNone, mamodeNone, driftNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        result  thermo(highhigh, lowlow, longlong, shortshort, lengthlength, mamodemamode, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def true_range(self, driftNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  true_range(highhigh, lowlow, closeclose, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def ui(self, lengthNone, scalarNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        result  ui(closeclose, lengthlength, scalarscalar, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    # Volume\n    def ad(self, open_None, signedTrue, offsetNone, **kwargs):\n        if open_ is not None:\n            open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  ad(highhigh, lowlow, closeclose, volumevolume, open_open_, signedsigned, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def adosc(self, open_None, fastNone, slowNone, signedTrue, offsetNone, **kwargs):\n        if open_ is not None:\n            open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  adosc(highhigh, lowlow, closeclose, volumevolume, open_open_, fastfast, slowslow, signedsigned, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def aobv(self, fastNone, slowNone, mamodeNone, max_lookbackNone, min_lookbackNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  aobv(closeclose, volumevolume, fastfast, slowslow, mamodemamode, max_lookbackmax_lookback, min_lookbackmin_lookback, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def cmf(self, open_None, lengthNone, offsetNone, **kwargs):\n        if open_ is not None:\n            open_  self._get_column(kwargs.pop(\"open\", \"open\"))\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  cmf(highhigh, lowlow, closeclose, volumevolume, open_open_, lengthlength, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def efi(self, lengthNone, mamodeNone, offsetNone, driftNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  efi(closeclose, volumevolume, lengthlength, offsetoffset, mamodemamode, driftdrift, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def eom(self, lengthNone, divisorNone, offsetNone, driftNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  eom(highhigh, lowlow, closeclose, volumevolume, lengthlength, divisordivisor, offsetoffset, driftdrift, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def mfi(self, lengthNone, driftNone, offsetNone, **kwargs):\n        high  self._get_column(kwargs.pop(\"high\", \"high\"))\n        low  self._get_column(kwargs.pop(\"low\", \"low\"))\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  mfi(highhigh, lowlow, closeclose, volumevolume, lengthlength, driftdrift, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def nvi(self, lengthNone, initialNone, signedTrue, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  nvi(closeclose, volumevolume, lengthlength, initialinitial, signedsigned, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def obv(self, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  obv(closeclose, volumevolume, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def pvi(self, lengthNone, initialNone, signedTrue, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  pvi(closeclose, volumevolume, lengthlength, initialinitial, signedsigned, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def pvol(self, volumeNone, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  pvol(closeclose, volumevolume, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def pvr(self, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  pvr(closeclose, volumevolume)\n        return self._post_process(result, **kwargs)\n\n    def pvt(self, offsetNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  pvt(closeclose, volumevolume, offsetoffset, **kwargs)\n        return self._post_process(result, **kwargs)\n\n    def vp(self, widthNone, percentNone, **kwargs):\n        close  self._get_column(kwargs.pop(\"close\", \"close\"))\n        volume  self._get_column(kwargs.pop(\"volume\", \"volume\"))\n        result  vp(closeclose, volumevolume, widthwidth, percentpercent, **kwargs)\n        return self._post_process(result, **kwargs)\n\n\n\n",
        "AgentRunResult(output='Este conteúdo pertence ao diretório raiz pandas_ta e suas subpastas candles, cycles e momentum. Ele implementa indicadores técnicos de análise de ações com Pandas, incluindo:\\n\\n- candles: padrões de velas como Doji, Inside Bar e Heikin Ashi;\\n- cycles: técnicas cíclicas para detectar padrões de mercado como Even Better SineWave;\\n- momentum: indicadores de momentum como Awesome Oscillator, APO, Bias e Balance of Power.\\n\\nTecnologias: Pandas, NumPy, análise técnica.')\npandas_ta/candles/__init__.py\n\n# -*- coding: utf-8 -*-\nfrom .ha import ha\nfrom .cdl_doji import cdl_doji\nfrom .cdl_inside import cdl_inside\n\n\n\npandas_ta/candles/cdl_doji.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import sma\nfrom pandas_ta.utils import get_offset, high_low_range, is_percent\nfrom pandas_ta.utils import real_body, verify_series\n\n\ndef cdl_doji(open_, high, low, close, lengthNone, factorNone, scalarNone, asintTrue, offsetNone, **kwargs):\n    \"\"\"Candle Type: Doji\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    factor  float(factor) if is_percent(factor) else 10\n    scalar  float(scalar) if scalar else 100\n    open_  verify_series(open_, length)\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n    naive  kwargs.pop(\"naive\", False)\n\n    if open_ is None or high is None or low is None or close is None: return\n\n    # Calculate Result\n    body  real_body(open_, close).abs()\n    hl_range  high_low_range(high, low).abs()\n    hl_range_avg  sma(hl_range, length)\n    doji  body < 0.01 * factor * hl_range_avg\n\n    if naive:\n        doji.iloc[:length]  body < 0.01 * factor * hl_range\n    if asint:\n        doji  scalar * doji.astype(int)\n\n    # Offset\n    if offset ! 0:\n        doji  doji.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        doji.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        doji.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    doji.name  f\"CDL_DOJI_{length}_{0.01 * factor}\"\n    doji.category  \"candles\"\n\n    return doji\n\n\ncdl_doji.__doc__  \\\n\"\"\"Candle Type: Doji\n\nA candle body is Doji, when it's shorter than 10% of the\naverage of the 10 previous candles' high-low range.\n\nSources:\n    TA-Lib: 96.56% Correlation\n\nCalculation:\n    Default values:\n        length10, percent10 (0.1), scalar100\n    ABS  Absolute Value\n    SMA  Simple Moving Average\n\n    BODY  ABS(close - open)\n    HL_RANGE  ABS(high - low)\n\n    DOJI  scalar IF BODY < 0.01 * percent * SMA(HL_RANGE, length) ELSE 0\n\nArgs:\n    open_ (pd.Series): Series of 'open's\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): The period. Default: 10\n    factor (float): Doji value. Default: 100\n    scalar (float): How much to magnify. Default: 100\n    asint (bool): Keep results numerical instead of boolean. Default: True\n\nKwargs:\n    naive (bool, optional): If True, prefills potential Doji less than\n        the length if less than a percentage of it's high-low range.\n        Default: False\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: CDL_DOJI column.\n\"\"\"\n\n\n\npandas_ta/candles/cdl_inside.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import candle_color, get_offset\nfrom pandas_ta.utils import verify_series\n\n\ndef cdl_inside(open_, high, low, close, asboolFalse, offsetNone, **kwargs):\n    \"\"\"Candle Type: Inside Bar\"\"\"\n    # Validate arguments\n    open_  verify_series(open_)\n    high  verify_series(high)\n    low  verify_series(low)\n    close  verify_series(close)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    inside  (high.diff() < 0) & (low.diff() > 0)\n\n    if not asbool:\n        inside * candle_color(open_, close)\n\n    # Offset\n    if offset ! 0:\n        inside  inside.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        inside.fillna(kwargs[\"fillna\"], inplaceTrue)\n\n    if \"fill_method\" in kwargs:\n        inside.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    inside.name  f\"CDL_INSIDE\"\n    inside.category  \"candles\"\n\n    return inside\n\n\ncdl_inside.__doc__  \\\n\"\"\"Candle Type: Inside Bar\n\nAn Inside Bar is a bar that is engulfed by the prior highs and lows of it's\nprevious bar. In other words, the current bar is smaller than it's previous bar.\nSet asboolTrue if you want to know if it is an Inside Bar. Note by default\nasboolFalse so this returns a 0 if it is not an Inside Bar, 1 if it is an\nInside Bar and close > open, and -1 if it is an Inside Bar but close < open.\n\nSources:\n    https://www.tradingview.com/script/IyIGN1WO-Inside-Bar/\n\nCalculation:\n    Default Inputs:\n        asboolFalse\n    inside  (high.diff() < 0) & (low.diff() > 0)\n\n    if not asbool:\n        inside * candle_color(open_, close)\n\nArgs:\n    open_ (pd.Series): Series of 'open's\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    asbool (bool): Returns the boolean result. Default: False\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature\n\"\"\"\n\n\n\npandas_ta/candles/ha.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef ha(open_, high, low, close, offsetNone, **kwargs):\n    \"\"\"Candle Type: Heikin Ashi\"\"\"\n    # Validate Arguments\n    open_  verify_series(open_)\n    high  verify_series(high)\n    low  verify_series(low)\n    close  verify_series(close)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    m  close.size\n    df  DataFrame({\n        \"HA_open\": 0.5 * (open_.iloc[0] + close.iloc[0]),\n        \"HA_high\": high,\n        \"HA_low\": low,\n        \"HA_close\": 0.25 * (open_ + high + low + close),\n    })\n\n    for i in range(1, m):\n        df[\"HA_open\"][i]  0.5 * (df[\"HA_open\"][i - 1] + df[\"HA_close\"][i - 1])\n\n    df[\"HA_high\"]  df[[\"HA_open\", \"HA_high\", \"HA_close\"]].max(axis1)\n    df[\"HA_low\"]  df[[\"HA_open\", \"HA_low\", \"HA_close\"]].min(axis1)\n\n    # Offset\n    if offset ! 0:\n        df  df.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        df.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        df.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    df.name  \"Heikin-Ashi\"\n    df.category  \"candles\"\n\n    return df\n\n\nha.__doc__  \\\n\"\"\"Heikin Ashi Candles (HA)\n\nThe Heikin-Ashi technique averages price data to create a Japanese\ncandlestick chart that filters out market noise. Heikin-Ashi charts,\ndeveloped by Munehisa Homma in the 1700s, share some characteristics\nwith standard candlestick charts but differ based on the values used\nto create each candle. Instead of using the open, high, low, and close\nlike standard candlestick charts, the Heikin-Ashi technique uses a\nmodified formula based on two-period averages. This gives the chart a\nsmoother appearance, making it easier to spots trends and reversals,\nbut also obscures gaps and some price data.\n\nSources:\n    https://www.investopedia.com/terms/h/heikinashi.asp\n\nCalculation:\n    HA_OPEN[0]  (open[0] + close[0]) / 2\n    HA_CLOSE  (open[0] + high[0] + low[0] + close[0]) / 4\n\n    for i > 1 in df.index:\n        HA_OPEN  (HA_OPEN[iâˆ’1] + HA_CLOSE[iâˆ’1]) / 2\n\n    HA_HIGH  MAX(HA_OPEN, HA_HIGH, HA_CLOSE)\n    HA_LOW  MIN(HA_OPEN, HA_LOW, HA_CLOSE)\n\n    How to Calculate Heikin-Ashi\n\n    Use one period to create the first Heikin-Ashi (HA) candle, using\n    the formulas. For example use the high, low, open, and close to\n    create the first HA close price. Use the open and close to create\n    the first HA open. The high of the period will be the first HA high,\n    and the low will be the first HA low. With the first HA calculated,\n    it is now possible to continue computing the HA candles per the formulas.\nâ€‹â€‹\nArgs:\n    open_ (pd.Series): Series of 'open's\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: ha_open, ha_high,ha_low, ha_close columns.\n\"\"\"\n\n\n\npandas_ta/cycles/__init__.py\n\n# -*- coding: utf-8 -*-\nfrom .ebsw import ebsw\n\n\n\npandas_ta/cycles/ebsw.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import cos as npCos\nfrom numpy import exp as npExp\nfrom numpy import NaN as npNaN\nfrom numpy import pi as npPi\nfrom numpy import sin as npSin\nfrom numpy import sqrt as npSqrt\nfrom pandas import Series\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef ebsw(close, lengthNone, barsNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Even Better SineWave (EBSW)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 38 else 40\n    bars  int(bars) if bars and bars > 0 else 10\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # variables\n    alpha1  HP  0 # alpha and HighPass\n    a1  b1  c1  c2  c3  0\n    Filt  Pwr  Wave  0\n\n    lastClose  lastHP  0\n    FilterHist  [0, 0]   # Filter history\n\n    # Calculate Result\n    m  close.size\n    result  [npNaN for _ in range(0, length - 1)] + [0]\n    for i in range(length, m):\n        # HighPass filter cyclic components whose periods are shorter than Duration input\n        alpha1  (1 - npSin(360 / length)) / npCos(360 / length)\n        HP  0.5 * (1 + alpha1) * (close[i] - lastClose) + alpha1 * lastHP\n\n        # Smooth with a Super Smoother Filter from equation 3-3\n        a1  npExp(-npSqrt(2) * npPi / bars)\n        b1  2 * a1 * npCos(npSqrt(2) * 180 / bars)\n        c2  b1\n        c3  -1 * a1 * a1\n        c1  1 - c2 - c3\n        Filt  c1 * (HP + lastHP) / 2 + c2 * FilterHist[1] + c3 * FilterHist[0]\n        # Filt  float(\"{:.8f}\".format(float(Filt))) # to fix for small scientific notations, the big ones fail\n\n        # 3 Bar average of Wave amplitude and power\n        Wave  (Filt + FilterHist[1] + FilterHist[0]) / 3\n        Pwr  (Filt * Filt + FilterHist[1] * FilterHist[1] + FilterHist[0] * FilterHist[0]) / 3\n\n        # Normalize the Average Wave to Square Root of the Average Power\n        Wave  Wave / npSqrt(Pwr)\n\n        # update storage, result\n        FilterHist.append(Filt)  # append new Filt value\n        FilterHist.pop(0)  # remove first element of list (left) -> updating/trim\n        lastHP  HP\n        lastClose  close[i]\n        result.append(Wave)\n\n    ebsw  Series(result, indexclose.index)\n\n    # Offset\n    if offset ! 0:\n        ebsw  ebsw.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        ebsw.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        ebsw.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    ebsw.name  f\"EBSW_{length}_{bars}\"\n    ebsw.category  \"cycles\"\n\n    return ebsw\n\n\nebsw.__doc__  \\\n\"\"\"Even Better SineWave (EBSW) *beta*\n\nThis indicator measures market cycles and uses a low pass filter to remove noise.\nIts output is bound signal between -1 and 1 and the maximum length of a detected\ntrend is limited by its length input.\n\nWritten by rengel8 for Pandas TA based on a publication at 'prorealcode.com' and\na book by J.F.Ehlers.\n\n* This implementation seems to be logically limited. It would make sense to\nimplement exactly the version from prorealcode and compare the behaviour.\n\n\nSources:\n    https://www.prorealcode.com/prorealtime-indicators/even-better-sinewave/\n    J.F.Ehlers 'Cycle Analytics for Traders', 2014\n\nCalculation:\n    refer to 'sources' or implementation\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's max cycle/trend period. Values between 40-48 work like\n        expected with minimum value: 39. Default: 40.\n    bars (int): Period of low pass filtering. Default: 10\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/__init__.py\n\n# -*- coding: utf-8 -*-\nfrom .ao import ao\nfrom .apo import apo\nfrom .bias import bias\nfrom .bop import bop\nfrom .brar import brar\nfrom .cci import cci\nfrom .cfo import cfo\nfrom .cg import cg\nfrom .cmo import cmo\nfrom .coppock import coppock\nfrom .er import er\nfrom .eri import eri\nfrom .fisher import fisher\nfrom .inertia import inertia\nfrom .kdj import kdj\nfrom .kst import kst\nfrom .macd import macd\nfrom .mom import mom\nfrom .pgo import pgo\nfrom .ppo import ppo\nfrom .psl import psl\nfrom .pvo import pvo\nfrom .qqe import qqe\nfrom .roc import roc\nfrom .rsi import rsi\nfrom .rsx import rsx\nfrom .rvgi import rvgi\nfrom .slope import slope\nfrom .smi import smi\nfrom .squeeze import squeeze\nfrom .stoch import stoch\nfrom .stochrsi import stochrsi\nfrom .td_seq import td_seq\nfrom .trix import trix\nfrom .tsi import tsi\nfrom .uo import uo\nfrom .willr import willr\n\n\n\npandas_ta/momentum/ao.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import sma\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef ao(high, low, fastNone, slowNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Awesome Oscillator (AO)\"\"\"\n    # Validate Arguments\n    fast  int(fast) if fast and fast > 0 else 5\n    slow  int(slow) if slow and slow > 0 else 34\n    if slow < fast:\n        fast, slow  slow, fast\n    _length  max(fast, slow)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    offset  get_offset(offset)\n\n    if high is None or low is None: return\n\n    # Calculate Result\n    median_price  0.5 * (high + low)\n    fast_sma  sma(median_price, fast)\n    slow_sma  sma(median_price, slow)\n    ao  fast_sma - slow_sma\n\n    # Offset\n    if offset ! 0:\n        ao  ao.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        ao.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        ao.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    ao.name  f\"AO_{fast}_{slow}\"\n    ao.category  \"momentum\"\n\n    return ao\n\n\nao.__doc__  \\\n\"\"\"Awesome Oscillator (AO)\n\nThe Awesome Oscillator is an indicator used to measure a security's momentum.\nAO is generally used to affirm trends or to anticipate possible reversals.\n\nSources:\n    https://www.tradingview.com/wiki/Awesome_Oscillator_(AO)\n    https://www.ifcm.co.uk/ntx-indicators/awesome-oscillator\n\nCalculation:\n    Default Inputs:\n        fast5, slow34\n    SMA  Simple Moving Average\n    median  (high + low) / 2\n    AO  SMA(median, fast) - SMA(median, slow)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    fast (int): The short period. Default: 5\n    slow (int): The long period. Default: 34\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/apo.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import sma\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef apo(close, fastNone, slowNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Absolute Price Oscillator (APO)\"\"\"\n    # Validate Arguments\n    fast  int(fast) if fast and fast > 0 else 12\n    slow  int(slow) if slow and slow > 0 else 26\n    if slow < fast:\n        fast, slow  slow, fast\n    close  verify_series(close, max(fast, slow))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    fastma  sma(close, lengthfast)\n    slowma  sma(close, lengthslow)\n    apo  fastma - slowma\n\n    # Offset\n    if offset ! 0:\n        apo  apo.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        apo.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        apo.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    apo.name  f\"APO_{fast}_{slow}\"\n    apo.category  \"momentum\"\n\n    return apo\n\n\napo.__doc__  \\\n\"\"\"Absolute Price Oscillator (APO)\n\nThe Absolute Price Oscillator is an indicator used to measure a security's\nmomentum.  It is simply the difference of two Exponential Moving Averages\n(EMA) of two different periods. Note: APO and MACD lines are equivalent.\n\nSources:\n    https://www.tradingtechnologies.com/xtrader-help/x-study/technical-indicator-definitions/absolute-price-oscillator-apo/\n\nCalculation:\n    Default Inputs:\n        fast12, slow26\n    SMA  Simple Moving Average\n    APO  SMA(close, fast) - SMA(close, slow)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    fast (int): The short period. Default: 12\n    slow (int): The long period. Default: 26\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/bias.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import ma\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef bias(close, lengthNone, mamodeNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Bias (BIAS)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 26\n    mamode  mamode if isinstance(mamode, str) else \"sma\"\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    bma  ma(mamode, close, lengthlength, **kwargs)\n    bias  (close / bma) - 1\n\n    # Offset\n    if offset ! 0:\n        bias  bias.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        bias.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        bias.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    bias.name  f\"BIAS_{bma.name}\"\n    bias.category  \"momentum\"\n\n    return bias\n\n\nbias.__doc__  \\\n\"\"\"Bias (BIAS)\n\nRate of change between the source and a moving average.\n\nSources:\n    Few internet resources on definitive definition.\n    Request by Github user homily, issue #46\n\nCalculation:\n    Default Inputs:\n        length26, MA'sma'\n\n    BIAS  (close - MA(close, length)) / MA(close, length)\n          (close / MA(close, length)) - 1\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): The period. Default: 26\n    mamode (str): Options: 'ema', 'hma', 'rma', 'sma', 'wma'. Default: 'sma'\n    drift (int): The short period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/bop.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, non_zero_range, verify_series\n\n\ndef bop(open_, high, low, close, scalarNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Balance of Power (BOP)\"\"\"\n    # Validate Arguments\n    open_  verify_series(open_)\n    high  verify_series(high)\n    low  verify_series(low)\n    close  verify_series(close)\n    scalar  float(scalar) if scalar else 1\n    high_low_range  non_zero_range(high, low)\n    close_open_range  non_zero_range(close, open_)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    bop  scalar * close_open_range / high_low_range\n\n    # Offset\n    if offset ! 0:\n        bop  bop.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        bop.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        bop.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    bop.name  f\"BOP\"\n    bop.category  \"momentum\"\n\n    return bop\n\n\nbop.__doc__  \\\n\"\"\"Balance of Power (BOP)\n\nBalance of Power measure the market strength of buyers against sellers.\n\nSources:\n    http://www.worden.com/TeleChartHelp/Content/Indicators/Balance_of_Power.htm\n\nCalculation:\n    BOP  scalar * (close - open) / (high - low)\n\nArgs:\n    open (pd.Series): Series of 'open's\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    scalar (float): How much to magnify. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Este trecho pertence à subpasta pandas_ta/momentum e contém os arquivos brar.py, cci.py, cfo.py, cg.py, cmo.py, coppock.py, er.py e eri.py. Ele define indicadores técnicos de momentum, incluindo BRAR, Commodity Channel Index (CCI), Chande Forecast Oscillator (CFO), Center of Gravity (CG), Chande Momentum Oscillator (CMO), Coppock Curve, Efficiency Ratio (ER) e Elder Ray Index (ERI), principais ferramentas para análise técnica de séries temporais financeiras usando o pandas.')\npandas_ta/momentum/brar.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.utils import get_drift, get_offset, non_zero_range, verify_series\n\n\ndef brar(open_, high, low, close, lengthNone, scalarNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: BRAR (BRAR)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 26\n    scalar  float(scalar) if scalar else 100\n    high_open_range  non_zero_range(high, open_)\n    open_low_range  non_zero_range(open_, low)\n    open_  verify_series(open_, length)\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if open_ is None or high is None or low is None or close is None: return\n\n    # Calculate Result\n    hcy  non_zero_range(high, close.shift(drift))\n    cyl  non_zero_range(close.shift(drift), low)\n\n    hcy[hcy < 0]  0  # Zero negative values\n    cyl[cyl < 0]  0  # \"\"\n\n    ar  scalar * high_open_range.rolling(length).sum()\n    ar / open_low_range.rolling(length).sum()\n\n    br  scalar * hcy.rolling(length).sum()\n    br / cyl.rolling(length).sum()\n\n    # Offset\n    if offset ! 0:\n        ar  ar.shift(offset)\n        br  ar.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        ar.fillna(kwargs[\"fillna\"], inplaceTrue)\n        br.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        ar.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        br.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _props  f\"_{length}\"\n    ar.name  f\"AR{_props}\"\n    br.name  f\"BR{_props}\"\n    ar.category  br.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    brardf  DataFrame({ar.name: ar, br.name: br})\n    brardf.name  f\"BRAR{_props}\"\n    brardf.category  \"momentum\"\n\n    return brardf\n\n\nbrar.__doc__  \\\n\"\"\"BRAR (BRAR)\n\nBR and AR\n\nSources:\n    No internet resources on definitive definition.\n    Request by Github user homily, issue #46\n\nCalculation:\n    Default Inputs:\n        length26, scalar100\n    SUM  Sum\n\n    HO_Diff  high - open\n    OL_Diff  open - low\n    HCY  high - close[-1]\n    CYL  close[-1] - low\n    HCY[HCY < 0]  0\n    CYL[CYL < 0]  0\n    AR  scalar * SUM(HO, length) / SUM(OL, length)\n    BR  scalar * SUM(HCY, length) / SUM(CYL, length)\n\nArgs:\n    open_ (pd.Series): Series of 'open's\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): The period. Default: 26\n    scalar (float): How much to magnify. Default: 100\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: ar, br columns.\n\"\"\"\n\n\n\npandas_ta/momentum/cci.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import hlc3, sma\nfrom pandas_ta.statistics.mad import mad\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef cci(high, low, close, lengthNone, cNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Commodity Channel Index (CCI)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 14\n    c  float(c) if c and c > 0 else 0.015\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    typical_price  hlc3(highhigh, lowlow, closeclose)\n    mean_typical_price  sma(typical_price, lengthlength)\n    mad_typical_price  mad(typical_price, lengthlength)\n\n    cci  typical_price - mean_typical_price\n    cci / c * mad_typical_price\n\n    # Offset\n    if offset ! 0:\n        cci  cci.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        cci.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        cci.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    cci.name  f\"CCI_{length}_{c}\"\n    cci.category  \"momentum\"\n\n    return cci\n\n\ncci.__doc__  \\\n\"\"\"Commodity Channel Index (CCI)\n\nCommodity Channel Index is a momentum oscillator used to primarily identify\noverbought and oversold levels relative to a mean.\n\nSources:\n    https://www.tradingview.com/wiki/Commodity_Channel_Index_(CCI)\n\nCalculation:\n    Default Inputs:\n        length14, c0.015\n    SMA  Simple Moving Average\n    MAD  Mean Absolute Deviation\n    tp  typical_price  hlc3  (high + low + close) / 3\n    mean_tp  SMA(tp, length)\n    mad_tp  MAD(tp, length)\n    CCI  (tp - mean_tp) / (c * mad_tp)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 14\n    c (float): Scaling Constant. Default: 0.015\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/cfo.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import linreg\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef cfo(close, lengthNone, scalarNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Chande Forcast Oscillator (CFO)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 9\n    scalar  float(scalar) if scalar else 100\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Finding linear regression of Series\n    cfo  scalar * (close - linreg(close, lengthlength, tsfTrue))\n    cfo / close\n\n    # Offset\n    if offset ! 0:\n        cfo  cfo.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        cfo.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        cfo.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    cfo.name  f\"CFO_{length}\"\n    cfo.category  \"momentum\"\n\n    return cfo\n\n\ncfo.__doc__  \\\n\"\"\"Chande Forcast Oscillator (CFO)\n\nThe Forecast Oscillator calculates the percentage difference between the actual\nprice and the Time Series Forecast (the endpoint of a linear regression line).\n\nSources:\n    https://www.fmlabs.com/reference/default.htm?urlForecastOscillator.htm\n\nCalculation:\n    Default Inputs:\n        length9, drift1, scalar100\n    LINREG  Linear Regression\n\n    CFO  scalar * (close - LINERREG(length, tdfTrue)) / close\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): The period. Default: 9\n    scalar (float): How much to magnify. Default: 100\n    drift (int): The short period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/cg.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series, weights\n\n\ndef cg(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Center of Gravity (CG)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    coefficients  [length - i for i in range(0, length)]\n    numerator  -close.rolling(length).apply(weights(coefficients), rawTrue)\n    cg  numerator / close.rolling(length).sum()\n\n    # Offset\n    if offset ! 0:\n        cg  cg.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        cg.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        cg.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    cg.name  f\"CG_{length}\"\n    cg.category  \"momentum\"\n\n    return cg\n\n\ncg.__doc__  \\\n\"\"\"Center of Gravity (CG)\n\nThe Center of Gravity Indicator by John Ehlers attempts to identify turning\npoints while exhibiting zero lag and smoothing.\n\nSources:\n    http://www.mesasoftware.com/papers/TheCGOscillator.pdf\n\nCalculation:\n    Default Inputs:\n        length10\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): The length of the period. Default: 10\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/cmo.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import rma\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef cmo(close, lengthNone, scalarNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Chande Momentum Oscillator (CMO)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 14\n    scalar  float(scalar) if scalar else 100\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    mom  close.diff(drift)\n    positive  mom.copy().clip(lower0)\n    negative  mom.copy().clip(upper0).abs()\n\n    talib  kwargs.pop(\"talib\", True)\n    if talib:\n        pos_  rma(positive, length)\n        neg_  rma(negative, length)\n    else:\n        pos_  positive.rolling(length).sum()\n        neg_  negative.rolling(length).sum()\n\n    cmo  scalar * (pos_ - neg_) / (pos_ + neg_)\n\n    # Offset\n    if offset ! 0:\n        cmo  cmo.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        cmo.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        cmo.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    cmo.name  f\"CMO_{length}\"\n    cmo.category  \"momentum\"\n\n    return cmo\n\n\ncmo.__doc__  \\\n\"\"\"Chande Momentum Oscillator (CMO)\n\nAttempts to capture the momentum of an asset with overbought at 50 and\noversold at -50.\n\nSources:\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/chande-momentum-oscillator-cmo/\n    https://www.tradingview.com/script/hdrf0fXV-Variable-Index-Dynamic-Average-VIDYA/\n\nCalculation:\n    Default Inputs:\n        drift1, scalar100\n\n    # Same Calculation as RSI except for this step\n    CMO  scalar * (PSUM - NSUM) / (PSUM + NSUM)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    scalar (float): How much to magnify. Default: 100\n    drift (int): The short period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    talib (bool): If True, uses TA-Libs implementation. Otherwise uses EMA version. Default: True\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/coppock.py\n\n# -*- coding: utf-8 -*-\nfrom .roc import roc\nfrom pandas_ta.overlap import wma\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef coppock(close, lengthNone, fastNone, slowNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Coppock Curve (COPC)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    fast  int(fast) if fast and fast > 0 else 11\n    slow  int(slow) if slow and slow > 0 else 14\n    close  verify_series(close, max(length, fast, slow))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    total_roc  roc(close, fast) + roc(close, slow)\n    coppock  wma(total_roc, length)\n\n    # Offset\n    if offset ! 0:\n        coppock  coppock.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        coppock.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        coppock.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    coppock.name  f\"COPC_{fast}_{slow}_{length}\"\n    coppock.category  \"momentum\"\n\n    return coppock\n\n\ncoppock.__doc__  \\\n\"\"\"Coppock Curve (COPC)\n\nCoppock Curve (originally called the \"Trendex Model\") is a momentum indicator\nis designed for use on a monthly time scale.  Although designed for monthly\nuse, a daily calculation over the same period can be made, converting the\nperiods to 294-day and 231-day rate of changes, and a 210-day weighted\nmoving average.\n\nSources:\n    https://en.wikipedia.org/wiki/Coppock_curve\n\nCalculation:\n    Default Inputs:\n        length10, fast11, slow14\n    SMA  Simple Moving Average\n    MAD  Mean Absolute Deviation\n    tp  typical_price  hlc3  (high + low + close) / 3\n    mean_tp  SMA(tp, length)\n    mad_tp  MAD(tp, length)\n    CCI  (tp - mean_tp) / (c * mad_tp)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): WMA period. Default: 10\n    fast (int): Fast ROC period. Default: 11\n    slow (int): Slow ROC period. Default: 14\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/er.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame, concat\nfrom pandas_ta.utils import get_drift, get_offset, verify_series, signals\n\n\ndef er(close, lengthNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Efficiency Ratio (ER)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 10\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n    drift  get_drift(drift)\n\n    if close is None: return\n\n    # Calculate Result\n    abs_diff  close.diff(length).abs()\n    abs_volatility  close.diff(drift).abs()\n\n    er  abs_diff\n    er / abs_volatility.rolling(windowlength).sum()\n\n    # Offset\n    if offset ! 0:\n        er  er.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        er.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        er.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    er.name  f\"ER_{length}\"\n    er.category  \"momentum\"\n\n    signal_indicators  kwargs.pop(\"signal_indicators\", False)\n    if signal_indicators:\n        signalsdf  concat(\n            [\n                DataFrame({er.name: er}),\n                signals(\n                    indicatorer,\n                    xakwargs.pop(\"xa\", 80),\n                    xbkwargs.pop(\"xb\", 20),\n                    xseriekwargs.pop(\"xserie\", None),\n                    xserie_akwargs.pop(\"xserie_a\", None),\n                    xserie_bkwargs.pop(\"xserie_b\", None),\n                    cross_valueskwargs.pop(\"cross_values\", False),\n                    cross_serieskwargs.pop(\"cross_series\", True),\n                    offsetoffset,\n                ),\n            ],\n            axis1,\n        )\n\n        return signalsdf\n    else:\n        return er\n\n\ner.__doc__  \\\n\"\"\"Efficiency Ratio (ER)\n\nThe Efficiency Ratio was invented by Perry J. Kaufman and presented in his book \"New Trading Systems and Methods\". It is designed to account for market noise or volatility.\n\nIt is calculated by dividing the net change in price movement over N periods by the sum of the absolute net changes over the same N periods.\n\nSources:\n    https://help.tc2000.com/m/69404/l/749623-kaufman-efficiency-ratio\n\nCalculation:\n    Default Inputs:\n        length10\n    ABS  Absolute Value\n    EMA  Exponential Moving Average\n\n    abs_diff  ABS(close.diff(length))\n    volatility  ABS(close.diff(1))\n    ER  abs_diff / SUM(volatility, length)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/eri.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import ema\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef eri(high, low, close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Elder Ray Index (ERI)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 13\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    ema_  ema(close, length)\n    bull  high - ema_\n    bear  low - ema_\n\n    # Offset\n    if offset ! 0:\n        bull  bull.shift(offset)\n        bear  bear.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        bull.fillna(kwargs[\"fillna\"], inplaceTrue)\n        bear.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        bull.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        bear.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    bull.name  f\"BULLP_{length}\"\n    bear.name  f\"BEARP_{length}\"\n    bull.category  bear.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    data  {bull.name: bull, bear.name: bear}\n    df  DataFrame(data)\n    df.name  f\"ERI_{length}\"\n    df.category  bull.category\n\n    return df\n\n\neri.__doc__  \\\n\"\"\"Elder Ray Index (ERI)\n\nElder's Bulls Ray Index contains his Bull and Bear Powers. Which are useful ways\nto look at the price and see the strength behind the market. Bull Power\nmeasures the capability of buyers in the market, to lift prices above an average\nconsensus of value.\n\nBears Power measures the capability of sellers, to drag prices below an average\nconsensus of value. Using them in tandem with a measure of trend allows you to\nidentify favourable entry points. We hope you've found this to be a useful\ndiscussion of the Bulls and Bears Power indicators.\n\nSources:\n    https://admiralmarkets.com/education/articles/forex-indicators/bears-and-bulls-power-indicator\n\nCalculation:\n    Default Inputs:\n        length13\n    EMA  Exponential Moving Average\n\n    BULLPOWER  high - EMA(close, length)\n    BEARPOWER  low - EMA(close, length)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 14\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: bull power and bear power columns.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Este conteúdo está no diretório pandas_ta/momentum e contém implementações de indicadores técnicos de momentum em análise técnica. Os arquivos abrangem os seguintes indicadores e tecnologias:\\n\\n- fisher.py: Implementa a transformação de Fisher para detectar reversões de preços.\\n- inertia.py: Calcula o indicador Inertia usando o RVI e regressão linear.\\n- kdj.py: Implementa o oscilador KDJ, que é uma extensão do estocástico lento.\\n- kst.py: Calcula o \"Know Sure Thing\", um indicador baseado em ROC e médias móveis.\\n- macd.py: Implementa o MACD com possibilidade de geração de sinais.\\n- mom.py: Calcula o momentum simples (diferença de preços).\\n- pgo.py: Calcula o Pretty Good Oscillator, baseado em SMA e ATR.\\n\\nTecnologias principais: pandas, numpy, análise técnica de séries temporais.')\npandas_ta/momentum/fisher.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import log as nplog\nfrom numpy import NaN as npNaN\nfrom pandas import DataFrame, Series\nfrom pandas_ta.overlap import ema, hl2\nfrom pandas_ta.utils import get_offset, high_low_range, verify_series, zero\n\n\ndef fisher(high, low, lengthNone, signalNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Fisher Transform (FISHT)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 9\n    signal  int(signal) if signal and signal > 0 else 1\n    _length  max(length, signal)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    offset  get_offset(offset)\n\n    if high is None or low is None: return\n\n    # Calculate Result\n    hl2_  hl2(high, low)\n    highest_hl2  hl2_.rolling(length).max()\n    lowest_hl2  hl2_.rolling(length).min()\n\n    hlr  high_low_range(highest_hl2, lowest_hl2)\n    hlr[hlr < 0.001]  0.001\n\n    position  ((hl2_ - lowest_hl2) / hlr) - 0.5\n\n    v  0\n    m  high.size\n    result  [npNaN for _ in range(0, length - 1)] + [0]\n    for i in range(length, m):\n        v  0.66 * position.iloc[i] + 0.67 * v\n        if v < -0.99:\n            v  -0.999\n        if v > 0.99:\n            v  0.999\n        result.append(0.5 * (nplog((1 + v) / (1 - v)) + result[i - 1]))\n    fisher  Series(result, indexhigh.index)\n    signalma  fisher.shift(signal)\n\n    # Offset\n    if offset ! 0:\n        fisher  fisher.shift(offset)\n        signalma  signalma.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        fisher.fillna(kwargs[\"fillna\"], inplaceTrue)\n        signalma.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        fisher.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        signalma.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _props  f\"_{length}_{signal}\"\n    fisher.name  f\"FISHERT{_props}\"\n    signalma.name  f\"FISHERTs{_props}\"\n    fisher.category  signalma.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    data  {fisher.name: fisher, signalma.name: signalma}\n    df  DataFrame(data)\n    df.name  f\"FISHERT{_props}\"\n    df.category  fisher.category\n\n    return df\n\n\nfisher.__doc__  \\\n\"\"\"Fisher Transform (FISHT)\n\nAttempts to identify significant price reversals by normalizing prices over a\nuser-specified number of periods. A reversal signal is suggested when the the\ntwo lines cross.\n\nSources:\n    TradingView (Correlation >99%)\n\nCalculation:\n    Default Inputs:\n        length9, signal1\n    HL2  hl2(high, low)\n    HHL2  HL2.rolling(length).max()\n    LHL2  HL2.rolling(length).min()\n\n    HLR  HHL2 - LHL2\n    HLR[HLR < 0.001]  0.001\n\n    position  ((HL2 - LHL2) / HLR) - 0.5\n\n    v  0\n    m  high.size\n    FISHER  [npNaN for _ in range(0, length - 1)] + [0]\n    for i in range(length, m):\n        v  0.66 * position[i] + 0.67 * v\n        if v < -0.99: v  -0.999\n        if v >  0.99: v   0.999\n        FISHER.append(0.5 * (nplog((1 + v) / (1 - v)) + FISHER[i - 1]))\n\n    SIGNAL  FISHER.shift(signal)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    length (int): Fisher period. Default: 9\n    signal (int): Fisher Signal period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/inertia.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import linreg\nfrom pandas_ta.volatility import rvi\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef inertia(closeNone, highNone, lowNone, lengthNone, rvi_lengthNone, scalarNone, refinedNone, thirdsNone, mamodeNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Inertia (INERTIA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 20\n    rvi_length  int(rvi_length) if rvi_length and rvi_length > 0 else 14\n    scalar  float(scalar) if scalar and scalar > 0 else 100\n    refined  False if refined is None else True\n    thirds  False if thirds is None else True\n    mamode  mamode if isinstance(mamode, str) else \"ema\"\n    _length  max(length, rvi_length)\n    close  verify_series(close, _length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    if refined or thirds:\n        high  verify_series(high, _length)\n        low  verify_series(low, _length)\n        if high is None or low is None: return\n\n    # Calculate Result\n    if refined:\n        _mode, rvi_  \"r\", rvi(close, highhigh, lowlow, lengthrvi_length, scalarscalar, refinedrefined, mamodemamode)\n    elif thirds:\n        _mode, rvi_  \"t\", rvi(close, highhigh, lowlow, lengthrvi_length, scalarscalar, thirdsthirds, mamodemamode)\n    else:\n        _mode, rvi_  \"\",  rvi(close, lengthrvi_length, scalarscalar, mamodemamode)\n\n    inertia  linreg(rvi_, lengthlength)\n\n    # Offset\n    if offset ! 0:\n        inertia  inertia.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        inertia.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        inertia.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name & Category\n    _props  f\"_{length}_{rvi_length}\"\n    inertia.name  f\"INERTIA{_mode}{_props}\"\n    inertia.category  \"momentum\"\n\n    return inertia\n\n\ninertia.__doc__  \\\n\"\"\"Inertia (INERTIA)\n\nInertia was developed by Donald Dorsey and was introduced his article\nin September, 1995. It is the Relative Vigor Index smoothed by the Least\nSquares Moving Average. Postive Inertia when values are greater than 50,\nNegative Inertia otherwise.\n\nSources:\n    https://www.investopedia.com/terms/r/relative_vigor_index.asp\n\nCalculation:\n    Default Inputs:\n        length14, ma_length20\n    LSQRMA  Least Squares Moving Average\n\n    INERTIA  LSQRMA(RVI(length), ma_length)\n\nArgs:\n    open_ (pd.Series): Series of 'open's\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 20\n    rvi_length (int): RVI period. Default: 14\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/kdj.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import rma\nfrom pandas_ta.utils import get_offset, non_zero_range, verify_series\n\n\ndef kdj(highNone, lowNone, closeNone, lengthNone, signalNone, offsetNone, **kwargs):\n    \"\"\"Indicator: KDJ (KDJ)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 9\n    signal  int(signal) if signal and signal > 0 else 3\n    _length  max(length, signal)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    highest_high  high.rolling(length).max()\n    lowest_low  low.rolling(length).min()\n\n    fastk  100 * (close - lowest_low) / non_zero_range(highest_high, lowest_low)\n\n    k  rma(fastk, lengthsignal)\n    d  rma(k, lengthsignal)\n    j  3 * k - 2 * d\n\n    # Offset\n    if offset ! 0:\n        k  k.shift(offset)\n        d  d.shift(offset)\n        j  j.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        k.fillna(kwargs[\"fillna\"], inplaceTrue)\n        d.fillna(kwargs[\"fillna\"], inplaceTrue)\n        j.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        k.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        d.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        j.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _params  f\"_{length}_{signal}\"\n    k.name  f\"K{_params}\"\n    d.name  f\"D{_params}\"\n    j.name  f\"J{_params}\"\n    k.category  d.category  j.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    kdjdf  DataFrame({k.name: k, d.name: d, j.name: j})\n    kdjdf.name  f\"KDJ{_params}\"\n    kdjdf.category  \"momentum\"\n\n    return kdjdf\n\n\nkdj.__doc__  \\\n\"\"\"KDJ (KDJ)\n\nThe KDJ indicator is actually a derived form of the Slow\nStochastic with the only difference being an extra line\ncalled the J line. The J line represents the divergence\nof the %D value from the %K. The value of J can go\nbeyond [0, 100] for %K and %D lines on the chart.\n\nSources:\n    https://www.prorealcode.com/prorealtime-indicators/kdj/\n    https://docs.anychart.com/Stock_Charts/Technical_Indicators/Mathematical_Description#kdj\n\nCalculation:\n    Default Inputs:\n        length9, signal3\n    LL  low for last 9 periods\n    HH  high for last 9 periods\n\n    FAST_K  100 * (close - LL) / (HH - LL)\n\n    K  RMA(FAST_K, signal)\n    D  RMA(K, signal)\n    J  3K - 2D\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): Default: 9\n    signal (int): Default: 3\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/kst.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom .roc import roc\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef kst(close, roc1None, roc2None, roc3None, roc4None, sma1None, sma2None, sma3None, sma4None, signalNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: 'Know Sure Thing' (KST)\"\"\"\n    # Validate arguments\n    roc1  int(roc1) if roc1 and roc1 > 0 else 10\n    roc2  int(roc2) if roc2 and roc2 > 0 else 15\n    roc3  int(roc3) if roc3 and roc3 > 0 else 20\n    roc4  int(roc4) if roc4 and roc4 > 0 else 30\n\n    sma1  int(sma1) if sma1 and sma1 > 0 else 10\n    sma2  int(sma2) if sma2 and sma2 > 0 else 10\n    sma3  int(sma3) if sma3 and sma3 > 0 else 10\n    sma4  int(sma4) if sma4 and sma4 > 0 else 15\n\n    signal  int(signal) if signal and signal > 0 else 9\n    _length  max(roc1, roc2, roc3, roc4, sma1, sma2, sma3, sma4, signal)\n    close  verify_series(close, _length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    rocma1  roc(close, roc1).rolling(sma1).mean()\n    rocma2  roc(close, roc2).rolling(sma2).mean()\n    rocma3  roc(close, roc3).rolling(sma3).mean()\n    rocma4  roc(close, roc4).rolling(sma4).mean()\n\n    kst  100 * (rocma1 + 2 * rocma2 + 3 * rocma3 + 4 * rocma4)\n    kst_signal  kst.rolling(signal).mean()\n\n    # Offset\n    if offset ! 0:\n        kst  kst.shift(offset)\n        kst_signal  kst_signal.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        kst.fillna(kwargs[\"fillna\"], inplaceTrue)\n        kst_signal.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        kst.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        kst_signal.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    kst.name  f\"KST_{roc1}_{roc2}_{roc3}_{roc4}_{sma1}_{sma2}_{sma3}_{sma4}\"\n    kst_signal.name  f\"KSTs_{signal}\"\n    kst.category  kst_signal.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    data  {kst.name: kst, kst_signal.name: kst_signal}\n    kstdf  DataFrame(data)\n    kstdf.name  f\"KST_{roc1}_{roc2}_{roc3}_{roc4}_{sma1}_{sma2}_{sma3}_{sma4}_{signal}\"\n    kstdf.category  \"momentum\"\n\n    return kstdf\n\n\nkst.__doc__  \\\n\"\"\"'Know Sure Thing' (KST)\n\nThe 'Know Sure Thing' is a momentum based oscillator and based on ROC.\n\nSources:\n    https://www.tradingview.com/wiki/Know_Sure_Thing_(KST)\n    https://www.incrediblecharts.com/indicators/kst.php\n\nCalculation:\n    Default Inputs:\n        roc110, roc215, roc320, roc430,\n        sma110, sma210, sma310, sma415, signal9, drift1\n    ROC  Rate of Change\n    SMA  Simple Moving Average\n    rocsma1  SMA(ROC(close, roc1), sma1)\n    rocsma2  SMA(ROC(close, roc2), sma2)\n    rocsma3  SMA(ROC(close, roc3), sma3)\n    rocsma4  SMA(ROC(close, roc4), sma4)\n\n    KST  100 * (rocsma1 + 2 * rocsma2 + 3 * rocsma3 + 4 * rocsma4)\n    KST_Signal  SMA(KST, signal)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    roc1 (int): ROC 1 period. Default: 10\n    roc2 (int): ROC 2 period. Default: 15\n    roc3 (int): ROC 3 period. Default: 20\n    roc4 (int): ROC 4 period. Default: 30\n    sma1 (int): SMA 1 period. Default: 10\n    sma2 (int): SMA 2 period. Default: 10\n    sma3 (int): SMA 3 period. Default: 10\n    sma4 (int): SMA 4 period. Default: 15\n    signal (int): It's period. Default: 9\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: kst and kst_signal columns\n\"\"\"\n\n\n\npandas_ta/momentum/macd.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import concat, DataFrame\nfrom pandas_ta.overlap import ema\nfrom pandas_ta.utils import get_offset, verify_series, signals\n\n\ndef macd(close, fastNone, slowNone, signalNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Moving Average, Convergence/Divergence (MACD)\"\"\"\n    # Validate arguments\n    fast  int(fast) if fast and fast > 0 else 12\n    slow  int(slow) if slow and slow > 0 else 26\n    signal  int(signal) if signal and signal > 0 else 9\n    if slow < fast:\n        fast, slow  slow, fast\n    close  verify_series(close, max(fast, slow, signal))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    fastma  ema(close, lengthfast)\n    slowma  ema(close, lengthslow)\n\n    macd  fastma - slowma\n    signalma  ema(closemacd.loc[macd.first_valid_index():,], lengthsignal)\n    histogram  macd - signalma\n\n    # Offset\n    if offset ! 0:\n        macd  macd.shift(offset)\n        histogram  histogram.shift(offset)\n        signalma  signalma.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        macd.fillna(kwargs[\"fillna\"], inplaceTrue)\n        histogram.fillna(kwargs[\"fillna\"], inplaceTrue)\n        signalma.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        macd.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        histogram.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        signalma.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _props  f\"_{fast}_{slow}_{signal}\"\n    macd.name  f\"MACD{_props}\"\n    histogram.name  f\"MACDh{_props}\"\n    signalma.name  f\"MACDs{_props}\"\n    macd.category  histogram.category  signalma.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    data  {macd.name: macd, histogram.name: histogram, signalma.name: signalma}\n    df  DataFrame(data)\n    df.name  f\"MACD{_props}\"\n    df.category  macd.category\n\n    signal_indicators  kwargs.pop(\"signal_indicators\", False)\n    if signal_indicators:\n        signalsdf  concat(\n            [\n                df,\n                signals(\n                    indicatorhistogram,\n                    xakwargs.pop(\"xa\", 0),\n                    xbkwargs.pop(\"xb\", None),\n                    xseriekwargs.pop(\"xserie\", None),\n                    xserie_akwargs.pop(\"xserie_a\", None),\n                    xserie_bkwargs.pop(\"xserie_b\", None),\n                    cross_valueskwargs.pop(\"cross_values\", True),\n                    cross_serieskwargs.pop(\"cross_series\", True),\n                    offsetoffset,\n                ),\n                signals(\n                    indicatormacd,\n                    xakwargs.pop(\"xa\", 0),\n                    xbkwargs.pop(\"xb\", None),\n                    xseriekwargs.pop(\"xserie\", None),\n                    xserie_akwargs.pop(\"xserie_a\", None),\n                    xserie_bkwargs.pop(\"xserie_b\", None),\n                    cross_valueskwargs.pop(\"cross_values\", False),\n                    cross_serieskwargs.pop(\"cross_series\", True),\n                    offsetoffset,\n                ),\n            ],\n            axis1,\n        )\n\n        return signalsdf\n    else:\n        return df\n\n\nmacd.__doc__  \\\n\"\"\"Moving Average Convergence Divergence (MACD)\n\nThe MACD is a popular indicator to that is used to identify a security's trend.\nWhile APO and MACD are the same calculation, MACD also returns two more series\ncalled Signal and Histogram. The Signal is an EMA of MACD and the Histogram is\nthe difference of MACD and Signal.\n\nSources:\n    https://www.tradingview.com/wiki/MACD_(Moving_Average_Convergence/Divergence)\n\nCalculation:\n    Default Inputs:\n        fast12, slow26, signal9\n    EMA  Exponential Moving Average\n    MACD  EMA(close, fast) - EMA(close, slow)\n    Signal  EMA(MACD, signal)\n    Histogram  MACD - Signal\n\nArgs:\n    close (pd.Series): Series of 'close's\n    fast (int): The short period. Default: 12\n    slow (int): The long period. Default: 26\n    signal (int): The signal period. Default: 9\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: macd, histogram, signal columns.\n\"\"\"\n\n\n\npandas_ta/momentum/mom.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef mom(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Momentum (MOM)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    mom  close.diff(length)\n\n    # Offset\n    if offset ! 0:\n        mom  mom.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        mom.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        mom.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    mom.name  f\"MOM_{length}\"\n    mom.category  \"momentum\"\n\n    return mom\n\n\nmom.__doc__  \\\n\"\"\"Momentum (MOM)\n\nMomentum is an indicator used to measure a security's speed (or strength) of\nmovement.  Or simply the change in price.\n\nSources:\n    http://www.onlinetradingconcepts.com/TechnicalAnalysis/Momentum.html\n\nCalculation:\n    Default Inputs:\n        length1\n    MOM  close.diff(length)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/pgo.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import ema, sma\nfrom pandas_ta.volatility import atr\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef pgo(high, low, close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Pretty Good Oscillator (PGO)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 14\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    pgo  close - sma(close, length)\n    pgo / ema(atr(high, low, close, length), length)\n\n    # Offset\n    if offset ! 0:\n        pgo  pgo.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        pgo.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        pgo.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    pgo.name  f\"PGO_{length}\"\n    pgo.category  \"momentum\"\n\n    return pgo\n\n\npgo.__doc__  \\\n\"\"\"Pretty Good Oscillator (PGO)\n\nThe Pretty Good Oscillator indicator was created by Mark Johnson to measure the distance of the current close from its N-day Simple Moving Average, expressed in terms of an average true range over a similar period. Johnson's approach was to\nuse it as a breakout system for longer term trades. Long if greater than 3.0 and\nshort if less than -3.0.\n\nSources:\n    https://library.tradingtechnologies.com/trade/chrt-ti-pretty-good-oscillator.html\n\nCalculation:\n    Default Inputs:\n        length14\n    ATR  Average True Range\n    SMA  Simple Moving Average\n    EMA  Exponential Moving Average\n\n    PGO  (close - SMA(close, length)) / EMA(ATR(high, low, close, length), length)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 14\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Este conteúdo pertence ao diretório `pandas_ta/momentum` e engloba diversos arquivos Python que implementam indicadores técnicos de momentum para análise técnica de séries temporais financeiras. Inclui os seguintes arquivos e temas:\\n\\n- `ppo.py`: Percentage Price Oscillator (PPO) – mede momentum baseado em médias móveis de preço.\\n- `psl.py`: Psychological Line (PSL) – mede a quantidade de períodos de alta em relação ao total.\\n- `pvo.py`: Percentage Volume Oscillator (PVO) – aplica lógica do PPO ao volume para medir momentum de volume.\\n- `qqe.py`: Quantitative Qualitative Estimation (QQE) – usa RSI suavizado e bandas para identificar tendências.\\n- `roc.py`: Rate of Change (ROC) – mede a mudança percentual no preço.\\n- `rsi.py`: Relative Strength Index (RSI) – mede a força relativa da movimentação de preços.\\n\\nAs tecnologias e conceitos envolvidos incluem médias móveis (SMA, EMA, RMA), séries temporais com pandas, operações vetoriais com NumPy, e cálculos de indicadores técnicos como RSI, PPO, ROC e outros.')\npandas_ta/momentum/ppo.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import ema, sma\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef ppo(close, fastNone, slowNone, signalNone, scalarNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Percentage Price Oscillator (PPO)\"\"\"\n    # Validate Arguments\n    fast  int(fast) if fast and fast > 0 else 12\n    slow  int(slow) if slow and slow > 0 else 26\n    signal  int(signal) if signal and signal > 0 else 9\n    scalar  float(scalar) if scalar else 100\n    if slow < fast:\n        fast, slow  slow, fast\n    close  verify_series(close, max(fast, slow, signal))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    fastma  sma(close, lengthfast)\n    slowma  sma(close, lengthslow)\n    ppo  scalar * (fastma - slowma)\n    ppo / slowma\n\n    signalma  ema(ppo, lengthsignal)\n    histogram  ppo - signalma\n\n    # Offset\n    if offset ! 0:\n        ppo  ppo.shift(offset)\n        histogram  histogram.shift(offset)\n        signalma  signalma.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        ppo.fillna(kwargs[\"fillna\"], inplaceTrue)\n        histogram.fillna(kwargs[\"fillna\"], inplaceTrue)\n        signalma.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        ppo.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        histogram.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        signalma.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _props  f\"_{fast}_{slow}_{signal}\"\n    ppo.name  f\"PPO{_props}\"\n    histogram.name  f\"PPOh{_props}\"\n    signalma.name  f\"PPOs{_props}\"\n    ppo.category  histogram.category  signalma.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    data  {ppo.name: ppo, histogram.name: histogram, signalma.name: signalma}\n    df  DataFrame(data)\n    df.name  f\"PPO{_props}\"\n    df.category  ppo.category\n\n    return df\n\n\nppo.__doc__  \\\n\"\"\"Percentage Price Oscillator (PPO)\n\nThe Percentage Price Oscillator is similar to MACD in measuring momentum.\n\nSources:\n    https://www.tradingview.com/wiki/MACD_(Moving_Average_Convergence/Divergence)\n\nCalculation:\n    Default Inputs:\n        fast12, slow26\n    SMA  Simple Moving Average\n    EMA  Exponential Moving Average\n    fast_sma  SMA(close, fast)\n    slow_sma  SMA(close, slow)\n    PPO  100 * (fast_sma - slow_sma) / slow_sma\n    Signal  EMA(PPO, signal)\n    Histogram  PPO - Signal\n\nArgs:\n    close(pandas.Series): Series of 'close's\n    fast(int): The short period. Default: 12\n    slow(int): The long period. Default: 26\n    signal(int): The signal period. Default: 9\n    scalar (float): How much to magnify. Default: 100\n    offset(int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: ppo, histogram, signal columns\n\"\"\"\n\n\n\npandas_ta/momentum/psl.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import sign as npSign\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef psl(close, open_None, lengthNone, scalarNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Psychological Line (PSL)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 12\n    scalar  float(scalar) if scalar and scalar > 0 else 100\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    if open_ is not None:\n        open_  verify_series(open_)\n        diff  npSign(close - open_)\n    else:\n        diff  npSign(close.diff(drift))\n\n    diff.fillna(0, inplaceTrue)\n    diff[diff < 0]  0  # Zero negative values\n\n    psl  scalar * diff.rolling(length).sum()\n    psl / length\n\n    # Offset\n    if offset ! 0:\n        psl  psl.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        psl.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        psl.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _props  f\"_{length}\"\n    psl.name  f\"PSL{_props}\"\n    psl.category  \"momentum\"\n\n    return psl\n\n\npsl.__doc__  \\\n\"\"\"Psychological Line (PSL)\n\nThe Psychological Line is an oscillator-type indicator that compares the\nnumber of the rising periods to the total number of periods. In other\nwords, it is the percentage of bars that close above the previous\nbar over a given period.\n\nSources:\n    https://www.quantshare.com/item-851-psychological-line\n\nCalculation:\n    Default Inputs:\n        length12, scalar100, drift1\n\n    IF NOT open:\n        DIFF  SIGN(close - close[drift])\n    ELSE:\n        DIFF  SIGN(close - open)\n\n    DIFF.fillna(0)\n    DIFF[DIFF < 0]  0\n\n    PSL  scalar * SUM(DIFF, length) / length\n\nArgs:\n    close (pd.Series): Series of 'close's\n    open_ (pd.Series, optional): Series of 'open's\n    length (int): It's period. Default: 12\n    scalar (float): How much to magnify. Default: 100\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/pvo.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import ema\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef pvo(volume, fastNone, slowNone, signalNone, scalarNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Percentage Volume Oscillator (PVO)\"\"\"\n    # Validate Arguments\n    fast  int(fast) if fast and fast > 0 else 12\n    slow  int(slow) if slow and slow > 0 else 26\n    signal  int(signal) if signal and signal > 0 else 9\n    scalar  float(scalar) if scalar else 100\n    if slow < fast:\n        fast, slow  slow, fast\n    volume  verify_series(volume, max(fast, slow, signal))\n    offset  get_offset(offset)\n\n    if volume is None: return\n\n    # Calculate Result\n    fastma  ema(volume, lengthfast)\n    slowma  ema(volume, lengthslow)\n    pvo  scalar * (fastma - slowma)\n    pvo / slowma\n\n    signalma  ema(pvo, lengthsignal)\n    histogram  pvo - signalma\n\n    # Offset\n    if offset ! 0:\n        pvo  pvo.shift(offset)\n        histogram  histogram.shift(offset)\n        signalma  signalma.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        pvo.fillna(kwargs[\"fillna\"], inplaceTrue)\n        histogram.fillna(kwargs[\"fillna\"], inplaceTrue)\n        signalma.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        pvo.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        histogram.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        signalma.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _props  f\"_{fast}_{slow}_{signal}\"\n    pvo.name  f\"PVO{_props}\"\n    histogram.name  f\"PVOh{_props}\"\n    signalma.name  f\"PVOs{_props}\"\n    pvo.category  histogram.category  signalma.category  \"momentum\"\n\n    #\n    data  {pvo.name: pvo, histogram.name: histogram, signalma.name: signalma}\n    df  DataFrame(data)\n    df.name  pvo.name\n    df.category  pvo.category\n\n    return df\n\n\npvo.__doc__  \\\n\"\"\"Percentage Volume Oscillator (PVO)\n\nPercentage Volume Oscillator is a Momentum Oscillator for Volume.\n\nSources:\n    https://www.fmlabs.com/reference/default.htm?urlPVO.htm\n\nCalculation:\n    Default Inputs:\n        fast12, slow26, signal9\n    EMA  Exponential Moving Average\n\n    PVO  (EMA(volume, fast) - EMA(volume, slow)) / EMA(volume, slow)\n    Signal  EMA(PVO, signal)\n    Histogram  PVO - Signal\n\nArgs:\n    volume (pd.Series): Series of 'volume's\n    fast (int): The short period. Default: 12\n    slow (int): The long period. Default: 26\n    signal (int): The signal period. Default: 9\n    scalar (float): How much to magnify. Default: 100\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: pvo, histogram, signal columns.\n\"\"\"\n\n\n\npandas_ta/momentum/qqe.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import maximum as npMaximum\nfrom numpy import minimum as npMinimum\nfrom numpy import nan as npNaN\nfrom pandas import DataFrame, Series\n\nfrom .rsi import rsi\nfrom pandas_ta.overlap import ma\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef qqe(close, lengthNone, smoothNone, factorNone, mamodeNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Quantitative Qualitative Estimation (QQE)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 14\n    smooth  int(smooth) if smooth and smooth > 0 else 5\n    factor  float(factor) if factor else 4.236\n    wilders_length  2 * length - 1\n    mamode  mamode if isinstance(mamode, str) else \"ema\"\n    close  verify_series(close, max(length, smooth, wilders_length))\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    rsi_  rsi(close, length)\n    _mode  mamode.lower()[0] if mamode ! \"ema\" else \"\"\n    rsi_ma  ma(mamode, rsi_, lengthsmooth)\n\n    # RSI MA True Range\n    rsi_ma_tr  rsi_ma.diff(drift).abs()\n\n    # Double Smooth the RSI MA True Range using Wilder's Length with a default\n    # width of 4.236.\n    smoothed_rsi_tr_ma  ma(\"ema\", rsi_ma_tr, lengthwilders_length)\n    dar  factor * ma(\"ema\", smoothed_rsi_tr_ma, lengthwilders_length)\n\n    # Create the Upper and Lower Bands around RSI MA.\n    upperband  rsi_ma + dar\n    lowerband  rsi_ma - dar\n\n    m  close.size\n    long  Series(0, indexclose.index)\n    short  Series(0, indexclose.index)\n    trend  Series(1, indexclose.index)\n    qqe  Series(rsi_ma.iloc[0], indexclose.index)\n    qqe_long  Series(npNaN, indexclose.index)\n    qqe_short  Series(npNaN, indexclose.index)\n\n    for i in range(1, m):\n        c_rsi, p_rsi  rsi_ma.iloc[i], rsi_ma.iloc[i - 1]\n        c_long, p_long  long.iloc[i - 1], long.iloc[i - 2]\n        c_short, p_short  short.iloc[i - 1], short.iloc[i - 2]\n\n        # Long Line\n        if p_rsi > c_long and c_rsi > c_long:\n            long.iloc[i]  npMaximum(c_long, lowerband.iloc[i])\n        else:\n            long.iloc[i]  lowerband.iloc[i]\n\n        # Short Line\n        if p_rsi < c_short and c_rsi < c_short:\n            short.iloc[i]  npMinimum(c_short, upperband.iloc[i])\n        else:\n            short.iloc[i]  upperband.iloc[i]\n\n        # Trend & QQE Calculation\n        # Long: Current RSI_MA value Crosses the Prior Short Line Value\n        # Short: Current RSI_MA Crosses the Prior Long Line Value\n        if (c_rsi > c_short and p_rsi < p_short) or (c_rsi < c_short and p_rsi > p_short):\n            trend.iloc[i]  1\n            qqe.iloc[i]  qqe_long.iloc[i]  long.iloc[i]\n        elif (c_rsi > c_long and p_rsi < p_long) or (c_rsi < c_long and p_rsi > p_long):\n            trend.iloc[i]  -1\n            qqe.iloc[i]  qqe_short.iloc[i]  short.iloc[i]\n        else:\n            trend.iloc[i]  trend.iloc[i - 1]\n            if trend.iloc[i]  1:\n                qqe.iloc[i]  qqe_long.iloc[i]  long.iloc[i]\n            else:\n                qqe.iloc[i]  qqe_short.iloc[i]   short.iloc[i]\n\n    # Offset\n    if offset ! 0:\n        rsi_ma  rsi_ma.shift(offset)\n        qqe  qqe.shift(offset)\n        long  long.shift(offset)\n        short  short.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        rsi_ma.fillna(kwargs[\"fillna\"], inplaceTrue)\n        qqe.fillna(kwargs[\"fillna\"], inplaceTrue)\n        qqe_long.fillna(kwargs[\"fillna\"], inplaceTrue)\n        qqe_short.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        rsi_ma.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        qqe.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        qqe_long.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        qqe_short.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _props  f\"{_mode}_{length}_{smooth}_{factor}\"\n    qqe.name  f\"QQE{_props}\"\n    rsi_ma.name  f\"QQE{_props}_RSI{_mode.upper()}MA\"\n    qqe_long.name  f\"QQEl{_props}\"\n    qqe_short.name  f\"QQEs{_props}\"\n    qqe.category  rsi_ma.category  \"momentum\"\n    qqe_long.category  qqe_short.category  qqe.category\n\n    # Prepare DataFrame to return\n    data  {\n        qqe.name: qqe, rsi_ma.name: rsi_ma,\n        # long.name: long, short.name: short\n        qqe_long.name: qqe_long, qqe_short.name: qqe_short\n    }\n    df  DataFrame(data)\n    df.name  f\"QQE{_props}\"\n    df.category  qqe.category\n\n    return df\n\n\nqqe.__doc__  \\\n\"\"\"Quantitative Qualitative Estimation (QQE)\n\nThe Quantitative Qualitative Estimation (QQE) is similar to SuperTrend but uses a Smoothed RSI with an upper and lower bands. The band width is a combination of a one period True Range of the Smoothed RSI which is double smoothed using Wilder's smoothing length (2 * rsiLength - 1) and multiplied by the default factor of 4.236. A Long trend is determined when the Smoothed RSI crosses the previous upperband and a Short trend when the Smoothed RSI crosses the previous lowerband.\n\nBased on QQE.mq5 by EarnForex Copyright Â© 2010, based on version by Tim Hyder (2008), based on version by Roman Ignatov (2006)\n\nSources:\n    https://www.tradingview.com/script/IYfA9R2k-QQE-MT4/\n    https://www.tradingpedia.com/forex-trading-indicators/quantitative-qualitative-estimation\n    https://www.prorealcode.com/prorealtime-indicators/qqe-quantitative-qualitative-estimation/\n\nCalculation:\n    Default Inputs:\n        length14, smooth5, factor4.236, mamode\"ema\", drift1\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): RSI period. Default: 14\n    smooth (int): RSI smoothing period. Default: 5\n    factor (float): QQE Factor. Default: 4.236\n    mamode (str): Smoothing MA type: \"ema\", \"hma\", \"rma\", \"sma\" or \"wma\".\n        Default: \"ema\"\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: QQE, RSI_MA (basis), QQEl (long), and QQEs (short) columns.\n\"\"\"\n\n\n\npandas_ta/momentum/roc.py\n\n# -*- coding: utf-8 -*-\nfrom .mom import mom\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef roc(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Rate of Change (ROC)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    roc  100 * mom(closeclose, lengthlength) / close.shift(length)\n\n    # Offset\n    if offset ! 0:\n        roc  roc.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        roc.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        roc.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    roc.name  f\"ROC_{length}\"\n    roc.category  \"momentum\"\n\n    return roc\n\n\nroc.__doc__  \\\n\"\"\"Rate of Change (ROC)\n\nRate of Change is an indicator is also referred to as Momentum (yeah, confusingly).\nIt is a pure momentum oscillator that measures the percent change in price with the\nprevious price 'n' (or length) periods ago.\n\nSources:\n    https://www.tradingview.com/wiki/Rate_of_Change_(ROC)\n\nCalculation:\n    Default Inputs:\n        length1\n    MOM  Momentum\n    ROC  100 * MOM(close, length) / close.shift(length)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/rsi.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame, concat\nfrom pandas_ta.overlap import rma\nfrom pandas_ta.utils import get_drift, get_offset, verify_series, signals\n\n\ndef rsi(close, lengthNone, scalarNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Relative Strength Index (RSI)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 14\n    scalar  float(scalar) if scalar else 100\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    negative  close.diff(drift)\n    positive  negative.copy()\n\n    positive[positive < 0]  0  # Make negatives 0 for the postive series\n    negative[negative > 0]  0  # Make postives 0 for the negative series\n\n    positive_avg  rma(positive, lengthlength)\n    negative_avg  rma(negative, lengthlength)\n\n    rsi  scalar * positive_avg / (positive_avg + negative_avg.abs())\n\n    # Offset\n    if offset ! 0:\n        rsi  rsi.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        rsi.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        rsi.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    rsi.name  f\"RSI_{length}\"\n    rsi.category  \"momentum\"\n\n    signal_indicators  kwargs.pop(\"signal_indicators\", False)\n    if signal_indicators:\n        signalsdf  concat(\n            [\n                DataFrame({rsi.name: rsi}),\n                signals(\n                    indicatorrsi,\n                    xakwargs.pop(\"xa\", 80),\n                    xbkwargs.pop(\"xb\", 20),\n                    xseriekwargs.pop(\"xserie\", None),\n                    xserie_akwargs.pop(\"xserie_a\", None),\n                    xserie_bkwargs.pop(\"xserie_b\", None),\n                    cross_valueskwargs.pop(\"cross_values\", False),\n                    cross_serieskwargs.pop(\"cross_series\", True),\n                    offsetoffset,\n                ),\n            ],\n            axis1,\n        )\n\n        return signalsdf\n    else:\n        return rsi\n\n\nrsi.__doc__  \\\n\"\"\"Relative Strength Index (RSI)\n\nThe Relative Strength Index is popular momentum oscillator used to measure the\nvelocity as well as the magnitude of directional price movements.\n\nSources:\n    https://www.tradingview.com/wiki/Relative_Strength_Index_(RSI)\n\nCalculation:\n    Default Inputs:\n        length14, scalar100, drift1\n    ABS  Absolute Value\n    EMA  Exponential Moving Average\n\n    positive  close if close.diff(drift) > 0 else 0\n    negative  close if close.diff(drift) < 0 else 0\n\n    pos_avg  EMA(positive, length)\n    neg_avg  ABS(EMA(negative, length))\n\n    RSI  scalar * pos_avg / (pos_avg + neg_avg)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 14\n    scalar (float): How much to magnify. Default: 100\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Esse conteúdo está no diretório pandas_ta/momentum e contém implementações de indicadores técnicos de momentum utilizados em análise técnica. Ele inclui os seguintes arquivos:\\n\\n- rsx.py: Implementa o indicador Relative Strength Xtra (RSX), inspirado no RSI, focado em reduzir ruído e melhorar a suavização.\\n- rvgi.py: Implementa o Relative Vigor Index (RVGI), que compara a força relativa do fechamento com a amplitude do candle.\\n- slope.py: Calcula a inclinação de uma série temporal e pode ser representada como ângulo em radianos ou graus.\\n- smi.py: Define o indicador SMI Ergodic (SMIIO), uma versão do True Strength Index com linha de sinal.\\n\\nTecnologias: Python, pandas, numpy, indicadores técnicos como RSI, EMA, TSI.')\npandas_ta/momentum/rsx.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import NaN as npNaN\nfrom pandas import concat, DataFrame, Series\nfrom pandas_ta.utils import get_drift, get_offset, verify_series, signals\n\n\ndef rsx(close, lengthNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Relative Strength Xtra (inspired by Jurik RSX)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 14\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # variables\n    vC, v1C  0, 0\n    v4, v8, v10, v14, v18, v20  0, 0, 0, 0, 0, 0\n\n    f0, f8, f10, f18, f20, f28, f30, f38  0, 0, 0, 0, 0, 0, 0, 0\n    f40, f48, f50, f58, f60, f68, f70, f78  0, 0, 0, 0, 0, 0, 0, 0\n    f80, f88, f90  0, 0, 0\n\n    # Calculate Result\n    m  close.size\n    result  [npNaN for _ in range(0, length - 1)] + [0]\n    for i in range(length, m):\n        if f90  0:\n            f90  1.0\n            f0  0.0\n            if length - 1.0 > 5:\n                f88  length - 1.0\n            else:\n                f88  5.0\n            f8  100.0 * close.iloc[i]\n            f18  3.0 / (length + 2.0)\n            f20  1.0 - f18\n        else:\n            if f88 < f90:\n                f90  f88 + 1\n            else:\n                f90  f90 + 1\n            f10  f8\n            f8  100 * close.iloc[i]\n            v8  f8 - f10\n            f28  f20 * f28 + f18 * v8\n            f30  f18 * f28 + f20 * f30\n            vC  1.5 * f28 - 0.5 * f30\n            f38  f20 * f38 + f18 * vC\n            f40  f18 * f38 + f20 * f40\n            v10  1.5 * f38 - 0.5 * f40\n            f48  f20 * f48 + f18 * v10\n            f50  f18 * f48 + f20 * f50\n            v14  1.5 * f48 - 0.5 * f50\n            f58  f20 * f58 + f18 * abs(v8)\n            f60  f18 * f58 + f20 * f60\n            v18  1.5 * f58 - 0.5 * f60\n            f68  f20 * f68 + f18 * v18\n            f70  f18 * f68 + f20 * f70\n            v1C  1.5 * f68 - 0.5 * f70\n            f78  f20 * f78 + f18 * v1C\n            f80  f18 * f78 + f20 * f80\n            v20  1.5 * f78 - 0.5 * f80\n\n            if f88 > f90 and f8 ! f10:\n                f0  1.0\n            if f88  f90 and f0  0.0:\n                f90  0.0\n\n        if f88 < f90 and v20 > 0.0000000001:\n            v4  (v14 / v20 + 1.0) * 50.0\n            if v4 > 100.0:\n                v4  100.0\n            if v4 < 0.0:\n                v4  0.0\n        else:\n            v4  50.0\n        result.append(v4)\n    rsx  Series(result, indexclose.index)\n\n    # Offset\n    if offset ! 0:\n        rsx  rsx.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        rsx.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        rsx.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    rsx.name  f\"RSX_{length}\"\n    rsx.category  \"momentum\"\n\n    signal_indicators  kwargs.pop(\"signal_indicators\", False)\n    if signal_indicators:\n        signalsdf  concat(\n            [\n                DataFrame({rsx.name: rsx}),\n                signals(\n                    indicatorrsx,\n                    xakwargs.pop(\"xa\", 80),\n                    xbkwargs.pop(\"xb\", 20),\n                    xseriekwargs.pop(\"xserie\", None),\n                    xserie_akwargs.pop(\"xserie_a\", None),\n                    xserie_bkwargs.pop(\"xserie_b\", None),\n                    cross_valueskwargs.pop(\"cross_values\", False),\n                    cross_serieskwargs.pop(\"cross_series\", True),\n                    offsetoffset,\n                ),\n            ],\n            axis1\n        )\n\n        return signalsdf\n    else:\n        return rsx\n\n\nrsx.__doc__  \\\n\"\"\"Relative Strength Xtra (rsx)\n\nThe Relative Strength Xtra is based on the popular RSI indicator and inspired\nby the work Jurik Research. The code implemented is based on published code\nfound at 'prorealcode.com'. This enhanced version of the rsi reduces noise and\nprovides a clearer, only slightly delayed insight on momentum and velocity of\nprice movements.\n\nSources:\n    http://www.jurikres.com/catalog1/ms_rsx.htm\n    https://www.prorealcode.com/prorealtime-indicators/jurik-rsx/\n\nCalculation:\n    Refer to the sources above for information as well as code example.\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 14\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/rvgi.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import swma\nfrom pandas_ta.utils import get_offset, non_zero_range, verify_series\n\n\ndef rvgi(open_, high, low, close, lengthNone, swma_lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Relative Vigor Index (RVGI)\"\"\"\n    # Validate Arguments\n    high_low_range  non_zero_range(high, low)\n    close_open_range  non_zero_range(close, open_)\n    length  int(length) if length and length > 0 else 14\n    swma_length  int(swma_length) if swma_length and swma_length > 0 else 4\n    _length  max(length, swma_length)\n    open_  verify_series(open_, _length)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    offset  get_offset(offset)\n\n    if open_ is None or high is None or low is None or close is None: return\n\n    # Calculate Result\n    numerator  swma(close_open_range, lengthswma_length).rolling(length).sum()\n    denominator  swma(high_low_range, lengthswma_length).rolling(length).sum()\n\n    rvgi  numerator / denominator\n    signal  swma(rvgi, lengthswma_length)\n\n    # Offset\n    if offset ! 0:\n        rvgi  rvgi.shift(offset)\n        signal  signal.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        rvgi.fillna(kwargs[\"fillna\"], inplaceTrue)\n        signal.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        rvgi.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        signal.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name & Category\n    rvgi.name  f\"RVGI_{length}_{swma_length}\"\n    signal.name  f\"RVGIs_{length}_{swma_length}\"\n    rvgi.category  signal.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    df  DataFrame({rvgi.name: rvgi, signal.name: signal})\n    df.name  f\"RVGI_{length}_{swma_length}\"\n    df.category  rvgi.category\n\n    return df\n\n\nrvgi.__doc__  \\\n\"\"\"Relative Vigor Index (RVGI)\n\nThe Relative Vigor Index attempts to measure the strength of a trend relative to\nits closing price to its trading range.  It is based on the belief that it tends\nto close higher than they open in uptrends or close lower than they open in\ndowntrends.\n\nSources:\n    https://www.investopedia.com/terms/r/relative_vigor_index.asp\n\nCalculation:\n    Default Inputs:\n        length14, swma_length4\n    SWMA  Symmetrically Weighted Moving Average\n    numerator  SUM(SWMA(close - open, swma_length), length)\n    denominator  SUM(SWMA(high - low, swma_length), length)\n    RVGI  numerator / denominator\n\nArgs:\n    open_ (pd.Series): Series of 'open's\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 14\n    swma_length (int): It's period. Default: 4\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/slope.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import arctan as npAtan\nfrom numpy import pi as npPi\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef slope( close, lengthNone, as_angleNone, to_degreesNone, verticalNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Slope\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 1\n    as_angle  True if isinstance(as_angle, bool) else False\n    to_degrees  True if isinstance(to_degrees, bool) else False\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    slope  close.diff(length) / length\n    if as_angle:\n        slope  slope.apply(npAtan)\n        if to_degrees:\n            slope * 180 / npPi\n\n    # Offset\n    if offset ! 0:\n        slope  slope.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        slope.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        slope.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    slope.name  f\"SLOPE_{length}\" if not as_angle else f\"ANGLE{'d' if to_degrees else 'r'}_{length}\"\n    slope.category  \"momentum\"\n\n    return slope\n\n\nslope.__doc__  \\\n\"\"\"Slope\n\nReturns the slope of a series of length n. Can convert the slope to angle.\nDefault: slope.\n\nSources: Algebra I\n\nCalculation:\n    Default Inputs:\n        length1\n    slope  close.diff(length) / length\n\n    if as_angle:\n        slope  slope.apply(atan)\n        if to_degrees:\n            slope * 180 / PI\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period.  Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    as_angle (value, optional): Converts slope to an angle. Default: False\n    to_degrees (value, optional): Converts slope angle to degrees. Default: False\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/smi.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom .tsi import tsi\nfrom pandas_ta.overlap import ema\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef smi(close, fastNone, slowNone, signalNone, scalarNone, offsetNone, **kwargs):\n    \"\"\"Indicator: SMI Ergodic Indicator (SMIIO)\"\"\"\n    # Validate arguments\n    fast  int(fast) if fast and fast > 0 else 5\n    slow  int(slow) if slow and slow > 0 else 20\n    signal  int(signal) if signal and signal > 0 else 5\n    if slow < fast:\n        fast, slow  slow, fast\n    scalar  float(scalar) if scalar else 1\n    close  verify_series(close, max(fast, slow, signal))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    smi  tsi(close, fastfast, slowslow, scalarscalar)\n    signalma  ema(smi, signal)\n    osc  smi - signalma\n\n    # Offset\n    if offset ! 0:\n        smi  smi.shift(offset)\n        signalma  signalma.shift(offset)\n        osc  osc.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        smi.fillna(kwargs[\"fillna\"], inplaceTrue)\n        signalma.fillna(kwargs[\"fillna\"], inplaceTrue)\n        osc.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        smi.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        signalma.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        osc.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _scalar  f\"_{scalar}\" if scalar ! 1 else \"\"\n    _props  f\"_{fast}_{slow}_{signal}{_scalar}\"\n    smi.name  f\"SMI{_props}\"\n    signalma.name  f\"SMIs{_props}\"\n    osc.name  f\"SMIo{_props}\"\n    smi.category  signalma.category  osc.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    data  {smi.name: smi, signalma.name: signalma, osc.name: osc}\n    df  DataFrame(data)\n    df.name  f\"SMI{_props}\"\n    df.category  smi.category\n\n    return df\n\n\nsmi.__doc__  \\\n\"\"\"SMI Ergodic Indicator (SMI)\n\nThe SMI Ergodic Indicator is the same as the True Strength Index (TSI) developed\nby William Blau, except the SMI includes a signal line. The SMI uses double\nmoving averages of price minus previous price over 2 time frames. The signal\nline, which is an EMA of the SMI, is plotted to help trigger trading signals.\nThe trend is bullish when crossing above zero and bearish when crossing below\nzero. This implementation includes both the SMI Ergodic Indicator and SMI\nErgodic Oscillator.\n\nSources:\n    https://www.motivewave.com/studies/smi_ergodic_indicator.htm\n    https://www.tradingview.com/script/Xh5Q0une-SMI-Ergodic-Oscillator/\n    https://www.tradingview.com/script/cwrgy4fw-SMIIO/\n\nCalculation:\n    Default Inputs:\n        fast5, slow20, signal5\n    TSI  True Strength Index\n    EMA  Exponential Moving Average\n\n    ERG  TSI(close, fast, slow)\n    Signal  EMA(ERG, signal)\n    OSC  ERG - Signal\n\nArgs:\n    close (pd.Series): Series of 'close's\n    fast (int): The short period. Default: 5\n    slow (int): The long period. Default: 20\n    signal (int): The signal period. Default: 5\n    scalar (float): How much to magnify. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: smi, signal, oscillator columns.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Contexto: Este conteúdo está localizado na pasta raiz/pandas_ta/momentum e consiste em cinco módulos Python — squeeze.py, stoch.py, stochrsi.py, td_seq.py e trix.py — que implementam indicadores técnicos de momentum para análise de séries temporais financeiras.\\n\\nTópicos e Tecnologias: Cada módulo define uma função principal com docstrings explicativas e implementações dos seguintes indicadores de momentum:\\n\\n- squeeze.py: Squeeze Momentum Indicator (SQZ), baseado no TTM Squeeze de John Carter, combinando Bollinger Bands e Keltner Channels com opções detalhadas e LazyBear.\\n- stoch.py: Stochastic Oscillator (%K e %D), com base nos extremos de preços em janelas móveis.\\n- stochrsi.py: Stochastic RSI, que aplica o estocástico ao valor do RSI para capturar condições de sobrecompra/sobrevenda com maior sensibilidade.\\n- td_seq.py: TD Sequential (TD_SEQ), de Tom DeMark, visando identificar reversões de tendência através de contagens sequenciais de candles.\\n- trix.py: TRIX, um oscilador baseado em média móvel exponencial tripla e taxa de mudança, útil para detectar divergências.\\n\\nBibliotecas utilizadas incluem pandas e numpy, com funções utilitárias internas do pandas_ta.')\npandas_ta/momentum/squeeze.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import NaN as npNaN\nfrom pandas import DataFrame\nfrom pandas_ta.momentum import mom\nfrom pandas_ta.overlap import ema, linreg, sma\nfrom pandas_ta.trend import decreasing, increasing\nfrom pandas_ta.volatility import bbands, kc\nfrom pandas_ta.utils import get_offset\nfrom pandas_ta.utils import unsigned_differences, verify_series\n\n\ndef squeeze(high, low, close, bb_lengthNone, bb_stdNone, kc_lengthNone, kc_scalarNone, mom_lengthNone, mom_smoothNone, use_trNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Squeeze Momentum (SQZ)\"\"\"\n    # Validate arguments\n    bb_length  int(bb_length) if bb_length and bb_length > 0 else 20\n    bb_std  float(bb_std) if bb_std and bb_std > 0 else 2.0\n    kc_length  int(kc_length) if kc_length and kc_length > 0 else 20\n    kc_scalar  float(kc_scalar) if kc_scalar and kc_scalar > 0 else 1.5\n    mom_length  int(mom_length) if mom_length and mom_length > 0 else 12\n    mom_smooth  int(mom_smooth) if mom_smooth and mom_smooth > 0 else 6\n    _length  max(bb_length, kc_length, mom_length, mom_smooth)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    use_tr  kwargs.setdefault(\"tr\", True)\n    asint  kwargs.pop(\"asint\", True)\n    detailed  kwargs.pop(\"detailed\", False)\n    lazybear  kwargs.pop(\"lazybear\", False)\n    mamode  kwargs.pop(\"mamode\", \"sma\").lower()\n\n    def simplify_columns(df, n3):\n        df.columns  df.columns.str.lower()\n        return [c.split(\"_\")[0][n - 1:n] for c in df.columns]\n\n    # Calculate Result\n    bbd  bbands(close, lengthbb_length, stdbb_std, mamodemamode)\n    kch  kc(high, low, close, lengthkc_length, scalarkc_scalar, mamodemamode, truse_tr)\n\n    # Simplify KC and BBAND column names for dynamic access\n    bbd.columns  simplify_columns(bbd)\n    kch.columns  simplify_columns(kch)\n\n    if lazybear:\n        highest_high  high.rolling(kc_length).max()\n        lowest_low  low.rolling(kc_length).min()\n        avg_  0.25 * (highest_high + lowest_low) + 0.5 * kch.b\n\n        squeeze  linreg(close - avg_, lengthkc_length)\n\n    else:\n        momo  mom(close, lengthmom_length)\n        if mamode.lower()  \"ema\":\n            squeeze  ema(momo, lengthmom_smooth)\n        else: # \"sma\"\n            squeeze  sma(momo, lengthmom_smooth)\n\n    # Classify Squeezes\n    squeeze_on  (bbd.l > kch.l) & (bbd.u < kch.u)\n    squeeze_off  (bbd.l < kch.l) & (bbd.u > kch.u)\n    no_squeeze  ~squeeze_on & ~squeeze_off\n\n    # Offset\n    if offset ! 0:\n        squeeze  squeeze.shift(offset)\n        squeeze_on  squeeze_on.shift(offset)\n        squeeze_off  squeeze_off.shift(offset)\n        no_squeeze  no_squeeze.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        squeeze.fillna(kwargs[\"fillna\"], inplaceTrue)\n        squeeze_on.fillna(kwargs[\"fillna\"], inplaceTrue)\n        squeeze_off.fillna(kwargs[\"fillna\"], inplaceTrue)\n        no_squeeze.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        squeeze.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        squeeze_on.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        squeeze_off.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        no_squeeze.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _props  \"\" if use_tr else \"hlr\"\n    _props + f\"_{bb_length}_{bb_std}_{kc_length}_{kc_scalar}\"\n    _props + \"_LB\" if lazybear else \"\"\n    squeeze.name  f\"SQZ{_props}\"\n\n    data  {\n        squeeze.name: squeeze,\n        f\"SQZ_ON\": squeeze_on.astype(int) if asint else squeeze_on,\n        f\"SQZ_OFF\": squeeze_off.astype(int) if asint else squeeze_off,\n        f\"SQZ_NO\": no_squeeze.astype(int) if asint else no_squeeze,\n    }\n    df  DataFrame(data)\n    df.name  squeeze.name\n    df.category  squeeze.category  \"momentum\"\n\n    # Detailed Squeeze Series\n    if detailed:\n        pos_squeeze  squeeze[squeeze > 0]\n        neg_squeeze  squeeze[squeeze < 0]\n\n        pos_inc, pos_dec  unsigned_differences(pos_squeeze, asintTrue)\n        neg_inc, neg_dec  unsigned_differences(neg_squeeze, asintTrue)\n\n        pos_inc * squeeze\n        pos_dec * squeeze\n        neg_dec * squeeze\n        neg_inc * squeeze\n\n        pos_inc.replace(0, npNaN, inplaceTrue)\n        pos_dec.replace(0, npNaN, inplaceTrue)\n        neg_dec.replace(0, npNaN, inplaceTrue)\n        neg_inc.replace(0, npNaN, inplaceTrue)\n\n        sqz_inc  squeeze * increasing(squeeze)\n        sqz_dec  squeeze * decreasing(squeeze)\n        sqz_inc.replace(0, npNaN, inplaceTrue)\n        sqz_dec.replace(0, npNaN, inplaceTrue)\n\n        # Handle fills\n        if \"fillna\" in kwargs:\n            sqz_inc.fillna(kwargs[\"fillna\"], inplaceTrue)\n            sqz_dec.fillna(kwargs[\"fillna\"], inplaceTrue)\n            pos_inc.fillna(kwargs[\"fillna\"], inplaceTrue)\n            pos_dec.fillna(kwargs[\"fillna\"], inplaceTrue)\n            neg_dec.fillna(kwargs[\"fillna\"], inplaceTrue)\n            neg_inc.fillna(kwargs[\"fillna\"], inplaceTrue)\n        if \"fill_method\" in kwargs:\n            sqz_inc.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n            sqz_dec.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n            pos_inc.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n            pos_dec.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n            neg_dec.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n            neg_inc.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n        df[f\"SQZ_INC\"]  sqz_inc\n        df[f\"SQZ_DEC\"]  sqz_dec\n        df[f\"SQZ_PINC\"]  pos_inc\n        df[f\"SQZ_PDEC\"]  pos_dec\n        df[f\"SQZ_NDEC\"]  neg_dec\n        df[f\"SQZ_NINC\"]  neg_inc\n\n    return df\n\n\nsqueeze.__doc__  \\\n\"\"\"Squeeze (SQZ)\n\nThe default is based on John Carter's \"TTM Squeeze\" indicator, as discussed\nin his book \"Mastering the Trade\" (chapter 11). The Squeeze indicator attempts\nto capture the relationship between two studies: Bollinger BandsÂ® and Keltner's\nChannels. When the volatility increases, so does the distance between the bands,\nconversely, when the volatility declines, the distance also decreases. It finds\nsections of the Bollinger BandsÂ® study which fall inside the Keltner's Channels.\n\nSources:\n    https://tradestation.tradingappstore.com/products/TTMSqueeze\n    https://www.tradingview.com/scripts/lazybear/\n    https://tlc.thinkorswim.com/center/reference/Tech-Indicators/studies-library/T-U/TTM-Squeeze\n\nCalculation:\n    Default Inputs:\n        bb_length20, bb_std2, kc_length20, kc_scalar1.5, mom_length12,\n        mom_smooth12, trTrue, lazybearFalse,\n    BB  Bollinger Bands\n    KC  Keltner Channels\n    MOM  Momentum\n    SMA  Simple Moving Average\n    EMA  Exponential Moving Average\n    TR  True Range\n\n    RANGE  TR(high, low, close) if using_tr else high - low\n    BB_LOW, BB_MID, BB_HIGH  BB(close, bb_length, stdbb_std)\n    KC_LOW, KC_MID, KC_HIGH  KC(high, low, close, kc_length, kc_scalar, TR)\n\n    if lazybear:\n        HH  high.rolling(kc_length).max()\n        LL  low.rolling(kc_length).min()\n        AVG   0.25 * (HH + LL) + 0.5 * KC_MID\n        SQZ  linreg(close - AVG, kc_length)\n    else:\n        MOMO  MOM(close, mom_length)\n        if mamode  \"ema\":\n            SQZ  EMA(MOMO, mom_smooth)\n        else:\n            SQZ  EMA(momo, mom_smooth)\n\n    SQZ_ON   (BB_LOW > KC_LOW) and (BB_HIGH < KC_HIGH)\n    SQZ_OFF  (BB_LOW < KC_LOW) and (BB_HIGH > KC_HIGH)\n    NO_SQZ  !SQZ_ON and !SQZ_OFF\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    bb_length (int): Bollinger Bands period. Default: 20\n    bb_std (float): Bollinger Bands Std. Dev. Default: 2\n    kc_length (int): Keltner Channel period. Default: 20\n    kc_scalar (float): Keltner Channel scalar. Default: 1.5\n    mom_length (int): Momentum Period. Default: 12\n    mom_smooth (int): Smoothing Period of Momentum. Default: 6\n    mamode (str): Only \"ema\" or \"sma\". Default: \"sma\"\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    tr (value, optional): Use True Range for Keltner Channels. Default: True\n    asint (value, optional): Use integers instead of bool. Default: True\n    mamode (value, optional): Which MA to use. Default: \"sma\"\n    lazybear (value, optional): Use LazyBear's TradingView implementation.\n        Default: False\n    detailed (value, optional): Return additional variations of SQZ for\n        visualization. Default: False\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: SQZ, SQZ_ON, SQZ_OFF, NO_SQZ columns by default. More\n        detailed columns if 'detailed' kwarg is True.\n\"\"\"\n\n\n\npandas_ta/momentum/stoch.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import sma\nfrom pandas_ta.utils import get_offset, non_zero_range, verify_series\n\n\ndef stoch(high, low, close, kNone, dNone, smooth_kNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Stochastic Oscillator (STOCH)\"\"\"\n    # Validate arguments\n    k  k if k and k > 0 else 14\n    d  d if d and d > 0 else 3\n    smooth_k  smooth_k if smooth_k and smooth_k > 0 else 3\n    _length  max(k, d, smooth_k)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    lowest_low  low.rolling(k).min()\n    highest_high  high.rolling(k).max()\n\n    stoch  100 * (close - lowest_low)\n    stoch / non_zero_range(highest_high, lowest_low)\n\n    stoch_k  sma(stoch, lengthsmooth_k)\n    stoch_d  sma(stoch_k, lengthd)\n\n    # Offset\n    if offset ! 0:\n        stoch_k  stoch_k.shift(offset)\n        stoch_d  stoch_d.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        stoch_k.fillna(kwargs[\"fillna\"], inplaceTrue)\n        stoch_d.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        stoch_k.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        stoch_d.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _name  \"STOCH\"\n    _props  f\"_{k}_{d}_{smooth_k}\"\n    stoch_k.name  f\"{_name}k{_props}\"\n    stoch_d.name  f\"{_name}d{_props}\"\n    stoch_k.category  stoch_d.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    data  {stoch_k.name: stoch_k, stoch_d.name: stoch_d}\n    df  DataFrame(data)\n    df.name  f\"{_name}{_props}\"\n    df.category  stoch_k.category\n\n    return df\n\n\nstoch.__doc__  \\\n\"\"\"Stochastic (STOCH)\n\nThe Stochastic Oscillator (STOCH) was developed by George Lane in the 1950's.\nHe believed this indicator was a good way to measure momentum because changes in\nmomentum precede changes in price.\n\nIt is a range-bound oscillator with two lines moving between 0 and 100.\nThe first line (%K) displays the current close in relation to the period's\nhigh/low range. The second line (%D) is a Simple Moving Average of the %K line.\nThe most common choices are a 14 period %K and a 3 period SMA for %D.\n\nSources:\n    https://www.tradingview.com/wiki/Stochastic_(STOCH)\n    https://www.sierrachart.com/index.php?pagedoc/StudiesReference.php&ID332&NameKD_-_Slow\n\nCalculation:\n    Default Inputs:\n        k14, d3, smooth_k3\n    SMA  Simple Moving Average\n    LL   low for last k periods\n    HH   high for last k periods\n\n    STOCH  100 * (close - LL) / (HH - LL)\n    STOCHk  SMA(STOCH, smooth_k)\n    STOCHd  SMA(FASTK, d)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    k (int): The Fast %K period. Default: 14\n    d (int): The Slow %K period. Default: 3\n    smooth_k (int): The Slow %D period. Default: 3\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: %K, %D columns.\n\"\"\"\n\n\n\npandas_ta/momentum/stochrsi.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom .rsi import rsi\nfrom pandas_ta.overlap import sma\nfrom pandas_ta.utils import get_offset, non_zero_range, verify_series\n\n\ndef stochrsi(close, lengthNone, rsi_lengthNone, kNone, dNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Stochastic RSI Oscillator (STOCHRSI)\"\"\"\n    # Validate arguments\n    length  length if length and length > 0 else 14\n    rsi_length  rsi_length if rsi_length and rsi_length > 0 else 14\n    k  k if k and k > 0 else 3\n    d  d if d and d > 0 else 3\n    close  verify_series(close, max(length, rsi_length, k, d))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    rsi_  rsi(close, lengthrsi_length)\n    lowest_rsi  rsi_.rolling(length).min()\n    highest_rsi  rsi_.rolling(length).max()\n\n    stoch  100 * (rsi_ - lowest_rsi)\n    stoch / non_zero_range(highest_rsi, lowest_rsi)\n\n    stochrsi_k  sma(stoch, lengthk)\n    stochrsi_d  sma(stochrsi_k, lengthd)\n\n    # Offset\n    if offset ! 0:\n        stochrsi_k  stochrsi_k.shift(offset)\n        stochrsi_d  stochrsi_d.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        stochrsi_k.fillna(kwargs[\"fillna\"], inplaceTrue)\n        stochrsi_d.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        stochrsi_k.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        stochrsi_d.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _name  \"STOCHRSI\"\n    _props  f\"_{length}_{rsi_length}_{k}_{d}\"\n    stochrsi_k.name  f\"{_name}k{_props}\"\n    stochrsi_d.name  f\"{_name}d{_props}\"\n    stochrsi_k.category  stochrsi_d.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    data  {stochrsi_k.name: stochrsi_k, stochrsi_d.name: stochrsi_d}\n    df  DataFrame(data)\n    df.name  f\"{_name}{_props}\"\n    df.category  stochrsi_k.category\n\n    return df\n\n\nstochrsi.__doc__  \\\n\"\"\"Stochastic (STOCHRSI)\n\n\"Stochastic RSI and Dynamic Momentum Index\" was created by Tushar Chande and Stanley Kroll and published in Stock & Commodities V.11:5 (189-199)\n\nIt is a range-bound oscillator with two lines moving between 0 and 100.\nThe first line (%K) displays the current RSI in relation to the period's\nhigh/low range. The second line (%D) is a Simple Moving Average of the %K line.\nThe most common choices are a 14 period %K and a 3 period SMA for %D.\n\nSources:\n    https://www.tradingview.com/wiki/Stochastic_(STOCH)\n\nCalculation:\n    Default Inputs:\n        length14, rsi_length14, k3, d3\n    RSI  Relative Strength Index\n    SMA  Simple Moving Average\n\n    RSI  RSI(high, low, close, rsi_length)\n    LL   lowest RSI for last rsi_length periods\n    HH   highest RSI for last rsi_length periods\n\n    STOCHRSI   100 * (RSI - LL) / (HH - LL)\n    STOCHRSIk  SMA(STOCHRSI, k)\n    STOCHRSId  SMA(STOCHRSIk, d)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): The STOCHRSI period. Default: 14\n    rsi_length (int): RSI period. Default: 14\n    k (int): The Fast %K period. Default: 3\n    d (int): The Slow %K period. Default: 3\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: RSI %K, RSI %D columns.\n\"\"\"\n\n\n\npandas_ta/momentum/td_seq.py\n\n# -*- coding: utf-8 -*-\n# import numpy as np\nfrom numpy import where as npWhere\nfrom pandas import DataFrame, Series\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef td_seq(close, asintNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Tom Demark Sequential (TD_SEQ)\"\"\"\n    # Validate arguments\n    close  verify_series(close)\n    offset  get_offset(offset)\n    asint  asint if isinstance(asint, bool) else False\n    show_all  kwargs.setdefault(\"show_all\", True)\n\n    def true_sequence_count(series: Series):\n        index  series.where(series  False).last_valid_index()\n\n        if index is None:\n            return series.count()\n        else:\n            s  series[series.index > index]\n            return s.count()\n\n    def calc_td(series: Series, direction: str, show_all: bool):\n        td_bool  series.diff(4) > 0 if direction\"up\" else series.diff(4) < 0\n        td_num  npWhere(\n            td_bool, td_bool.rolling(13, min_periods0).apply(true_sequence_count), 0\n        )\n        td_num  Series(td_num)\n\n        if show_all:\n            td_num  td_num.mask(td_num  0)\n        else:\n            td_num  td_num.mask(~td_num.between(6,9))\n\n        return td_num\n\n    up_seq  calc_td(close, \"up\", show_all)\n    down_seq  calc_td(close, \"down\", show_all)\n\n    if asint:\n        if up_seq.hasnans and down_seq.hasnans:\n            up_seq.fillna(0, inplaceTrue)\n            down_seq.fillna(0, inplaceTrue)\n        up_seq  up_seq.astype(int)\n        down_seq  down_seq.astype(int)\n\n     # Offset\n    if offset ! 0:\n        up_seq  up_seq.shift(offset)\n        down_seq  down_seq.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        up_seq.fillna(kwargs[\"fillna\"], inplaceTrue)\n        down_seq.fillna(kwargs[\"fillna\"], inplaceTrue)\n\n    if \"fill_method\" in kwargs:\n        up_seq.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        down_seq.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name & Category\n    up_seq.name  f\"TD_SEQ_UPa\" if show_all else f\"TD_SEQ_UP\"\n    down_seq.name  f\"TD_SEQ_DNa\" if show_all else f\"TD_SEQ_DN\"\n    up_seq.category  down_seq.category  \"momentum\"\n\n    # Prepare Dataframe to return\n    data  {\n        up_seq.name: up_seq,\n        down_seq.name: down_seq\n    }\n    df  DataFrame(data)\n    df.name  \"TD_SEQ\"\n    df.category  up_seq.category\n\n    return df\n\n\ntd_seq.__doc__  \\\n\"\"\"TD Sequential (TD_SEQ)\n\nTom DeMark's Sequential indicator attempts to identify a price point where an\nuptrend or a downtrend exhausts itself and reverses.\n\nSources:\n    https://tradetrekker.wordpress.com/tdsequential/\n\nCalculation:\n    Compare current close price with 4 days ago price, up to 13 days. For the\n    consecutive ascending or descending price sequence, display 6th to 9th day\n    value.\n\nArgs:\n    close (pd.Series): Series of 'close's\n    asint (bool): If True, fillnas with 0 and change type to int. Default: False\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    show_all (bool): Show 1 - 13. If set to False, show 6 - 9. Default: True\n    fillna (value, optional): pd.DataFrame.fillna(value)\n\nReturns:\n    pd.DataFrame: New feature generated.\n\"\"\"\n\n\npandas_ta/momentum/trix.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap.ema import ema\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef trix(close, lengthNone, signalNone, scalarNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Trix (TRIX)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 30\n    signal  int(signal) if signal and signal > 0 else 9\n    scalar  float(scalar) if scalar else 100\n    close  verify_series(close, max(length, signal))\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    ema1  ema(closeclose, lengthlength, **kwargs)\n    ema2  ema(closeema1, lengthlength, **kwargs)\n    ema3  ema(closeema2, lengthlength, **kwargs)\n    trix  scalar * ema3.pct_change(drift)\n\n    trix_signal  trix.rolling(signal).mean()\n\n    # Offset\n    if offset ! 0:\n        trix  trix.shift(offset)\n        trix_signal  trix_signal.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        trix.fillna(kwargs[\"fillna\"], inplaceTrue)\n        trix_signal.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        trix.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        trix_signal.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name & Category\n    trix.name  f\"TRIX_{length}_{signal}\"\n    trix_signal.name  f\"TRIXs_{length}_{signal}\"\n    trix.category  trix_signal.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    df  DataFrame({trix.name: trix, trix_signal.name: trix_signal})\n    df.name  f\"TRIX_{length}_{signal}\"\n    df.category  \"momentum\"\n\n    return df\n\n\ntrix.__doc__  \\\n\"\"\"Trix (TRIX)\n\nTRIX is a momentum oscillator to identify divergences.\n\nSources:\n    https://www.tradingview.com/wiki/TRIX\n\nCalculation:\n    Default Inputs:\n        length18, drift1\n    EMA  Exponential Moving Average\n    ROC  Rate of Change\n    ema1  EMA(close, length)\n    ema2  EMA(ema1, length)\n    ema3  EMA(ema2, length)\n    TRIX  100 * ROC(ema3, drift)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 18\n    signal (int): It's period. Default: 9\n    scalar (float): How much to magnify. Default: 100\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output=\"Este trecho pertence ao diretório pandas_ta e abrange arquivos dos subdiretórios momentum e overlap. Os arquivos em momentum implementam indicadores de momentum: True Strength Index (TSI), Ultimate Oscillator (UO) e William's %R (WILLR). Já os arquivos de overlap definem médias móveis (moving averages), como Exponential Moving Average (EMA), Arnaud Legoux (ALMA), Double EMA (DEMA) e Fibonacci Weighted MA (FWMA). As tecnologias envolvidas são Python e pandas, focando em cálculos financeiros e análise técnica.\")\npandas_ta/momentum/tsi.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import ema\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef tsi(close, fastNone, slowNone, scalarNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: True Strength Index (TSI)\"\"\"\n    # Validate Arguments\n    fast  int(fast) if fast and fast > 0 else 13\n    slow  int(slow) if slow and slow > 0 else 25\n    # if slow < fast:\n    #     fast, slow  slow, fast\n    scalar  float(scalar) if scalar else 100\n    close  verify_series(close, max(fast, slow))\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n    if \"length\" in kwargs: kwargs.pop(\"length\")\n\n    if close is None: return\n\n    # Calculate Result\n    diff  close.diff(drift)\n    slow_ema  ema(closediff, lengthslow, **kwargs)\n    fast_slow_ema  ema(closeslow_ema, lengthfast, **kwargs)\n\n    abs_diff  diff.abs()\n    abs_slow_ema  ema(closeabs_diff, lengthslow, **kwargs)\n    abs_fast_slow_ema  ema(closeabs_slow_ema, lengthfast, **kwargs)\n\n    tsi  scalar * fast_slow_ema / abs_fast_slow_ema\n\n    # Offset\n    if offset ! 0:\n        tsi  tsi.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        tsi.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        tsi.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    tsi.name  f\"TSI_{fast}_{slow}\"\n    tsi.category  \"momentum\"\n\n    return tsi\n\n\ntsi.__doc__  \\\n\"\"\"True Strength Index (TSI)\n\nThe True Strength Index is a momentum indicator used to identify short-term\nswings while in the direction of the trend as well as determining overbought\nand oversold conditions.\n\nSources:\n    https://www.investopedia.com/terms/t/tsi.asp\n\nCalculation:\n    Default Inputs:\n        fast13, slow25, scalar100, drift1\n    EMA  Exponential Moving Average\n    diff  close.diff(drift)\n\n    slow_ema  EMA(diff, slow)\n    fast_slow_ema  EMA(slow_ema, slow)\n\n    abs_diff_slow_ema  absolute_diff_ema  EMA(ABS(diff), slow)\n    abema  abs_diff_fast_slow_ema  EMA(abs_diff_slow_ema, fast)\n\n    TSI  scalar * fast_slow_ema / abema\n\nArgs:\n    close (pd.Series): Series of 'close's\n    fast (int): The short period. Default: 13\n    slow (int): The long period. Default: 25\n    scalar (float): How much to magnify. Default: 100\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/uo.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef uo(high, low, close, fastNone, mediumNone, slowNone, fast_wNone, medium_wNone, slow_wNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Ultimate Oscillator (UO)\"\"\"\n    # Validate arguments\n    fast  int(fast) if fast and fast > 0 else 7\n    fast_w  float(fast_w) if fast_w and fast_w > 0 else 4.0\n    medium  int(medium) if medium and medium > 0 else 14\n    medium_w  float(medium_w) if medium_w and medium_w > 0 else 2.0\n    slow  int(slow) if slow and slow > 0 else 28\n    slow_w  float(slow_w) if slow_w and slow_w > 0 else 1.0\n    _length  max(fast, medium, slow)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    tdf  DataFrame({\n        \"high\": high,\n        \"low\": low,\n        f\"close_{drift}\": close.shift(drift)\n    })\n    max_h_or_pc  tdf.loc[:, [\"high\", f\"close_{drift}\"]].max(axis1)\n    min_l_or_pc  tdf.loc[:, [\"low\", f\"close_{drift}\"]].min(axis1)\n    del tdf\n\n    bp  close - min_l_or_pc\n    tr  max_h_or_pc - min_l_or_pc\n\n    fast_avg  bp.rolling(fast).sum() / tr.rolling(fast).sum()\n    medium_avg  bp.rolling(medium).sum() / tr.rolling(medium).sum()\n    slow_avg  bp.rolling(slow).sum() / tr.rolling(slow).sum()\n\n    total_weight  fast_w + medium_w + slow_w\n    weights  (fast_w * fast_avg) + (medium_w * medium_avg) + (slow_w * slow_avg)\n    uo  100 * weights / total_weight\n\n    # Offset\n    if offset ! 0:\n        uo  uo.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        uo.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        uo.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    uo.name  f\"UO_{fast}_{medium}_{slow}\"\n    uo.category  \"momentum\"\n\n    return uo\n\n\nuo.__doc__  \\\n\"\"\"Ultimate Oscillator (UO)\n\nThe Ultimate Oscillator is a momentum indicator over three different\nperiods.  It attempts to correct false divergence trading signals.\n\nSources:\n    https://www.tradingview.com/wiki/Ultimate_Oscillator_(UO)\n\nCalculation:\n    Default Inputs:\n        fast7, medium14, slow28,\n        fast_w4.0, medium_w2.0, slow_w1.0, drift1\n    min_low_or_pc   close.shift(drift).combine(low, min)\n    max_high_or_pc  close.shift(drift).combine(high, max)\n\n    bp  buying pressure  close - min_low_or_pc\n    tr  true range  max_high_or_pc - min_low_or_pc\n\n    fast_avg  SUM(bp, fast) / SUM(tr, fast)\n    medium_avg  SUM(bp, medium) / SUM(tr, medium)\n    slow_avg  SUM(bp, slow) / SUM(tr, slow)\n\n    total_weight  fast_w + medium_w + slow_w\n    weights  (fast_w * fast_avg) + (medium_w * medium_avg) + (slow_w * slow_avg)\n    UO  100 * weights / total_weight\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    fast (int): The Fast %K period. Default: 7\n    medium (int): The Slow %K period. Default: 14\n    slow (int): The Slow %D period. Default: 28\n    fast_w (float): The Fast %K period. Default: 4.0\n    medium_w (float): The Slow %K period. Default: 2.0\n    slow_w (float): The Slow %D period. Default: 1.0\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/momentum/willr.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef willr(high, low, close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: William's Percent R (WILLR)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 14\n    min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    _length  max(length, min_periods)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    lowest_low  low.rolling(length, min_periodsmin_periods).min()\n    highest_high  high.rolling(length, min_periodsmin_periods).max()\n\n    willr  100 * ((close - lowest_low) / (highest_high - lowest_low) - 1)\n\n    # Offset\n    if offset ! 0:\n        willr  willr.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        willr.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        willr.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    willr.name  f\"WILLR_{length}\"\n    willr.category  \"momentum\"\n\n    return willr\n\n\nwillr.__doc__  \\\n\"\"\"William's Percent R (WILLR)\n\nWilliam's Percent R is a momentum oscillator similar to the RSI that\nattempts to identify overbought and oversold conditions.\n\nSources:\n    https://www.tradingview.com/wiki/Williams_%25R_(%25R)\n\nCalculation:\n    Default Inputs:\n        length20\n    LL  low.rolling(length).min()\n    HH  high.rolling(length).max()\n\n    WILLR  100 * ((close - LL) / (HH - LL) - 1)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 14\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/__init__.py\n\n# -*- coding: utf-8 -*-\nfrom .alma import alma\nfrom .dema import dema\nfrom .ema import ema\nfrom .fwma import fwma\nfrom .hilo import hilo\nfrom .hl2 import hl2\nfrom .hlc3 import hlc3\nfrom .hma import hma\nfrom .hwma import hwma\nfrom .kama import kama\nfrom .ichimoku import ichimoku\nfrom .linreg import linreg\nfrom .ma import ma\nfrom .mcgd import mcgd\nfrom .midpoint import midpoint\nfrom .midprice import midprice\nfrom .ohlc4 import ohlc4\nfrom .pwma import pwma\nfrom .rma import rma\nfrom .sinwma import sinwma\nfrom .sma import sma\nfrom .ssf import ssf\nfrom .supertrend import supertrend\nfrom .swma import swma\nfrom .t3 import t3\nfrom .tema import tema\nfrom .trima import trima\nfrom .vidya import vidya\nfrom .vwap import vwap\nfrom .vwma import vwma\nfrom .wcp import wcp\nfrom .wma import wma\nfrom .zlma import zlma\n\n\npandas_ta/overlap/alma.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import exp as npExp\nfrom numpy import NaN as npNaN\nfrom pandas import Series\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef alma(close, lengthNone, sigmaNone, distribution_offsetNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Arnaud Legoux Moving Average (ALMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    sigma  float(sigma) if sigma and sigma > 0 else 6.0\n    distribution_offset  float(distribution_offset) if distribution_offset and distribution_offset > 0 else 0.85\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Pre-Calculations\n    m  distribution_offset * (length - 1)\n    s  length / sigma\n    wtd  list(range(length))\n    for i in range(0, length):\n        wtd[i]  npExp(-1 * ((i - m) * (i - m)) / (2 * s * s))\n\n    # Calculate Result\n    result  [npNaN for _ in range(0, length - 1)] + [0]\n    for i in range(length, close.size):\n        window_sum  0\n        cum_sum  0\n        for j in range(0, length):\n            # wtd  math.exp(-1 * ((j - m) * (j - m)) / (2 * s * s))        # moved to pre-calc for efficiency\n            window_sum  window_sum + wtd[j] * close.iloc[i - j]\n            cum_sum  cum_sum + wtd[j]\n\n        almean  window_sum / cum_sum\n        result.append(npNaN) if i  length else result.append(almean)\n\n    alma  Series(result, indexclose.index)\n\n    # Offset\n    if offset ! 0:\n        alma  alma.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        alma.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        alma.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name & Category\n    alma.name  f\"ALMA_{length}_{sigma}_{distribution_offset}\"\n    alma.category  \"overlap\"\n\n    return alma\n\n\nalma.__doc__  \\\n\"\"\"Arnaud Legoux Moving Average (ALMA)\n\nThe ALMA moving average uses the curve of the Normal (Gauss) distribution, which\ncan be shifted from 0 to 1. This allows regulating the smoothness and high\nsensitivity of the indicator. Sigma is another parameter that is responsible for\nthe shape of the curve coefficients. This moving average reduces lag of the data\nin conjunction with smoothing to reduce noise.\n\nImplemented for Pandas TA by rengel8 based on the source provided below.\n\nSources:\n    https://www.prorealcode.com/prorealtime-indicators/alma-arnaud-legoux-moving-average/\n\nCalculation:\n    refer to provided source\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period, window size. Default: 10\n    sigma (float): Smoothing value. Default 6.0\n    distribution_offset (float): Value to offset the distribution min 0\n        (smoother), max 1 (more responsive). Default 0.85\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/dema.py\n\n# -*- coding: utf-8 -*-\nfrom .ema import ema\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef dema(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Double Exponential Moving Average (DEMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    ema1  ema(closeclose, lengthlength)\n    ema2  ema(closeema1, lengthlength)\n    dema  2 * ema1 - ema2\n\n    # Offset\n    if offset ! 0:\n        dema  dema.shift(offset)\n\n    # Name & Category\n    dema.name  f\"DEMA_{length}\"\n    dema.category  \"overlap\"\n\n    return dema\n\n\ndema.__doc__  \\\n\"\"\"Double Exponential Moving Average (DEMA)\n\nThe Double Exponential Moving Average attempts to a smoother average with less\nlag than the normal Exponential Moving Average (EMA).\n\nSources:\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/double-exponential-moving-average-dema/\n\nCalculation:\n    Default Inputs:\n        length10\n    EMA  Exponential Moving Average\n    ema1  EMA(close, length)\n    ema2  EMA(ema1, length)\n\n    DEMA  2 * ema1 - ema2\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/ema.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import NaN as npNaN\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef ema(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Exponential Moving Average (EMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    adjust  kwargs.pop(\"adjust\", False)\n    sma  kwargs.pop(\"sma\", True)\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    if sma:\n        close  close.copy()\n        sma_nth  close[0:length].mean()\n        close[:length - 1]  npNaN\n        close.iloc[length - 1]  sma_nth\n    ema  close.ewm(spanlength, adjustadjust).mean()\n\n    # Offset\n    if offset ! 0:\n        ema  ema.shift(offset)\n\n    # Name & Category\n    ema.name  f\"EMA_{length}\"\n    ema.category  \"overlap\"\n\n    return ema\n\n\nema.__doc__  \\\n\"\"\"Exponential Moving Average (EMA)\n\nThe Exponential Moving Average is more responsive moving average compared to the\nSimple Moving Average (SMA).  The weights are determined by alpha which is\nproportional to it's length.  There are several different methods of calculating\nEMA.  One method uses just the standard definition of EMA and another uses the\nSMA to generate the initial value for the rest of the calculation.\n\nSources:\n    https://stockcharts.com/school/doku.php?idchart_school:technical_indicators:moving_averages\n    https://www.investopedia.com/ask/answers/122314/what-exponential-moving-average-ema-formula-and-how-ema-calculated.asp\n\nCalculation:\n    Default Inputs:\n        length10, adjustFalse, smaTrue\n    if sma:\n        sma_nth  close[0:length].sum() / length\n        close[:length - 1]  np.NaN\n        close.iloc[length - 1]  sma_nth\n    EMA  close.ewm(spanlength, adjustadjust).mean()\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    adjust (bool, optional): Default: False\n    sma (bool, optional): If True, uses SMA for initial value. Default: True\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/fwma.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import fibonacci, get_offset, verify_series, weights\n\n\ndef fwma(close, lengthNone, ascNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Fibonacci's Weighted Moving Average (FWMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    asc  asc if asc else True\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    fibs  fibonacci(nlength, weightedTrue)\n    fwma  close.rolling(length, min_periodslength).apply(weights(fibs), rawTrue)\n\n    # Offset\n    if offset ! 0:\n        fwma  fwma.shift(offset)\n\n    # Name & Category\n    fwma.name  f\"FWMA_{length}\"\n    fwma.category  \"overlap\"\n\n    return fwma\n\n\nfwma.__doc__  \\\n\"\"\"Fibonacci's Weighted Moving Average (FWMA)\n\nFibonacci's Weighted Moving Average is similar to a Weighted Moving Average\n(WMA) where the weights are based on the Fibonacci Sequence.\n\nSource: Kevin Johnson\n\nCalculation:\n    Default Inputs:\n        length10,\n\n    def weights(w):\n        def _compute(x):\n            return np.dot(w * x)\n        return _compute\n\n    fibs  utils.fibonacci(length - 1)\n    FWMA  close.rolling(length)_.apply(weights(fibs), rawTrue)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    asc (bool): Recent values weigh more. Default: True\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output=\"Esses arquivos pertencem ao diretório pandas_ta/overlap e implementam indicadores técnicos de análise de tendências baseados em médias móveis para o pacote Pandas TA. Os principais indicadores abordados incluem Gann HiLo (hilo.py), HL2 e HLC3 (hl2.py, hlc3.py), Hull Moving Average – HMA (hma.py), Holt-Winter Moving Average – HWMA (hwma.py), Ichimoku Kinkō Hyō (ichimoku.py), e Kaufman's Adaptive Moving Average – KAMA (kama.py). Cada indicador trata de diferentes cálculos de médias móveis, incluindo simples, exponenciais e adaptativas, com suporte a parâmetros de offset e preenchimento de dados faltantes.\")\npandas_ta/overlap/hilo.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import NaN as npNaN\nfrom pandas import DataFrame, Series\nfrom .ma import ma\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef hilo(high, low, close, high_lengthNone, low_lengthNone, mamodeNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Gann HiLo (HiLo)\"\"\"\n    # Validate Arguments\n    high_length  int(high_length) if high_length and high_length > 0 else 13\n    low_length  int(low_length) if low_length and low_length > 0 else 21\n    mamode  mamode.lower() if isinstance(mamode, str) else \"sma\"\n    _length  max(high_length, low_length)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    m  close.size\n    hilo  Series(npNaN, indexclose.index)\n    long  Series(npNaN, indexclose.index)\n    short  Series(npNaN, indexclose.index)\n\n    high_ma  ma(mamode, high, lengthhigh_length)\n    low_ma  ma(mamode, low, lengthlow_length)\n\n    for i in range(1, m):\n        if close.iloc[i] > high_ma.iloc[i - 1]:\n            hilo.iloc[i]  long.iloc[i]  low_ma.iloc[i]\n        elif close.iloc[i] < low_ma.iloc[i - 1]:\n            hilo.iloc[i]  short.iloc[i]  high_ma.iloc[i]\n        else:\n            hilo.iloc[i]  hilo.iloc[i - 1]\n            long.iloc[i]  short.iloc[i]  hilo.iloc[i - 1]\n\n    # Offset\n    if offset ! 0:\n        hilo  hilo.shift(offset)\n        long  long.shift(offset)\n        short  short.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        hilo.fillna(kwargs[\"fillna\"], inplaceTrue)\n        long.fillna(kwargs[\"fillna\"], inplaceTrue)\n        short.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        hilo.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        long.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        short.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name & Category\n    _props  f\"_{high_length}_{low_length}\"\n    data  {f\"HILO{_props}\": hilo, f\"HILOl{_props}\": long, f\"HILOs{_props}\": short}\n    df  DataFrame(data, indexclose.index)\n\n    df.name  f\"HILO{_props}\"\n    df.category  \"overlap\"\n\n    return df\n\n\nhilo.__doc__  \\\n\"\"\"Gann HiLo Activator(HiLo)\n\nThe Gann High Low Activator Indicator was created by Robert Krausz in a 1998\nissue of Stocks & Commodities Magazine. It is a moving average based trend\nindicator consisting of two different simple moving averages.\n\nThe indicator tracks both curves (of the highs and the lows). The close of the\nbar defines which of the two gets plotted.\n\nIncreasing high_length and decreasing low_length better for short trades,\nvice versa for long positions.\n\nSources:\n    https://www.sierrachart.com/index.php?pagedoc/StudiesReference.php&ID447&NameGann_HiLo_Activator\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/simple-moving-average-sma/\n    https://www.tradingview.com/script/XNQSLIYb-Gann-High-Low/\n\nCalculation:\n    Default Inputs:\n        high_length13, low_length21, mamode\"sma\"\n    EMA  Exponential Moving Average\n    HMA  Hull Moving Average\n    SMA  Simple Moving Average # Default\n\n    if \"ema\":\n        high_ma  EMA(high, high_length)\n        low_ma  EMA(low, low_length)\n    elif \"hma\":\n        high_ma  HMA(high, high_length)\n        low_ma  HMA(low, low_length)\n    else: # \"sma\"\n        high_ma  SMA(high, high_length)\n        low_ma  SMA(low, low_length)\n\n    # Similar to Supertrend MA selection\n    hilo  Series(npNaN, indexclose.index)\n    for i in range(1, m):\n        if close.iloc[i] > high_ma.iloc[i - 1]:\n            hilo.iloc[i]  low_ma.iloc[i]\n        elif close.iloc[i] < low_ma.iloc[i - 1]:\n            hilo.iloc[i]  high_ma.iloc[i]\n        else:\n            hilo.iloc[i]  hilo.iloc[i - 1]\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    high_length (int): It's period. Default: 13\n    low_length (int): It's period. Default: 21\n    mamode (str): Options: 'sma' or 'ema'. Default: 'sma'\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    adjust (bool): Default: True\n    presma (bool, optional): If True, uses SMA for initial value.\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: HILO (line), HILOl (long), HILOs (short) columns.\n\"\"\"\n\n\n\npandas_ta/overlap/hl2.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef hl2(high, low, offsetNone, **kwargs):\n    \"\"\"Indicator: HL2 \"\"\"\n    # Validate Arguments\n    high  verify_series(high)\n    low  verify_series(low)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    hl2  0.5 * (high + low)\n\n    # Offset\n    if offset ! 0:\n        hl2  hl2.shift(offset)\n\n    # Name & Category\n    hl2.name  \"HL2\"\n    hl2.category  \"overlap\"\n\n    return hl2\n\n\n\npandas_ta/overlap/hlc3.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef hlc3(high, low, close, offsetNone, **kwargs):\n    \"\"\"Indicator: HLC3\"\"\"\n    # Validate Arguments\n    high  verify_series(high)\n    low  verify_series(low)\n    close  verify_series(close)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    hlc3  (high + low + close) / 3.0\n\n    # Offset\n    if offset ! 0:\n        hlc3  hlc3.shift(offset)\n\n    # Name & Category\n    hlc3.name  \"HLC3\"\n    hlc3.category  \"overlap\"\n\n    return hlc3\n\n\n\npandas_ta/overlap/hma.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import sqrt as npSqrt\nfrom .wma import wma\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef hma(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Hull Moving Average (HMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    half_length  int(length / 2)\n    sqrt_length  int(npSqrt(length))\n\n    wmaf  wma(closeclose, lengthhalf_length)\n    wmas  wma(closeclose, lengthlength)\n    hma  wma(close2 * wmaf - wmas, lengthsqrt_length)\n\n    # Offset\n    if offset ! 0:\n        hma  hma.shift(offset)\n\n    # Name & Category\n    hma.name  f\"HMA_{length}\"\n    hma.category  \"overlap\"\n\n    return hma\n\n\nhma.__doc__  \\\n\"\"\"Hull Moving Average (HMA)\n\nThe Hull Exponential Moving Average attempts to reduce or remove lag in moving\naverages.\n\nSources:\n    https://alanhull.com/hull-moving-average\n\nCalculation:\n    Default Inputs:\n        length10\n    WMA  Weighted Moving Average\n    half_length  int(0.5 * length)\n    sqrt_length  int(sqrt(length))\n\n    wmaf  WMA(close, half_length)\n    wmas  WMA(close, length)\n    HMA  WMA(2 * wmaf - wmas, sqrt_length)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/hwma.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import Series\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef hwma(close, naNone, nbNone, ncNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Holt-Winter Moving Average\"\"\"\n    # Validate Arguments\n    na  float(na) if na and na > 0 and na < 1 else 0.2\n    nb  float(nb) if nb and nb > 0 and nb < 1 else 0.1\n    nc  float(nc) if nc and nc > 0 and nc < 1 else 0.1\n    close  verify_series(close)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    last_a  last_v  0\n    last_f  close.iloc[0]\n\n    result  []\n    m  close.size\n    for i in range(m):\n        F  (1.0 - na) * (last_f + last_v + 0.5 * last_a) + na * close.iloc[i]\n        V  (1.0 - nb) * (last_v + last_a) + nb * (F - last_f)\n        A  (1.0 - nc) * last_a + nc * (V - last_v)\n        result.append((F + V + 0.5 * A))\n        last_a, last_f, last_v  A, F, V # update values\n\n    hwma  Series(result, indexclose.index)\n\n    # Offset\n    if offset ! 0:\n        hwma  hwma.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        hwma.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        hwma.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name & Category\n    suffix  f\"{na}_{nb}_{nc}\"\n    hwma.name  f\"HWMA_{suffix}\"\n    hwma.category  \"overlap\"\n\n    return hwma\n\n\n\nhwma.__doc__  \\\n\"\"\"HWMA (Holt-Winter Moving Average)\n\nIndicator HWMA (Holt-Winter Moving Average) is a three-parameter moving average\nby the Holt-Winter method; the three parameters should be selected to obtain a\nforecast.\n\nThis version has been implemented for Pandas TA by rengel8 based\non a publication for MetaTrader 5.\n\nSources:\n    https://www.mql5.com/en/code/20856\n\nCalculation:\n    HWMA[i]  F[i] + V[i] + 0.5 * A[i]\n    where..\n    F[i]  (1-na) * (F[i-1] + V[i-1] + 0.5 * A[i-1]) + na * Price[i]\n    V[i]  (1-nb) * (V[i-1] + A[i-1]) + nb * (F[i] - F[i-1])\n    A[i]  (1-nc) * A[i-1] + nc * (V[i] - V[i-1])\n\nArgs:\n    close (pd.Series): Series of 'close's\n    na (float): Smoothed series parameter (from 0 to 1). Default: 0.2\n    nb (float): Trend parameter (from 0 to 1). Default: 0.1\n    nc (float): Seasonality parameter (from 0 to 1). Default: 0.1\n    close (pd.Series): Series of 'close's\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: hwma\n\"\"\"\n\n\n\npandas_ta/overlap/ichimoku.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import date_range, DataFrame, RangeIndex, Timedelta\nfrom .midprice import midprice\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef ichimoku(high, low, close, tenkanNone, kijunNone, senkouNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Ichimoku Kinkō Hyō (Ichimoku)\"\"\"\n    tenkan  int(tenkan) if tenkan and tenkan > 0 else 9\n    kijun  int(kijun) if kijun and kijun > 0 else 26\n    senkou  int(senkou) if senkou and senkou > 0 else 52\n    _length  max(tenkan, kijun, senkou)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return None, None\n\n    # Calculate Result\n    tenkan_sen  midprice(highhigh, lowlow, lengthtenkan)\n    kijun_sen  midprice(highhigh, lowlow, lengthkijun)\n    span_a  0.5 * (tenkan_sen + kijun_sen)\n    span_b  midprice(highhigh, lowlow, lengthsenkou)\n\n    # Copy Span A and B values before their shift\n    _span_a  span_a[-kijun:].copy()\n    _span_b  span_b[-kijun:].copy()\n\n    span_a  span_a.shift(kijun)\n    span_b  span_b.shift(kijun)\n    chikou_span  close.shift(-kijun)\n\n    # Offset\n    if offset ! 0:\n        tenkan_sen  tenkan_sen.shift(offset)\n        kijun_sen  kijun_sen.shift(offset)\n        span_a  span_a.shift(offset)\n        span_b  span_b.shift(offset)\n        chikou_span  chikou_span.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        span_a.fillna(kwargs[\"fillna\"], inplaceTrue)\n        span_b.fillna(kwargs[\"fillna\"], inplaceTrue)\n        chikou_span.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        span_a.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        span_b.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        chikou_span.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    span_a.name  f\"ISA_{tenkan}\"\n    span_b.name  f\"ISB_{kijun}\"\n    tenkan_sen.name  f\"ITS_{tenkan}\"\n    kijun_sen.name  f\"IKS_{kijun}\"\n    chikou_span.name  f\"ICS_{kijun}\"\n\n    chikou_span.category  kijun_sen.category  tenkan_sen.category  \"trend\"\n    span_b.category  span_a.category  chikou_span\n\n    # Prepare Ichimoku DataFrame\n    data  {\n        span_a.name: span_a,\n        span_b.name: span_b,\n        tenkan_sen.name: tenkan_sen,\n        kijun_sen.name: kijun_sen,\n        chikou_span.name: chikou_span,\n    }\n    ichimokudf  DataFrame(data)\n    ichimokudf.name  f\"ICHIMOKU_{tenkan}_{kijun}_{senkou}\"\n    ichimokudf.category  \"overlap\"\n\n    # Prepare Span DataFrame\n    last  close.index[-1]\n    if close.index.dtype  \"int64\":\n        ext_index  RangeIndex(startlast + 1, stoplast + kijun + 1)\n        spandf  DataFrame(indexext_index, columns[span_a.name, span_b.name])\n        _span_a.index  _span_b.index  ext_index\n    else:\n        df_freq  close.index.value_counts().mode()[0]\n        tdelta  Timedelta(df_freq, unit\"d\")\n        new_dt  date_range(startlast + tdelta, periodskijun, freq\"B\")\n        spandf  DataFrame(indexnew_dt, columns[span_a.name, span_b.name])\n        _span_a.index  _span_b.index  new_dt\n\n    spandf[span_a.name]  _span_a\n    spandf[span_b.name]  _span_b\n    spandf.name  f\"ICHISPAN_{tenkan}_{kijun}\"\n    spandf.category  \"overlap\"\n\n    return ichimokudf, spandf\n\n\nichimoku.__doc__  \\\n\"\"\"Ichimoku Kinkō Hyō (ichimoku)\n\nDeveloped Pre WWII as a forecasting model for financial markets.\n\nSources:\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/ichimoku-ich/\n\nCalculation:\n    Default Inputs:\n        tenkan9, kijun26, senkou52\n    MIDPRICE  Midprice\n    TENKAN_SEN  MIDPRICE(high, low, close, lengthtenkan)\n    KIJUN_SEN  MIDPRICE(high, low, close, lengthkijun)\n    CHIKOU_SPAN  close.shift(-kijun)\n\n    SPAN_A  0.5 * (TENKAN_SEN + KIJUN_SEN)\n    SPAN_A  SPAN_A.shift(kijun)\n\n    SPAN_B  MIDPRICE(high, low, close, lengthsenkou)\n    SPAN_B  SPAN_B.shift(kijun)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    tenkan (int): Tenkan period. Default: 9\n    kijun (int): Kijun period. Default: 26\n    senkou (int): Senkou period. Default: 52\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: Two DataFrames.\n        For the visible period: spanA, spanB, tenkan_sen, kijun_sen,\n            and chikou_span columns\n        For the forward looking period: spanA and spanB columns\n\"\"\"\n\n\n\npandas_ta/overlap/kama.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import NaN as npNaN\nfrom pandas import Series\nfrom pandas_ta.utils import get_drift, get_offset, non_zero_range, verify_series\n\n\ndef kama(close, lengthNone, fastNone, slowNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Kaufman's Adaptive Moving Average (KAMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    fast  int(fast) if fast and fast > 0 else 2\n    slow  int(slow) if slow and slow > 0 else 30\n    close  verify_series(close, max(fast, slow, length))\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    def weight(length: int) -> float:\n        return 2 / (length + 1)\n\n    fr  weight(fast)\n    sr  weight(slow)\n\n    abs_diff  non_zero_range(close, close.shift(length)).abs()\n    peer_diff  non_zero_range(close, close.shift(drift)).abs()\n    peer_diff_sum  peer_diff.rolling(length).sum()\n    er  abs_diff / peer_diff_sum\n    x  er * (fr - sr) + sr\n    sc  x * x\n\n    m  close.size\n    result  [npNaN for _ in range(0, length - 1)] + [0]\n    for i in range(length, m):\n        result.append(sc.iloc[i] * close.iloc[i] + (1 - sc.iloc[i]) * result[i - 1])\n\n    kama  Series(result, indexclose.index)\n\n    # Offset\n    if offset ! 0:\n        kama  kama.shift(offset)\n\n    # Name & Category\n    kama.name  f\"KAMA_{length}_{fast}_{slow}\"\n    kama.category  \"overlap\"\n\n    return kama\n\n\nkama.__doc__  \\\n\"\"\"Kaufman's Adaptive Moving Average (KAMA)\n\nDeveloped by Perry Kaufman, Kaufman's Adaptive Moving Average (KAMA) is a moving average\ndesigned to account for market noise or volatility. KAMA will closely follow prices when\nthe price swings are relatively small and the noise is low. KAMA will adjust when the\nprice swings widen and follow prices from a greater distance. This trend-following indicator\ncan be used to identify the overall trend, time turning points and filter price movements.\n\nSources:\n    https://stockcharts.com/school/doku.php?idchart_school:technical_indicators:kaufman_s_adaptive_moving_average\n    https://www.tradingview.com/script/wZGOIz9r-REPOST-Indicators-3-Different-Adaptive-Moving-Averages/\n\nCalculation:\n    Default Inputs:\n        length10\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    fast (int): Fast MA period. Default: 2\n    slow (int): Slow MA period. Default: 30\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Context: This content resides in the pandas_ta/overlap directory of the pandas_ta root. It contains Python modules for implementing various overlap technical indicators.\\n\\nMain topics and technologies: Technical analysis indicators (e.g., SMA, EMA, LinReg, PWMA, RMA, MCGD, OHLC4, Midpoint), primarily using pandas for time series operations and NumPy for calculations.')\npandas_ta/overlap/linreg.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import arctan as npAtan\nfrom numpy import pi as npPi\nfrom numpy import sqrt as npSqrt\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef linreg(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Linear Regression\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 14\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n    angle  kwargs.pop(\"angle\", False)\n    intercept  kwargs.pop(\"intercept\", False)\n    degrees  kwargs.pop(\"degrees\", False)\n    r  kwargs.pop(\"r\", False)\n    slope  kwargs.pop(\"slope\", False)\n    tsf  kwargs.pop(\"tsf\", False)\n\n    if close is None: return\n\n    # Calculate Result\n    x  range(1, length + 1)  # [1, 2, ..., n] from 1 to n keeps Sum(xy) low\n    x_sum  0.5 * length * (length + 1)\n    x2_sum  x_sum * (2 * length + 1) / 3\n    divisor  length * x2_sum - x_sum * x_sum\n\n    def linear_regression(series):\n        y_sum  series.sum()\n        xy_sum  (x * series).sum()\n\n        m  (length * xy_sum - x_sum * y_sum) / divisor\n        if slope:\n            return m\n        b  (y_sum * x2_sum - x_sum * xy_sum) / divisor\n        if intercept:\n            return b\n\n        if angle:\n            theta  npAtan(m)\n            if degrees:\n                theta * 180 / npPi\n            return theta\n\n        if r:\n            y2_sum  (series * series).sum()\n            rn  length * xy_sum - x_sum * y_sum\n            rd  npSqrt(divisor * (length * y2_sum - y_sum * y_sum))\n            return rn / rd\n\n        return m * length + b if tsf else m * (length - 1) + b\n\n    linreg  close.rolling(length, min_periodslength).apply(linear_regression, rawFalse)\n\n    # Offset\n    if offset ! 0:\n        linreg  linreg.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        linreg.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        linreg.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    linreg.name  f\"LR\"\n    if slope: linreg.name + \"m\"\n    if intercept: linreg.name + \"b\"\n    if angle: linreg.name + \"a\"\n    if r: linreg.name + \"r\"\n    linreg.name + f\"_{length}\"\n    linreg.category  \"overlap\"\n\n    return linreg\n\n\nlinreg.__doc__  \\\n\"\"\"Linear Regression Moving Average (linreg)\n\nLinear Regression Moving Average (LINREG). This is a simplified version of a\nStandard Linear Regression. LINREG is a rolling regression of one variable. A\nStandard Linear Regression is between two or more variables.\n\nSource: TA Lib\n\nCalculation:\n    Default Inputs:\n        length14\n    x  [1, 2, ..., n]\n    x_sum  0.5 * length * (length + 1)\n    x2_sum  length * (length + 1) * (2 * length + 1) / 6\n    divisor  length * x2_sum - x_sum * x_sum\n\n    lr(series):\n        y_sum  series.sum()\n        y2_sum  (series* series).sum()\n        xy_sum  (x * series).sum()\n\n        m  (length * xy_sum - x_sum * y_sum) / divisor\n        b  (y_sum * x2_sum - x_sum * xy_sum) / divisor\n        return m * (length - 1) + b\n\n    linreg  close.rolling(length).apply(lr)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period.  Default: 10\n    offset (int): How many periods to offset the result.  Default: 0\n\nKwargs:\n    angle (bool, optional): If True, returns the angle of the slope in radians.\n        Default: False.\n    degrees (bool, optional): If True, returns the angle of the slope in\n        degrees. Default: False.\n    intercept (bool, optional): If True, returns the angle of the slope in\n        radians. Default: False.\n    r (bool, optional): If True, returns it's correlation 'r'. Default: False.\n    slope (bool, optional): If True, returns the slope. Default: False.\n    tsf (bool, optional): If True, returns the Time Series Forecast value.\n        Default: False.\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/ma.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import Series\n\nfrom .dema import dema\nfrom .ema import ema\nfrom .fwma import fwma\nfrom .hma import hma\nfrom .linreg import linreg\nfrom .midpoint import midpoint\nfrom .pwma import pwma\nfrom .rma import rma\nfrom .sinwma import sinwma\nfrom .sma import sma\nfrom .swma import swma\nfrom .t3 import t3\nfrom .tema import tema\nfrom .trima import trima\nfrom .vidya import vidya\nfrom .wma import wma\nfrom .zlma import zlma\n\n\ndef ma(name:str  None, source:Series  None, **kwargs) -> Series:\n    \"\"\"Simple MA Utility for easier MA selection\n\n    Available MAs:\n        dema, ema, fwma, hma, linreg, midpoint, pwma, rma,\n        sinwma, sma, swma, t3, tema, trima, vidya, wma, zlma\n\n    Examples:\n        ema8  ta.ma(\"ema\", df.close, length8)\n        sma50  ta.ma(\"sma\", df.close, length50)\n        pwma10  ta.ma(\"pwma\", df.close, length10, ascFalse)\n\n    Args:\n        name (str): One of the Available MAs. Default: \"ema\"\n        source (pd.Series): The 'source' Series.\n\n    Kwargs:\n        Any additional kwargs the MA may require.\n\n    Returns:\n        pd.Series: New feature generated.\n    \"\"\"\n\n    _mas  [\n        \"dema\", \"ema\", \"fwma\", \"hma\", \"linreg\", \"midpoint\", \"pwma\", \"rma\",\n        \"sinwma\", \"sma\", \"swma\", \"t3\", \"tema\", \"trima\", \"vidya\", \"wma\", \"zlma\"\n    ]\n    if name is None and source is None:\n        return _mas\n    elif isinstance(name, str) and name.lower() in _mas:\n        name  name.lower()\n    else: # \"ema\"\n        name  _mas[1]\n\n    if   name  \"dema\": return dema(source, **kwargs)\n    elif name  \"fwma\": return fwma(source, **kwargs)\n    elif name  \"hma\": return hma(source, **kwargs)\n    elif name  \"linreg\": return linreg(source, **kwargs)\n    elif name  \"midpoint\": return midpoint(source, **kwargs)\n    elif name  \"pwma\": return pwma(source, **kwargs)\n    elif name  \"rma\": return rma(source, **kwargs)\n    elif name  \"sinwma\": return sinwma(source, **kwargs)\n    elif name  \"sma\": return sma(source, **kwargs)\n    elif name  \"swma\": return swma(source, **kwargs)\n    elif name  \"t3\": return t3(source, **kwargs)\n    elif name  \"tema\": return tema(source, **kwargs)\n    elif name  \"trima\": return trima(source, **kwargs)\n    elif name  \"vidya\": return vidya(source, **kwargs)\n    elif name  \"wma\": return wma(source, **kwargs)\n    elif name  \"zlma\": return zlma(source, **kwargs)\n    else: return ema(source, **kwargs)\n\n\npandas_ta/overlap/mcgd.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef mcgd(close, lengthNone, offsetNone, cNone, **kwargs):\n    \"\"\"Indicator: McGinley Dynamic Indicator\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 10\n    c  float(c) if c and 0 < c < 1 else 1\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    close  close.copy()\n\n    def mcg_(series):\n        denom  (c * length * (series.iloc[1] / series.iloc[0]) ** 4)\n        series.iloc[1]  (series.iloc[0] + ((series.iloc[1] - series.iloc[0]) / denom))\n        return series.iloc[1]\n\n    mcg_cell  close[0:].rolling(2, min_periods2).apply(mcg_, rawFalse)\n    mcg_ds  close[:1].append(mcg_cell[1:])\n\n    # Offset\n    if offset ! 0:\n        mcg_ds  mcg_ds.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        mcg_ds.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        mcg_ds.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name & Category\n    mcg_ds.name  f\"MCGD_{length}\"\n    mcg_ds.category  \"overlap\"\n\n    return mcg_ds\n\n\nmcgd.__doc__  \\\n\"\"\"McGinley Dynamic Indicator\n\nThe McGinley Dynamic looks like a moving average line, yet it is actually a\nsmoothing mechanism for prices that minimizes price separation, price whipsaws,\nand hugs prices much more closely. Because of the calculation, the Dynamic Line\nspeeds up in down markets as it follows prices yet moves more slowly in up\nmarkets. The indicator was designed by John R. McGinley, a Certified Market\nTechnician and former editor of the Market Technicians Association's Journal\nof Technical Analysis.\n\nSources:\n    https://www.investopedia.com/articles/forex/09/mcginley-dynamic-indicator.asp\n\nCalculation:\n    Default Inputs:\n        length10\n        offset0\n        c1\n\n    def mcg_(series):\n        denom  (constant * length * (series.iloc[1] / series.iloc[0]) ** 4)\n        series.iloc[1]  (series.iloc[0] + ((series.iloc[1] - series.iloc[0]) / denom))\n        return series.iloc[1]\n    mcg_cell  close[0:].rolling(2, min_periods2).apply(mcg_, rawFalse)\n    mcg_ds  close[:1].append(mcg_cell[1:])\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): Indicator's period. Default: 10\n    offset (int): Number of periods to offset the result. Default: 0\n    c (float): Multiplier for the denominator, sometimes set to 0.6. Default: 1\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\npandas_ta/overlap/midpoint.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef midpoint(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Midpoint\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 2\n    min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    close  verify_series(close, max(length, min_periods))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    lowest  close.rolling(length, min_periodsmin_periods).min()\n    highest  close.rolling(length, min_periodsmin_periods).max()\n    midpoint  0.5 * (lowest + highest)\n\n    # Offset\n    if offset ! 0:\n        midpoint  midpoint.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        midpoint.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        midpoint.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    midpoint.name  f\"MIDPOINT_{length}\"\n    midpoint.category  \"overlap\"\n\n    return midpoint\n\n\n\npandas_ta/overlap/midprice.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef midprice(high, low, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Midprice\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 2\n    min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    _length  max(length, min_periods)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    offset  get_offset(offset)\n\n    if high is None or low is None: return\n\n    # Calculate Result\n    lowest_low  low.rolling(length, min_periodsmin_periods).min()\n    highest_high  high.rolling(length, min_periodsmin_periods).max()\n    midprice  0.5 * (lowest_low + highest_high)\n\n    # Offset\n    if offset ! 0:\n        midprice  midprice.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        midprice.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        midprice.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    midprice.name  f\"MIDPRICE_{length}\"\n    midprice.category  \"overlap\"\n\n    return midprice\n\n\n\npandas_ta/overlap/ohlc4.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef ohlc4(open_, high, low, close, offsetNone, **kwargs):\n    \"\"\"Indicator: OHLC4\"\"\"\n    # Validate Arguments\n    open_  verify_series(open_)\n    high  verify_series(high)\n    low  verify_series(low)\n    close  verify_series(close)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    ohlc4  0.25 * (open_ + high + low + close)\n\n    # Offset\n    if offset ! 0:\n        ohlc4  ohlc4.shift(offset)\n\n    # Name & Category\n    ohlc4.name  \"OHLC4\"\n    ohlc4.category  \"overlap\"\n\n    return ohlc4\n\n\n\npandas_ta/overlap/pwma.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, pascals_triangle, verify_series, weights\n\n\ndef pwma(close, lengthNone, ascNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Pascals Weighted Moving Average (PWMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    asc  asc if asc else True\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    triangle  pascals_triangle(nlength - 1, weightedTrue)\n    pwma  close.rolling(length, min_periodslength).apply(weights(triangle), rawTrue)\n\n    # Offset\n    if offset ! 0:\n        pwma  pwma.shift(offset)\n\n    # Name & Category\n    pwma.name  f\"PWMA_{length}\"\n    pwma.category  \"overlap\"\n\n    return pwma\n\n\npwma.__doc__  \\\n\"\"\"Pascal's Weighted Moving Average (PWMA)\n\nPascal's Weighted Moving Average is similar to a symmetric triangular window\nexcept PWMA's weights are based on Pascal's Triangle.\n\nSource: Kevin Johnson\n\nCalculation:\n    Default Inputs:\n        length10\n\n    def weights(w):\n        def _compute(x):\n            return np.dot(w * x)\n        return _compute\n\n    triangle  utils.pascals_triangle(length + 1)\n    PWMA  close.rolling(length)_.apply(weights(triangle), rawTrue)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period.  Default: 10\n    asc (bool): Recent values weigh more. Default: True\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/rma.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef rma(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: wildeR's Moving Average (RMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    alpha  (1.0 / length) if length > 0 else 0.5\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    rma  close.ewm(alphaalpha, min_periodslength).mean()\n\n    # Offset\n    if offset ! 0:\n        rma  rma.shift(offset)\n\n    # Name & Category\n    rma.name  f\"RMA_{length}\"\n    rma.category  \"overlap\"\n\n    return rma\n\n\nrma.__doc__  \\\n\"\"\"wildeR's Moving Average (RMA)\n\nThe WildeR's Moving Average is simply an Exponential Moving Average (EMA) with\na modified alpha  1 / length.\n\nSources:\n    https://tlc.thinkorswim.com/center/reference/Tech-Indicators/studies-library/V-Z/WildersSmoothing\n    https://www.incrediblecharts.com/indicators/wilder_moving_average.php\n\nCalculation:\n    Default Inputs:\n        length10\n    EMA  Exponential Moving Average\n    alpha  1 / length\n    RMA  EMA(close, alphaalpha)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/sinwma.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import pi as npPi\nfrom numpy import sin as npSin\nfrom pandas import Series\nfrom pandas_ta.utils import get_offset, verify_series, weights\n\n\ndef sinwma(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Sine Weighted Moving Average (SINWMA) by Everget of TradingView\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 14\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    sines  Series([npSin((i + 1) * npPi / (length + 1)) for i in range(0, length)])\n    w  sines / sines.sum()\n\n    sinwma  close.rolling(length, min_periodslength).apply(weights(w), rawTrue)\n\n    # Offset\n    if offset ! 0:\n        sinwma  sinwma.shift(offset)\n\n    # Name & Category\n    sinwma.name  f\"SINWMA_{length}\"\n    sinwma.category  \"overlap\"\n\n    return sinwma\n\n\nsinwma.__doc__  \\\n\"\"\"Sine Weighted Moving Average (SWMA)\n\nA weighted average using sine cycles. The middle term(s) of the average have the\nhighest weight(s).\n\nSource:\n    https://www.tradingview.com/script/6MWFvnPO-Sine-Weighted-Moving-Average/\n    Author: Everget (https://www.tradingview.com/u/everget/)\n\nCalculation:\n    Default Inputs:\n        length10\n\n    def weights(w):\n        def _compute(x):\n            return np.dot(w * x)\n        return _compute\n\n    sines  Series([sin((i + 1) * pi / (length + 1)) for i in range(0, length)])\n    w  sines / sines.sum()\n    SINWMA  close.rolling(length, min_periodslength).apply(weights(w), rawTrue)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/sma.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef sma(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Simple Moving Average (SMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    close  verify_series(close, max(length, min_periods))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    sma  close.rolling(length, min_periodsmin_periods).mean()\n\n    # Offset\n    if offset ! 0:\n        sma  sma.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        sma.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        sma.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name & Category\n    sma.name  f\"SMA_{length}\"\n    sma.category  \"overlap\"\n\n    return sma\n\n\nsma.__doc__  \\\n\"\"\"Simple Moving Average (SMA)\n\nThe Simple Moving Average is the classic moving average that is the equally\nweighted average over n periods.\n\nSources:\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/simple-moving-average-sma/\n\nCalculation:\n    Default Inputs:\n        length10\n    SMA  SUM(close, length) / length\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    adjust (bool): Default: True\n    presma (bool, optional): If True, uses SMA for initial value.\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Este conteúdo pertence ao diretório pandas_ta/overlap e contém os arquivos ssf.py, supertrend.py, swma.py, t3.py, tema.py, trima.py, vidya.py e vwap.py. Esses arquivos definem indicadores técnicos financeiros da categoria \"overlap\", como Super Smoother Filter (SSF), Supertrend, Symmetric Weighted Moving Average (SWMA), T3 Moving Average, Triple Exponential Moving Average (TEMA), Triangular Moving Average (TRIMA), Variable Index Dynamic Average (VIDYA) e Volume Weighted Average Price (VWAP). As tecnologias abordadas incluem cálculo de médias móveis, manipulação de séries temporais com Pandas, e uso de funções matemáticas da biblioteca NumPy.')\npandas_ta/overlap/ssf.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import cos as npCos\nfrom numpy import exp as npExp\nfrom numpy import pi as npPi\nfrom numpy import sqrt as npSqrt\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef ssf(close, lengthNone, polesNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Ehler's Super Smoother Filter (SSF)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    poles  int(poles) if poles in [2, 3] else 2\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    m  close.size\n    ssf  close.copy()\n\n    if poles  3:\n        x  npPi / length # x  PI / n\n        a0  npExp(-x) # e^(-x)\n        b0  2 * a0 * npCos(npSqrt(3) * x) # 2e^(-x)*cos(3^(.5) * x)\n        c0  a0 * a0 # e^(-2x)\n\n        c4  c0 * c0 # e^(-4x)\n        c3  -c0 * (1 + b0) # -e^(-2x) * (1 + 2e^(-x)*cos(3^(.5) * x))\n        c2  c0 + b0 # e^(-2x) + 2e^(-x)*cos(3^(.5) * x)\n        c1  1 - c2 - c3 - c4\n\n        for i in range(0, m):\n            ssf.iloc[i]  c1 * close.iloc[i] + c2 * ssf.iloc[i - 1] + c3 * ssf.iloc[i - 2] + c4 * ssf.iloc[i - 3]\n\n    else: # poles  2\n        x  npPi * npSqrt(2) / length # x  PI * 2^(.5) / n\n        a0  npExp(-x) # e^(-x)\n        a1  -a0 * a0 # -e^(-2x)\n        b1  2 * a0 * npCos(x) # 2e^(-x)*cos(x)\n        c1  1 - a1 - b1 # e^(-2x) - 2e^(-x)*cos(x) + 1\n\n        for i in range(0, m):\n            ssf.iloc[i]  c1 * close.iloc[i] + b1 * ssf.iloc[i - 1] + a1 * ssf.iloc[i - 2]\n\n    # Offset\n    if offset ! 0:\n        ssf  ssf.shift(offset)\n\n    # Name & Category\n    ssf.name  f\"SSF_{length}_{poles}\"\n    ssf.category  \"overlap\"\n\n    return ssf\n\n\nssf.__doc__  \\\n\"\"\"Ehler's Super Smoother Filter (SSF) Â© 2013\n\nJohn F. Ehlers's solution to reduce lag and remove aliasing noise with his\nresearch in aerospace analog filter design. This indicator comes with two\nversions determined by the keyword poles. By default, it uses two poles but\nthere is an option for three poles. Since SSF is a (Resursive) Digital Filter,\nthe number of poles determine how many prior recursive SSF bars to include in\nthe design of the filter. So two poles uses two prior SSF bars and three poles\nuses three prior SSF bars for their filter calculations.\n\nSources:\n    http://www.stockspotter.com/files/PredictiveIndicators.pdf\n    https://www.tradingview.com/script/VdJy0yBJ-Ehlers-Super-Smoother-Filter/\n    https://www.mql5.com/en/code/588\n    https://www.mql5.com/en/code/589\n\nCalculation:\n    Default Inputs:\n        length10, poles[2, 3]\n\n    See the source code or Sources listed above.\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    poles (int): The number of poles to use, either 2 or 3. Default: 2\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/supertrend.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import NaN as npNaN\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import hl2\nfrom pandas_ta.volatility import atr\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef supertrend(high, low, close, lengthNone, multiplierNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Supertrend\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 7\n    multiplier  float(multiplier) if multiplier and multiplier > 0 else 3.0\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Results\n    m  close.size\n    dir_, trend  [1] * m, [0] * m\n    long, short  [npNaN] * m, [npNaN] * m\n\n    hl2_  hl2(high, low)\n    matr  multiplier * atr(high, low, close, length)\n    upperband  hl2_ + matr\n    lowerband  hl2_ - matr\n\n    for i in range(1, m):\n        if close.iloc[i] > upperband.iloc[i - 1]:\n            dir_[i]  1\n        elif close.iloc[i] < lowerband.iloc[i - 1]:\n            dir_[i]  -1\n        else:\n            dir_[i]  dir_[i - 1]\n            if dir_[i] > 0 and lowerband.iloc[i] < lowerband.iloc[i - 1]:\n                lowerband.iloc[i]  lowerband.iloc[i - 1]\n            if dir_[i] < 0 and upperband.iloc[i] > upperband.iloc[i - 1]:\n                upperband.iloc[i]  upperband.iloc[i - 1]\n\n        if dir_[i] > 0:\n            trend[i]  long[i]  lowerband.iloc[i]\n        else:\n            trend[i]  short[i]  upperband.iloc[i]\n\n    # Prepare DataFrame to return\n    _props  f\"_{length}_{multiplier}\"\n    df  DataFrame({\n            f\"SUPERT{_props}\": trend,\n            f\"SUPERTd{_props}\": dir_,\n            f\"SUPERTl{_props}\": long,\n            f\"SUPERTs{_props}\": short,\n        }, indexclose.index)\n\n    df.name  f\"SUPERT{_props}\"\n    df.category  \"overlap\"\n\n    # Apply offset if needed\n    if offset ! 0:\n        df  df.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        df.fillna(kwargs[\"fillna\"], inplaceTrue)\n\n    if \"fill_method\" in kwargs:\n        df.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    return df\n\n\nsupertrend.__doc__  \\\n\"\"\"Supertrend (supertrend)\n\nSupertrend is an overlap indicator. It is used to help identify trend\ndirection, setting stop loss, identify support and resistance, and/or\ngenerate buy & sell signals.\n\nSources:\n    http://www.freebsensetips.com/blog/detail/7/What-is-supertrend-indicator-its-calculation\n\nCalculation:\n    Default Inputs:\n        length7, multiplier3.0\n    Default Direction:\n\tSet to +1 or bullish trend at start\n\n    MID  multiplier * ATR\n    LOWERBAND  HL2 - MID\n    UPPERBAND  HL2 + MID\n\n    if UPPERBAND[i] < FINAL_UPPERBAND[i-1] and close[i-1] > FINAL_UPPERBAND[i-1]:\n        FINAL_UPPERBAND[i]  UPPERBAND[i]\n    else:\n        FINAL_UPPERBAND[i]  FINAL_UPPERBAND[i-1])\n\n    if LOWERBAND[i] > FINAL_LOWERBAND[i-1] and close[i-1] < FINAL_LOWERBAND[i-1]:\n        FINAL_LOWERBAND[i]  LOWERBAND[i]\n    else:\n        FINAL_LOWERBAND[i]  FINAL_LOWERBAND[i-1])\n\n    if close[i] < FINAL_UPPERBAND[i]:\n        SUPERTREND[i]  FINAL_UPPERBAND[i]\n    else:\n        SUPERTREND[i]  FINAL_LOWERBAND[i]\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int) : length for ATR calculation. Default: 7\n    multiplier (float): Coefficient for upper and lower band distance to\n        midrange. Default: 3.0\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: SUPERT (trend), SUPERTd (direction), SUPERTl (long), SUPERTs (short) columns.\n\"\"\"\n\n\n\npandas_ta/overlap/swma.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, symmetric_triangle, verify_series, weights\n\n\ndef swma(close, lengthNone, ascNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Symmetric Weighted Moving Average (SWMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    # min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    asc  asc if asc else True\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    triangle  symmetric_triangle(length, weightedTrue)\n    swma  close.rolling(length, min_periodslength).apply(weights(triangle), rawTrue)\n    # swma  close.rolling(length).apply(weights(triangle), rawTrue)\n\n    # Offset\n    if offset ! 0:\n        swma  swma.shift(offset)\n\n    # Name & Category\n    swma.name  f\"SWMA_{length}\"\n    swma.category  \"overlap\"\n\n    return swma\n\n\nswma.__doc__  \\\n\"\"\"Symmetric Weighted Moving Average (SWMA)\n\nSymmetric Weighted Moving Average where weights are based on a symmetric\ntriangle.  For example: n3 -> [1, 2, 1], n4 -> [1, 2, 2, 1], etc...\nThis moving average has variable length in contrast to TradingView's fixed\nlength of 4.\n\nSource:\n    https://www.tradingview.com/study-script-reference/#fun_swma\n\nCalculation:\n    Default Inputs:\n        length10\n\n    def weights(w):\n        def _compute(x):\n            return np.dot(w * x)\n        return _compute\n\n    triangle  utils.symmetric_triangle(length - 1)\n    SWMA  close.rolling(length)_.apply(weights(triangle), rawTrue)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    asc (bool): Recent values weigh more. Default: True\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/t3.py\n\n# -*- coding: utf-8 -*-\nfrom .ema import ema\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef t3(close, lengthNone, aNone, offsetNone, **kwargs):\n    \"\"\"Indicator: T3\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    a  float(a) if a and a > 0 and a < 1 else 0.7\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    c1  -a * a**2\n    c2  3 * a**2 + 3 * a**3\n    c3  -6 * a**2 - 3 * a - 3 * a**3\n    c4  a**3 + 3 * a**2 + 3 * a + 1\n\n    e1  ema(closeclose, lengthlength, **kwargs)\n    e2  ema(closee1, lengthlength, **kwargs)\n    e3  ema(closee2, lengthlength, **kwargs)\n    e4  ema(closee3, lengthlength, **kwargs)\n    e5  ema(closee4, lengthlength, **kwargs)\n    e6  ema(closee5, lengthlength, **kwargs)\n    t3  c1 * e6 + c2 * e5 + c3 * e4 + c4 * e3\n\n    # Offset\n    if offset ! 0:\n        t3  t3.shift(offset)\n\n    # Name & Category\n    t3.name  f\"T3_{length}_{a}\"\n    t3.category  \"overlap\"\n\n    return t3\n\n\nt3.__doc__  \"\"\"Tim Tillson's T3 Moving Average (T3)\n\nTim Tillson's T3 Moving Average is considered a smoother and more responsive\nmoving average relative to other moving averages.\n\nSources:\n    http://www.binarytribune.com/forex-trading-indicators/t3-moving-average-indicator/\n\nCalculation:\n    Default Inputs:\n        length10, a0.7\n    c1  -a^3\n    c2  3a^2 + 3a^3  3a^2 * (1 + a)\n    c3  -6a^2 - 3a - 3a^3\n    c4  a^3 + 3a^2 + 3a + 1\n\n    ema1  EMA(close, length)\n    ema2  EMA(ema1, length)\n    ema3  EMA(ema2, length)\n    ema4  EMA(ema3, length)\n    ema5  EMA(ema4, length)\n    ema6  EMA(ema5, length)\n    T3  c1 * ema6 + c2 * ema5 + c3 * ema4 + c4 * ema3\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    a (float): 0 < a < 1. Default: 0.7\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    adjust (bool): Default: True\n    presma (bool, optional): If True, uses SMA for initial value.\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/tema.py\n\n# -*- coding: utf-8 -*-\nfrom .ema import ema\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef tema(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Triple Exponential Moving Average (TEMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    ema1  ema(closeclose, lengthlength, **kwargs)\n    ema2  ema(closeema1, lengthlength, **kwargs)\n    ema3  ema(closeema2, lengthlength, **kwargs)\n    tema  3 * (ema1 - ema2) + ema3\n\n    # Offset\n    if offset ! 0:\n        tema  tema.shift(offset)\n\n    # Name & Category\n    tema.name  f\"TEMA_{length}\"\n    tema.category  \"overlap\"\n\n    return tema\n\n\ntema.__doc__  \\\n\"\"\"Triple Exponential Moving Average (TEMA)\n\nA less laggy Exponential Moving Average.\n\nSources:\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/triple-exponential-moving-average-tema/\n\nCalculation:\n    Default Inputs:\n        length10\n    EMA  Exponential Moving Average\n    ema1  EMA(close, length)\n    ema2  EMA(ema1, length)\n    ema3  EMA(ema2, length)\n    TEMA  3 * (ema1 - ema2) + ema3\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    adjust (bool): Default: True\n    presma (bool, optional): If True, uses SMA for initial value.\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/trima.py\n\n# -*- coding: utf-8 -*-\nfrom .sma import sma\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef trima(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Triangular Moving Average (TRIMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    half_length  round(0.5 * (length + 1))\n    sma1  sma(close, lengthhalf_length)\n    trima  sma(sma1, lengthhalf_length)\n\n    # Offset\n    if offset ! 0:\n        trima  trima.shift(offset)\n\n    # Name & Category\n    trima.name  f\"TRIMA_{length}\"\n    trima.category  \"overlap\"\n\n    return trima\n\n\ntrima.__doc__  \\\n\"\"\"Triangular Moving Average (TRIMA)\n\nA weighted moving average where the shape of the weights are triangular and the\ngreatest weight is in the middle of the period.\n\nSources:\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/triangular-moving-average-trima/\n    tma  sma(sma(src, ceil(length / 2)), floor(length / 2) + 1)  # Tradingview\n    trima  sma(sma(x, n), n)  # Tradingview\n\nCalculation:\n    Default Inputs:\n        length10\n    SMA  Simple Moving Average\n    half_length  round(0.5 * (length + 1))\n    SMA1  SMA(close, half_length)\n    TRIMA  SMA(SMA1, half_length)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    adjust (bool): Default: True\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/vidya.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import nan as npNaN\nfrom pandas import Series\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef vidya(close, lengthNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Variable Index Dynamic Average (VIDYA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 14\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    def _cmo(source: Series, n:int , d: int):\n        \"\"\"Chande Momentum Oscillator (CMO) Patch\n        For some reason: from pandas_ta.momentum import cmo causes\n        pandas_ta.momentum.coppock to not be able to import it's\n        wma like from pandas_ta.overlap import wma?\n        Weird Circular TypeError!?!\n        \"\"\"\n        mom  source.diff(d)\n        positive  mom.copy().clip(lower0)\n        negative  mom.copy().clip(upper0).abs()\n        pos_sum  positive.rolling(n).sum()\n        neg_sum  negative.rolling(n).sum()\n        return (pos_sum - neg_sum) / (pos_sum + neg_sum)\n\n    # Calculate Result\n    m  close.size\n    alpha  2 / (length + 1)\n    abs_cmo  _cmo(close, length, drift).abs()\n    vidya  Series(0, indexclose.index)\n    for i in range(length, m):\n        vidya.iloc[i]  alpha * abs_cmo.iloc[i] * close.iloc[i] + vidya.iloc[i - 1] * (1 - alpha * abs_cmo.iloc[i])\n    vidya.replace({0: npNaN}, inplaceTrue)\n\n    # Offset\n    if offset ! 0:\n        vidya  vidya.shift(offset)\n\n    # Name & Category\n    vidya.name  f\"VIDYA_{length}\"\n    vidya.category  \"overlap\"\n\n    return vidya\n\n\nvidya.__doc__  \\\n\"\"\"Variable Index Dynamic Average (VIDYA)\n\nVariable Index Dynamic Average (VIDYA) was developed by Tushar Chande. It is\nsimilar to an Exponential Moving Average but it has a dynamically adjusted\nlookback period dependent on relative price volatility as measured by Chande\nMomentum Oscillator (CMO). When volatility is high, VIDYA reacts faster to\nprice changes. It is often used as moving average or trend identifier.\n\nSources:\n    https://www.tradingview.com/script/hdrf0fXV-Variable-Index-Dynamic-Average-VIDYA/\n    https://www.perfecttrendsystem.com/blog_mt4_2/en/vidya-indicator-for-mt4\n\nCalculation:\n    Default Inputs:\n        length10, adjustFalse, smaTrue\n    if sma:\n        sma_nth  close[0:length].sum() / length\n        close[:length - 1]  np.NaN\n        close.iloc[length - 1]  sma_nth\n    EMA  close.ewm(spanlength, adjustadjust).mean()\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 14\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    adjust (bool, optional): Use adjust option for EMA calculation. Default: False\n    sma (bool, optional): If True, uses SMA for initial value for EMA calculation. Default: True\n    talib (bool): If True, uses TA-Libs implementation for CMO. Otherwise uses EMA version. Default: True\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/vwap.py\n\n# -*- coding: utf-8 -*-\nfrom .hlc3 import hlc3\nfrom pandas_ta.utils import get_offset, is_datetime_ordered, verify_series\n\ndef vwap(high, low, close, volume, anchorNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Volume Weighted Average Price (VWAP)\"\"\"\n    # Validate Arguments\n    high  verify_series(high)\n    low  verify_series(low)\n    close  verify_series(close)\n    volume  verify_series(volume)\n    anchor  anchor.upper() if anchor and isinstance(anchor, str) and len(anchor) > 1 else \"D\"\n    offset  get_offset(offset)\n\n    typical_price  hlc3(highhigh, lowlow, closeclose)\n    if not is_datetime_ordered(volume):\n        print(f\"[!] VWAP volume series is not datetime ordered. Results may not be as expected.\")\n    if not is_datetime_ordered(typical_price):\n        print(f\"[!] VWAP price series is not datetime ordered. Results may not be as expected.\")\n\n    # Calculate Result\n    wp  typical_price * volume\n    vwap   wp.groupby(wp.index.to_period(anchor)).cumsum()\n    vwap / volume.groupby(volume.index.to_period(anchor)).cumsum()\n\n    # Offset\n    if offset ! 0:\n        vwap  vwap.shift(offset)\n\n    # Name & Category\n    vwap.name  f\"VWAP_{anchor}\"\n    vwap.category  \"overlap\"\n\n    return vwap\n\n\nvwap.__doc__  \\\n\"\"\"Volume Weighted Average Price (VWAP)\n\nThe Volume Weighted Average Price that measures the average typical price\nby volume.  It is typically used with intraday charts to identify general\ndirection.\n\nSources:\n    https://www.tradingview.com/wiki/Volume_Weighted_Average_Price_(VWAP)\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/volume-weighted-average-price-vwap/\n    https://stockcharts.com/school/doku.php?idchart_school:technical_indicators:vwap_intraday\n\nCalculation:\n    tp  typical_price  hlc3(high, low, close)\n    tpv  tp * volume\n    VWAP  tpv.cumsum() / volume.cumsum()\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    anchor (str): How to anchor VWAP. Depending on the index values, it will\n        implement various Timeseries Offset Aliases as listed here:\n        https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases\n        Default: \"D\".\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Este conteúdo refere-se à pasta pandas_ta, contendo arquivos dos submódulos overlap, performance e statistics. Eles implementam indicadores técnicos como VWMA, ZLMA, WMA, WCP, drawdown, retornos (logarítmico, percentual e por tendência) e medidas estatísticas (entropia, curtose, MAD). As tecnologias usadas incluem pandas, numpy e funções customizadas para validação e offset.')\npandas_ta/overlap/vwma.py\n\n# -*- coding: utf-8 -*-\nfrom .sma import sma\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef vwma(close, volume, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Volume Weighted Moving Average (VWMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    close  verify_series(close, length)\n    volume  verify_series(volume, length)\n    offset  get_offset(offset)\n\n    if close is None or volume is None: return\n\n    # Calculate Result\n    pv  close * volume\n    vwma  sma(closepv, lengthlength) / sma(closevolume, lengthlength)\n\n    # Offset\n    if offset ! 0:\n        vwma  vwma.shift(offset)\n\n    # Name & Category\n    vwma.name  f\"VWMA_{length}\"\n    vwma.category  \"overlap\"\n\n    return vwma\n\n\nvwma.__doc__  \\\n\"\"\"Volume Weighted Moving Average (VWMA)\n\nVolume Weighted Moving Average.\n\nSources:\n    https://www.motivewave.com/studies/volume_weighted_moving_average.htm\n\nCalculation:\n    Default Inputs:\n        length10\n    SMA  Simple Moving Average\n    pv  close * volume\n    VWMA  SMA(pv, length) / SMA(volume, length)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    length (int): It's period. Default: 10\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/wcp.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef wcp(high, low, close, offsetNone, **kwargs):\n    \"\"\"Indicator: Weighted Closing Price (WCP)\"\"\"\n    # Validate Arguments\n    high  verify_series(high)\n    low  verify_series(low)\n    close  verify_series(close)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    wcp  (high + low + 2 * close) / 4\n\n    # Offset\n    if offset ! 0:\n        wcp  wcp.shift(offset)\n\n    # Name & Category\n    wcp.name  \"WCP\"\n    wcp.category  \"overlap\"\n\n    return wcp\n\n\nwcp.__doc__  \\\n\"\"\"Weighted Closing Price (WCP)\n\nWeighted Closing Price is the weighted price given: high, low\nand double the close.\n\nSources:\n    https://www.fmlabs.com/reference/default.htm?urlWeightedCloses.htm\n\nCalculation:\n    WCP  (2 * close + high + low) / 4\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/wma.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import arange as npArange\nfrom numpy import dot as npDot\nfrom pandas import Series\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef wma(close, lengthNone, ascNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Weighted Moving Average (WMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    asc  asc if asc else True\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    total_weight  0.5 * length * (length + 1)\n    weights_  Series(npArange(1, length + 1))\n    weights  weights_ if asc else weights_[::-1]\n\n    def linear(w):\n        def _compute(x):\n            return npDot(x, w) / total_weight\n        return _compute\n\n    close_  close.rolling(length, min_periodslength)\n    wma  close_.apply(linear(weights), rawTrue)\n\n    # Offset\n    if offset ! 0:\n        wma  wma.shift(offset)\n\n    # Name & Category\n    wma.name  f\"WMA_{length}\"\n    wma.category  \"overlap\"\n\n    return wma\n\n\nwma.__doc__  \\\n\"\"\"Weighted Moving Average (WMA)\n\nThe Weighted Moving Average where the weights are linearly increasing and\nthe most recent data has the heaviest weight.\n\nSources:\n    https://en.wikipedia.org/wiki/Moving_average#Weighted_moving_average\n\nCalculation:\n    Default Inputs:\n        length10, ascTrue\n    total_weight  0.5 * length * (length + 1)\n    weights_  [1, 2, ..., length + 1]  # Ascending\n    weights  weights if asc else weights[::-1]\n\n    def linear_weights(w):\n        def _compute(x):\n            return (w * x).sum() / total_weight\n        return _compute\n\n    WMA  close.rolling(length)_.apply(linear_weights(weights), rawTrue)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    asc (bool): Recent values weigh more. Default: True\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/overlap/zlma.py\n\n# -*- coding: utf-8 -*-\nfrom . import (\n    dema, ema, hma, linreg, rma, sma, swma, t3, tema, trima, vidya, wma\n)\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef zlma(close, lengthNone, mamodeNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Zero Lag Moving Average (ZLMA)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    mamode  mamode.lower() if isinstance(mamode, str) else \"ema\"\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    lag  int(0.5 * (length - 1))\n    close_  2 * close - close.shift(lag)\n    if   mamode  \"dema\":   zlma  dema(close_, lengthlength, **kwargs)\n    elif mamode  \"hma\":    zlma  hma(close_, lengthlength, **kwargs)\n    elif mamode  \"linreg\": zlma  linreg(close_, lengthlength, **kwargs)\n    elif mamode  \"rma\":    zlma  rma(close_, lengthlength, **kwargs)\n    elif mamode  \"sma\":    zlma  sma(close_, lengthlength, **kwargs)\n    elif mamode  \"swma\":   zlma  swma(close_, lengthlength, **kwargs)\n    elif mamode  \"t3\":     zlma  t3(close_, lengthlength, **kwargs)\n    elif mamode  \"tema\":   zlma  tema(close_, lengthlength, **kwargs)\n    elif mamode  \"trima\":  zlma  trima(close_, lengthlength, **kwargs)\n    elif mamode  \"vidya\":  zlma  vidya(close_, lengthlength, **kwargs)\n    elif mamode  \"wma\":    zlma  wma(close_, lengthlength, **kwargs)\n    else:                    zlma  ema(close_, lengthlength, **kwargs) # \"ema\"\n\n    # Offset\n    if offset ! 0:\n        zlma  zlma.shift(offset)\n\n    # Name & Category\n    zlma.name  f\"ZL_{zlma.name}\"\n    zlma.category  \"overlap\"\n\n    return zlma\n\n\nzlma.__doc__  \\\n\"\"\"Zero Lag Moving Average (ZLMA)\n\nThe Zero Lag Moving Average attempts to eliminate the lag associated\nwith moving averages.  This is an adaption created by John Ehler and Ric Way.\n\nSources:\n    https://en.wikipedia.org/wiki/Zero_lag_exponential_moving_average\n\nCalculation:\n    Default Inputs:\n        length10, mamodeEMA\n    EMA  Exponential Moving Average\n    lag  int(0.5 * (length - 1))\n\n    SOURCE  2 * close - close.shift(lag)\n    ZLMA  MA(kindmamode, SOURCE, length)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    mamode (str): Options: 'ema', 'hma', 'sma', 'wma'. Default: 'ema'\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/performance/__init__.py\n\n# -*- coding: utf-8 -*-\nfrom .drawdown import drawdown\nfrom .log_return import log_return\nfrom .percent_return import percent_return\nfrom .trend_return import trend_return\n\n\n\npandas_ta/performance/drawdown.py\n\n# -*- coding: utf-8 -*-\nfrom sys import float_info as sflt\n\nfrom numpy import log as nplog\nfrom numpy import seterr\nfrom pandas import DataFrame\n\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef drawdown(close, offsetNone, **kwargs) -> DataFrame:\n    \"\"\"Indicator: Drawdown (DD)\"\"\"\n    # Validate Arguments\n    close  verify_series(close)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    max_close  close.cummax()\n    dd  max_close - close\n    dd_pct  1 - (close / max_close)\n\n    _np_err  seterr()\n    seterr(divide\"ignore\", invalid\"ignore\")\n    dd_log  nplog(max_close) - nplog(close)\n    seterr(divide_np_err[\"divide\"], invalid_np_err[\"invalid\"])\n\n    # Offset\n    if offset ! 0:\n        dd  dd.shift(offset)\n        dd_pct  dd_pct.shift(offset)\n        dd_log  dd_log.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        dd.fillna(kwargs[\"fillna\"], inplaceTrue)\n        dd_pct.fillna(kwargs[\"fillna\"], inplaceTrue)\n        dd_log.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        dd.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        dd_pct.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        dd_log.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    dd.name  \"DD\"\n    dd_pct.name  f\"{dd.name}_PCT\"\n    dd_log.name  f\"{dd.name}_LOG\"\n    dd.category  dd_pct.category  dd_log.category  \"performance\"\n\n    # Prepare DataFrame to return\n    data  {dd.name: dd, dd_pct.name: dd_pct, dd_log.name: dd_log}\n    df  DataFrame(data)\n    df.name  dd.name\n    df.category  dd.category\n\n    return df\n\n\n\ndrawdown.__doc__  \\\n\"\"\"Drawdown (DD)\n\nDrawdown is a peak-to-trough decline during a specific period for an investment,\ntrading account, or fund. It is usually quoted as the percentage between the\npeak and the subsequent trough.\n\nSources:\n    https://www.investopedia.com/terms/d/drawdown.asp\n\nCalculation:\n    PEAKDD  close.cummax()\n    DD  PEAKDD - close\n    DD%  1 - (close / PEAKDD)\n    DDlog  log(PEAKDD / close)\n\nArgs:\n    close (pd.Series): Series of 'close's.\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: drawdown, drawdown percent, drawdown log columns\n\"\"\"\n\n\n\npandas_ta/performance/log_return.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import log as nplog\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef log_return(close, lengthNone, cumulativeFalse, offsetNone, **kwargs):\n    \"\"\"Indicator: Log Return\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 1\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    log_return  nplog(close).diff(periodslength)\n\n    if cumulative:\n        log_return  log_return.cumsum()\n\n    # Offset\n    if offset ! 0:\n        log_return  log_return.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        log_return.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        log_return.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name & Category\n    log_return.name  f\"{'CUM' if cumulative else ''}LOGRET_{length}\"\n    log_return.category  \"performance\"\n\n    return log_return\n\n\nlog_return.__doc__  \\\n\"\"\"Log Return\n\nCalculates the logarithmic return of a Series.\nSee also: help(df.ta.log_return) for additional **kwargs a valid 'df'.\n\nSources:\n    https://stackoverflow.com/questions/31287552/logarithmic-returns-in-pandas-dataframe\n\nCalculation:\n    Default Inputs:\n        length1, cumulativeFalse\n    LOGRET  log( close.diff(periodslength) )\n    CUMLOGRET  LOGRET.cumsum() if cumulative\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 20\n    cumulative (bool): If True, returns the cumulative returns. Default: False\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/performance/percent_return.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef percent_return(close, lengthNone, cumulativeFalse, offsetNone, **kwargs):\n    \"\"\"Indicator: Percent Return\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 1\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    pct_return  close.pct_change(length)\n\n    if cumulative:\n        pct_return  pct_return.cumsum()\n\n    # Offset\n    if offset ! 0:\n        pct_return  pct_return.shift(offset)\n\n    # Name & Category\n    pct_return.name  f\"{'CUM' if cumulative else ''}PCTRET_{length}\"\n    pct_return.category  \"performance\"\n\n    return pct_return\n\n\npercent_return.__doc__  \\\n\"\"\"Percent Return\n\nCalculates the percent return of a Series.\nSee also: help(df.ta.percent_return) for additional **kwargs a valid 'df'.\n\nSources:\n    https://stackoverflow.com/questions/31287552/logarithmic-returns-in-pandas-dataframe\n\nCalculation:\n    Default Inputs:\n        length1, cumulativeFalse\n    PCTRET  close.pct_change(length)\n    CUMPCTRET  PCTRET.cumsum() if cumulative\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 20\n    cumulative (bool): If True, returns the cumulative returns. Default: False\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/performance/trend_return.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom .log_return import log_return\nfrom .percent_return import percent_return\nfrom pandas_ta.utils import get_offset, verify_series, zero\n\n\ndef trend_return(close, trend, logTrue, asboolNone, trend_reset0, trade_offsetNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Trend Return\"\"\"\n    # Validate Arguments\n    close  verify_series(close)\n    trend  verify_series(trend)\n    asbool  bool(asbool) if isinstance(asbool, bool) else False\n    log  bool(log) if isinstance(log, bool) else True\n    trend_reset  int(trend_reset) if trend_reset and isinstance(trend_reset, int) else 0\n    if trade_offset !0:\n        trade_offset  int(trade_offset) if trade_offset and isinstance(trade_offset, int) else -1\n    offset  get_offset(offset)\n\n    # Calculate Result\n    returns  log_return(close) if log else percent_return(close)\n    _return_name  returns.name\n\n    trends  trend.astype(int)\n    active_returns  (trends * returns).apply(zero)\n\n    tsum  0\n    m  trends.size\n    csum  []\n    for i in range(0, m):\n        if trends[i]  trend_reset:\n            tsum  0\n        else:\n            tsum + active_returns[i]\n        csum.append(tsum)\n\n    trades  trends.diff().shift(trade_offset).fillna(0).astype(int)\n    entries  (trades > 0).astype(int)\n    exits  (trades < 0).abs().astype(int)\n\n    if asbool:\n        trends  trends.astype(bool)\n        entries  entries.astype(bool)\n        exits  exits.astype(bool)\n\n    data  {\n        f\"TR_{_return_name}\": active_returns,\n        f\"TR_CUM{_return_name}\": csum,\n        f\"TR_Trends\": trends,\n        f\"TR_Trades\": trades,\n        f\"TR_Entries\": entries,\n        f\"TR_Exits\": exits,\n    }\n    df  DataFrame(data, indexclose.index)\n\n    # Offset\n    if offset ! 0:\n        df  df.shift(offset)\n\n    # Name & Category\n    df.name  f\"TR{'l' if log else 'p'}\"\n    df.category  \"performance\"\n\n    return df\n\n\ntrend_return.__doc__  \\\n\"\"\"Trend Return\n\nCalculates the Returns and Cumulative Returns of a Trend as defined by a\nsequence of booleans called a 'trend'. One popular example in TA literature is\nto be long when the 'close' > 'moving average'. For example, if the trend is\nlong when close is above sma(close, 50), then set trend close > sma(close, 50).\nTrend Return will calculate the returns and cumulative returns as well as the\nTrends, Trades, Entries and Exits. By default, Trends, Entries and Exits return\nintegers. When 'asboolTrue', Trends, Entries and Exits will return as boolean\nwhich is helpful when combined with the vectorbt backtesting package.\nAdditionally, returns are log returns by default.\n\nExamples:\nta.trend_return(close, trend close > ta.sma(close, 50))\nta.trend_return(close, trend ta.ema(close, 8) > ta.ema(close, 21))\n\nSources: Kevin Johnson\n\nCalculation:\n    Default Inputs:\n        logTrue, asboolFalse, trend_reset0\n\n    sum  0\n    returns  log_return if log else percent_return # These are not cumulative\n    returns  (trend * returns).apply(zero)\n    for i, in range(0, trend.size):\n        if item  trend_reset:\n            sum  0\n        else:\n            return_  returns.iloc[i]\n            if cumulative:\n                sum + return_\n            else:\n                sum  return_\n        trend_return.append(sum)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    trend (pd.Series): Series of 'trend's. The trend can be either a boolean or\n        integer series of '0's and '1's\n    log (bool): Calculate logarithmic returns. Default: True\n    asbool (bool): If True, it converts the Trends, Entries and Exits columns to\n        booleans. When boolean, it is also useful for backtesting with\n        vectorbt's Portfolio.from_signal(close, entries, exits) Default: False\n    trend_reset (value): Value used to identify if a trend has ended. Default: 0\n    trade_offset (value): Value used shift the trade entries/exits. Default: -1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: Returns columns: Returns, Cumulative Returns,\n    Trends (trend: 1, no trend: 0), Trades (Enter: 1, Exit: -1, Otherwise: 0),\n    Entries (entry: 1, nothing: 0), Exits (exit: 1, nothing: 0)\n\"\"\"\n\n\n\npandas_ta/statistics/__init__.py\n\n# -*- coding: utf-8 -*-\nfrom .entropy import entropy\nfrom .kurtosis import kurtosis\nfrom .mad import mad\nfrom .median import median\nfrom .quantile import quantile\nfrom .skew import skew\nfrom .stdev import stdev\nfrom .variance import variance\nfrom .zscore import zscore\n\n\n\npandas_ta/statistics/entropy.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import log as npLog\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef entropy(close, lengthNone, baseNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Entropy (ENTP)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    base  float(base) if base and base > 0 else 2.0\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    p  close / close.rolling(length).sum()\n    entropy  (-p * npLog(p) / npLog(base)).rolling(length).sum()\n\n    # Offset\n    if offset ! 0:\n        entropy  entropy.shift(offset)\n\n    # Name & Category\n    entropy.name  f\"ENTP_{length}\"\n    entropy.category  \"statistics\"\n\n    return entropy\n\n\nentropy.__doc__  \\\n\"\"\"Entropy (ENTP)\n\nIntroduced by Claude Shannon in 1948, entropy measures the unpredictability\nof the data, or equivalently, of its average information. A die has higher\nentropy (p1/6) versus a coin (p1/2).\n\nSources:\n    https://en.wikipedia.org/wiki/Entropy_(information_theory)\n\nCalculation:\n    Default Inputs:\n        length10, base2\n\n    P  close / SUM(close, length)\n    E  SUM(-P * npLog(P) / npLog(base), length)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    base (float): Logarithmic Base. Default: 2\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/statistics/kurtosis.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef kurtosis(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Kurtosis\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 30\n    min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    close  verify_series(close, max(length, min_periods))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    kurtosis  close.rolling(length, min_periodsmin_periods).kurt()\n\n    # Offset\n    if offset ! 0:\n        kurtosis  kurtosis.shift(offset)\n\n    # Name & Category\n    kurtosis.name  f\"KURT_{length}\"\n    kurtosis.category  \"statistics\"\n\n    return kurtosis\n\n\nkurtosis.__doc__  \\\n\"\"\"Rolling Kurtosis\n\nSources:\n\nCalculation:\n    Default Inputs:\n        length30\n    KURTOSIS  close.rolling(length).kurt()\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 30\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/statistics/mad.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import fabs as npfabs\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef mad(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Mean Absolute Deviation\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 30\n    min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    close  verify_series(close, max(length, min_periods))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    def mad_(series):\n        \"\"\"Mean Absolute Deviation\"\"\"\n        return npfabs(series - series.mean()).mean()\n\n    mad  close.rolling(length, min_periodsmin_periods).apply(mad_, rawTrue)\n\n    # Offset\n    if offset ! 0:\n        mad  mad.shift(offset)\n\n    # Name & Category\n    mad.name  f\"MAD_{length}\"\n    mad.category  \"statistics\"\n\n    return mad\n\n\nmad.__doc__  \\\n\"\"\"Rolling Mean Absolute Deviation\n\nSources:\n\nCalculation:\n    Default Inputs:\n        length30\n    mad  close.rolling(length).mad()\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 30\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Este trecho compreende arquivos dos diretórios pandas_ta/statistics e pandas_ta/trend. Ele define indicadores técnicos estatísticos como mediana, quantil, skew, desvio padrão, variância e z-score, além de indicadores de tendência como ADX, AMAT e Aroon. Usa pandas e numpy para cálculos de janelas móveis e métricas estatísticas sobre séries temporais financeiras.')\npandas_ta/statistics/median.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef median(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Median\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 30\n    min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    close  verify_series(close, max(length, min_periods))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    median  close.rolling(length, min_periodsmin_periods).median()\n\n    # Offset\n    if offset ! 0:\n        median  median.shift(offset)\n\n    # Name & Category\n    median.name  f\"MEDIAN_{length}\"\n    median.category  \"statistics\"\n\n    return median\n\n\nmedian.__doc__  \\\n\"\"\"Rolling Median\n\nRolling Median of over 'n' periods. Sibling of a Simple Moving Average.\n\nSources:\n    https://www.incrediblecharts.com/indicators/median_price.php\n\nCalculation:\n    Default Inputs:\n        length30\n    MEDIAN  close.rolling(length).median()\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 30\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/statistics/quantile.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef quantile(close, lengthNone, qNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Quantile\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 30\n    min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    q  float(q) if q and q > 0 and q < 1 else 0.5\n    close  verify_series(close, max(length, min_periods))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    quantile  close.rolling(length, min_periodsmin_periods).quantile(q)\n\n    # Offset\n    if offset ! 0:\n        quantile  quantile.shift(offset)\n\n    # Name & Category\n    quantile.name  f\"QTL_{length}_{q}\"\n    quantile.category  \"statistics\"\n\n    return quantile\n\n\nquantile.__doc__  \\\n\"\"\"Rolling Quantile\n\nSources:\n\nCalculation:\n    Default Inputs:\n        length30, q0.5\n    QUANTILE  close.rolling(length).quantile(q)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 30\n    q (float): The quantile. Default: 0.5\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/statistics/skew.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef skew(close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Skew\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 30\n    min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    close  verify_series(close, max(length, min_periods))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    skew  close.rolling(length, min_periodsmin_periods).skew()\n\n    # Offset\n    if offset ! 0:\n        skew  skew.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        skew.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        skew.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name & Category\n    skew.name  f\"SKEW_{length}\"\n    skew.category  \"statistics\"\n\n    return skew\n\n\nskew.__doc__  \\\n\"\"\"Rolling Skew\n\nSources:\n\nCalculation:\n    Default Inputs:\n        length30\n    SKEW  close.rolling(length).skew()\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 30\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/statistics/stdev.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import sqrt as npsqrt\nfrom .variance import variance\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef stdev(close, lengthNone, ddof1, offsetNone, **kwargs):\n    \"\"\"Indicator: Standard Deviation\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 30\n    ddof  int(ddof) if ddof > 0 and ddof < length else 1\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    stdev  variance(closeclose, lengthlength, ddofddof).apply(npsqrt)\n\n    # Offset\n    if offset ! 0:\n        stdev  stdev.shift(offset)\n\n    # Name & Category\n    stdev.name  f\"STDEV_{length}\"\n    stdev.category  \"statistics\"\n\n    return stdev\n\n\nstdev.__doc__  \\\n\"\"\"Rolling Standard Deviation\n\nSources:\n\nCalculation:\n    Default Inputs:\n        length30\n    VAR  Variance\n    STDEV  variance(close, length).apply(np.sqrt)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 30\n    ddof (int): Delta Degrees of Freedom.\n                The divisor used in calculations is N - ddof,\n                where N represents the number of elements. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/statistics/variance.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef variance(close, lengthNone, ddofNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Variance\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 1 else 30\n    ddof  int(ddof) if ddof and ddof > 0 and ddof < length else 0\n    min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    close  verify_series(close, max(length, min_periods))\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    variance  close.rolling(length, min_periodsmin_periods).var(ddof)\n\n    # Offset\n    if offset ! 0:\n        variance  variance.shift(offset)\n\n    # Name & Category\n    variance.name  f\"VAR_{length}\"\n    variance.category  \"statistics\"\n\n    return variance\n\n\nvariance.__doc__  \\\n\"\"\"Rolling Variance\n\nSources:\n\nCalculation:\n    Default Inputs:\n        length30\n    VARIANCE  close.rolling(length).var()\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 30\n    ddof (int): Delta Degrees of Freedom.\n                The divisor used in calculations is N - ddof,\n                where N represents the number of elements. Default: 0\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/statistics/zscore.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import sma\nfrom .stdev import stdev\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef zscore(close, lengthNone, stdNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Z Score\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 1 else 30\n    std  float(std) if std and std > 1 else 1\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    std * stdev(closeclose, lengthlength, **kwargs)\n    mean  sma(closeclose, lengthlength, **kwargs)\n    zscore  (close - mean) / std\n\n    # Offset\n    if offset ! 0:\n        zscore  zscore.shift(offset)\n\n    # Name & Category\n    zscore.name  f\"Z_{length}\"\n    zscore.category  \"statistics\"\n\n    return zscore\n\n\nzscore.__doc__  \\\n\"\"\"Rolling Z Score\n\nSources:\n\nCalculation:\n    Default Inputs:\n        length30, std1\n    SMA  Simple Moving Average\n    STDEV  Standard Deviation\n    std  std * STDEV(close, length)\n    mean  SMA(close, length)\n    ZSCORE  (close - mean) / std\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 30\n    std (float): It's period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/trend/__init__.py\n\n# -*- coding: utf-8 -*-\nfrom .adx import adx\nfrom .amat import amat\nfrom .aroon import aroon\nfrom .chop import chop\nfrom .cksp import cksp\nfrom .decay import decay\nfrom .decreasing import decreasing\nfrom .dpo import dpo\nfrom .increasing import increasing\nfrom .long_run import long_run\nfrom .psar import psar\nfrom .qstick import qstick\nfrom .short_run import short_run\nfrom .ttm_trend import ttm_trend\nfrom .vortex import vortex\n\n\n\npandas_ta/trend/adx.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import ma\nfrom pandas_ta.volatility import atr\nfrom pandas_ta.utils import get_drift, get_offset, verify_series, zero\n\n\ndef adx(high, low, close, lengthNone, scalarNone, mamodeNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: ADX\"\"\"\n    # Validate Arguments\n    length  length if length and length > 0 else 14\n    mamode  mamode if isinstance(mamode, str) else \"rma\"\n    scalar  float(scalar) if scalar else 100\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    atr_  atr(highhigh, lowlow, closeclose, lengthlength)\n\n    up  high - high.shift(drift)  # high.diff(drift)\n    dn  low.shift(drift) - low    # low.diff(-drift).shift(drift)\n\n    pos  ((up > dn) & (up > 0)) * up\n    neg  ((dn > up) & (dn > 0)) * dn\n\n    pos  pos.apply(zero)\n    neg  neg.apply(zero)\n\n    k  scalar / atr_\n    dmp  k * ma(mamode, pos, lengthlength)\n    dmn  k * ma(mamode, neg, lengthlength)\n\n    dx  scalar * (dmp - dmn).abs() / (dmp + dmn)\n    adx  ma(mamode, dx, lengthlength)\n\n    # Offset\n    if offset ! 0:\n        dmp  dmp.shift(offset)\n        dmn  dmn.shift(offset)\n        adx  adx.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        adx.fillna(kwargs[\"fillna\"], inplaceTrue)\n        dmp.fillna(kwargs[\"fillna\"], inplaceTrue)\n        dmn.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        adx.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        dmp.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        dmn.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    adx.name  f\"ADX_{length}\"\n    dmp.name  f\"DMP_{length}\"\n    dmn.name  f\"DMN_{length}\"\n\n    adx.category  dmp.category  dmn.category  \"trend\"\n\n    # Prepare DataFrame to return\n    data  {adx.name: adx, dmp.name: dmp, dmn.name: dmn}\n    adxdf  DataFrame(data)\n    adxdf.name  f\"ADX_{length}\"\n    adxdf.category  \"trend\"\n\n    return adxdf\n\n\nadx.__doc__  \\\n\"\"\"Average Directional Movement (ADX)\n\nAverage Directional Movement is meant to quantify trend strength by measuring\nthe amount of movement in a single direction.\n\nSources:\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/average-directional-movement-adx/\n    TA Lib Correlation: >99%\n\nCalculation:\n    DMI ADX TREND 2.0 by @TraderR0BERT, NETWORTHIE.COM\n        //Created by @TraderR0BERT, NETWORTHIE.COM, last updated 01/26/2016\n        //DMI Indicator\n        //Resolution input option for higher/lower time frames\n        study(title\"DMI ADX TREND 2.0\", shorttitle\"ADX TREND 2.0\")\n\n        adxlen  input(14, title\"ADX Smoothing\")\n        dilen  input(14, title\"DI Length\")\n        thold  input(20, title\"Threshold\")\n\n        threshold  thold\n\n        //Script for Indicator\n        dirmov(len) >\n            up  change(high)\n            down  -change(low)\n            truerange  rma(tr, len)\n            plus  fixnan(100 * rma(up > down and up > 0 ? up : 0, len) / truerange)\n            minus  fixnan(100 * rma(down > up and down > 0 ? down : 0, len) / truerange)\n            [plus, minus]\n\n        adx(dilen, adxlen) >\n            [plus, minus]  dirmov(dilen)\n            sum  plus + minus\n            adx  100 * rma(abs(plus - minus) / (sum  0 ? 1 : sum), adxlen)\n            [adx, plus, minus]\n\n        [sig, up, down]  adx(dilen, adxlen)\n        osobinput(40,title\"Exhaustion Level for ADX, default  40\")\n        col  sig > sig[1] ? green : sig < sig[1] ? red : gray\n\n        //Plot Definitions Current Timeframe\n        p1  plot(sig, colorcol, linewidth  3, title\"ADX\")\n        p2  plot(sig, colorcol, stylecircles, linewidth3, title\"ADX\")\n        p3  plot(up, colorblue, linewidth  3, title\"+DI\")\n        p4  plot(up, colorblue, stylecircles, linewidth3, title\"+DI\")\n        p5  plot(down, colorfuchsia, linewidth  3, title\"-DI\")\n        p6  plot(down, colorfuchsia, stylecircles, linewidth3, title\"-DI\")\n        h1  plot(threshold, colorblack, linewidth 3, title\"Threshold\")\n\n        trender  (sig > up or sig > down) ? 1 : 0\n        bgcolor(trender>0?black:gray, transp85)\n\n        //Alert Function for ADX crossing Threshold\n        Up_Cross  crossover(up, threshold)\n        alertcondition(Up_Cross, title\"DMI+ cross\", message\"DMI+ Crossing Threshold\")\n        Down_Cross  crossover(down, threshold)\n        alertcondition(Down_Cross, title\"DMI- cross\", message\"DMI- Crossing Threshold\")\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): It's period.  Default: 14\n    scalar (float): How much to magnify. Default: 100\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: adx, dmp, dmn columns.\n\"\"\"\n\n\n\npandas_ta/trend/amat.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom .long_run import long_run\nfrom .short_run import short_run\nfrom pandas_ta.overlap import ma\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef amat(closeNone, fastNone, slowNone, mamodeNone, lookbackNone, slope_lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Archer Moving Averages Trends (AMAT)\"\"\"\n    # Validate Arguments\n    fast  int(fast) if fast and fast > 0 else 8\n    slow  int(slow) if slow and slow > 0 else 21\n    lookback  int(lookback) if lookback and lookback > 0 else 2\n    mamode  mamode.lower() if isinstance(mamode, str) else \"ema\"\n    close  verify_series(close, max(fast, slow, lookback))\n    offset  get_offset(offset)\n    if \"length\" in kwargs: kwargs.pop(\"length\")\n\n    if close is None: return\n\n    # # Calculate Result\n    fast_ma  ma(mamode, close, lengthfast, **kwargs)\n    slow_ma  ma(mamode, close, lengthslow, **kwargs)\n\n    mas_long  long_run(fast_ma, slow_ma, lengthlookback)\n    mas_short  short_run(fast_ma, slow_ma, lengthlookback)\n\n    # Offset\n    if offset ! 0:\n        mas_long  mas_long.shift(offset)\n        mas_short  mas_short.shift(offset)\n\n    # # Handle fills\n    if \"fillna\" in kwargs:\n        mas_long.fillna(kwargs[\"fillna\"], inplaceTrue)\n        mas_short.fillna(kwargs[\"fillna\"], inplaceTrue)\n\n    if \"fill_method\" in kwargs:\n        mas_long.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        mas_short.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Prepare DataFrame to return\n    amatdf  DataFrame({\n        f\"AMAT{mamode[0]}_{mas_long.name}\": mas_long,\n        f\"AMAT{mamode[0]}_{mas_short.name}\": mas_short\n    })\n\n    # Name and Categorize it\n    amatdf.name  f\"AMAT_{mamode.upper()}_{fast}_{slow}_{lookback}\"\n    amatdf.category  \"trend\"\n\n    return amatdf\n\n\n\npandas_ta/trend/aroon.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.utils import get_offset, verify_series\nfrom pandas_ta.utils import recent_maximum_index, recent_minimum_index\n\n\ndef aroon(high, low, lengthNone, scalarNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Aroon & Aroon Oscillator\"\"\"\n    # Validate Arguments\n    length  length if length and length > 0 else 14\n    scalar  float(scalar) if scalar else 100\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    offset  get_offset(offset)\n\n    if high is None or low is None: return\n\n    # Calculate Result\n    periods_from_hh  high.rolling(length + 1).apply(recent_maximum_index, rawTrue)\n    periods_from_ll  low.rolling(length + 1).apply(recent_minimum_index, rawTrue)\n\n    aroon_up  aroon_down  scalar\n    aroon_up * 1 - (periods_from_hh / length)\n    aroon_down * 1 - (periods_from_ll / length)\n    aroon_osc  aroon_up - aroon_down\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        aroon_up.fillna(kwargs[\"fillna\"], inplaceTrue)\n        aroon_down.fillna(kwargs[\"fillna\"], inplaceTrue)\n        aroon_osc.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        aroon_up.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        aroon_down.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        aroon_osc.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Offset\n    if offset ! 0:\n        aroon_up  aroon_up.shift(offset)\n        aroon_down  aroon_down.shift(offset)\n        aroon_osc  aroon_osc.shift(offset)\n\n    # Name and Categorize it\n    aroon_up.name  f\"AROONU_{length}\"\n    aroon_down.name  f\"AROOND_{length}\"\n    aroon_osc.name  f\"AROONOSC_{length}\"\n\n    aroon_down.category  aroon_up.category  aroon_osc.category  \"trend\"\n\n    # Prepare DataFrame to return\n    data  {\n        aroon_down.name: aroon_down,\n        aroon_up.name: aroon_up,\n        aroon_osc.name: aroon_osc,\n    }\n    aroondf  DataFrame(data)\n    aroondf.name  f\"AROON_{length}\"\n    aroondf.category  aroon_down.category\n\n    return aroondf\n\n\naroon.__doc__  \\\n\"\"\"Aroon & Aroon Oscillator (AROON)\n\nAroon attempts to identify if a security is trending and how strong.\n\nSources:\n    https://www.tradingview.com/wiki/Aroon\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/aroon-ar/\n\nCalculation:\n    Default Inputs:\n        length1, scalar100\n\n    recent_maximum_index(x): return int(np.argmax(x[::-1]))\n    recent_minimum_index(x): return int(np.argmin(x[::-1]))\n\n    periods_from_hh  high.rolling(length + 1).apply(recent_maximum_index, rawTrue)\n    AROON_UP  scalar * (1 - (periods_from_hh / length))\n\n    periods_from_ll  low.rolling(length + 1).apply(recent_minimum_index, rawTrue)\n    AROON_DN  scalar * (1 - (periods_from_ll / length))\n\n    AROON_OSC  AROON_UP - AROON_DN\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 14\n    scalar (float): How much to magnify. Default: 100\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: aroon_up, aroon_down, aroon_osc columns.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Este conteúdo está na subpasta trend de pandas_ta, e implementa indicadores de análise de tendência em séries temporais financeiras. Os arquivos apresentados contêm funções para os seguintes indicadores técnicos:\\n\\n- chop.py: Choppiness Index (CHOP) — mede a tendência vs. lateralização do mercado.\\n- cksp.py: Chande Kroll Stop (CKSP) — stop loss baseado em volatilidade via ATR.\\n- decay.py: Linear ou exponencial Decay — suavização baseada em decaimento.\\n- decreasing.py e increasing.py — identificam períodos de queda ou alta consecutiva.\\n- dpo.py: Detrended Price Oscillator — remove tendência para destacar ciclos.\\n- long_run.py: Define condições de trend de longo prazo baseadas em outros indicadores.\\n- psar.py: Parabolic SAR — sinaliza reversões com base em tendência e aceleração.\\n\\nTecnologias e bibliotecas: pandas, numpy, funções auxiliares internas como verify_series, get_offset e atr. O foco é na detecção de tendências e reversões de preço.')\npandas_ta/trend/chop.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import log10 as npLog10\nfrom pandas_ta.volatility import atr\nfrom pandas_ta.utils import get_offset, get_drift, verify_series\n\n\ndef chop(high, low, close, lengthNone, atr_lengthNone, scalarNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Choppiness Index (CHOP)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 14\n    atr_length  int(atr_length) if atr_length is not None and atr_length > 0 else 1\n    scalar  float(scalar) if scalar else 100\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    diff  high.rolling(length).max() - low.rolling(length).min()\n\n    atr_  atr(highhigh, lowlow, closeclose, lengthatr_length)\n    atr_sum  atr_.rolling(length).sum()\n\n    chop  scalar * (npLog10(atr_sum) - npLog10(diff))\n    chop / npLog10(length)\n\n    # Offset\n    if offset ! 0:\n        chop  chop.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        chop.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        chop.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    chop.name  f\"CHOP_{length}_{atr_length}_{scalar}\"\n    chop.category  \"trend\"\n\n    return chop\n\n\nchop.__doc__  \\\n\"\"\"Choppiness Index (CHOP)\n\nThe Choppiness Index was created by Australian commodity trader\nE.W. Dreiss and is designed to determine if the market is choppy\n(trading sideways) or not choppy (trading within a trend in either\ndirection). Values closer to 100 implies the underlying is choppier\nwhereas values closer to 0 implies the underlying is trending.\n\nSources:\n    https://www.tradingview.com/scripts/choppinessindex/\n    https://www.motivewave.com/studies/choppiness_index.htm\n\nCalculation:\n    Default Inputs:\n        length14, scalar100, drift1\n    HH  high.rolling(length).max()\n    LL  low.rolling(length).min()\n\n    ATR_SUM  SUM(ATR(drift), length)\n    CHOP  scalar * (LOG10(ATR_SUM) - LOG10(HH - LL))\n    CHOP / LOG10(length)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 14\n    atr_length (int): Length for ATR. Default: 1\n    scalar (float): How much to magnify. Default: 100\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/trend/cksp.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.volatility import atr\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef cksp(high, low, close, pNone, xNone, qNone, offsetNone, tvmodeNone, **kwargs):\n    \"\"\"Indicator: Chande Kroll Stop (CKSP)\"\"\"\n    # Validate Arguments\n    # TV defaults(10,1,9), book defaults  (10,3,20)\n    p  int(p) if p and p > 0 else 10\n    x  float(x) if x and x > 0 else 1 if tvmode is True else 3\n    q  int(q) if q and q > 0 else 9 if tvmode is True else 20\n    _length  max(p, q, x)\n\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    if high is None or low is None or close is None: return\n\n    offset  get_offset(offset)\n    tvmode  tvmode if isinstance(tvmode, bool) else True\n    mamode  \"rma\" if tvmode is True else \"sma\"\n\n    # Calculate Result\n    atr_  atr(highhigh, lowlow, closeclose, lengthp, mamode  mamode)\n\n    long_stop_  high.rolling(p).max() - x * atr_\n    long_stop  long_stop_.rolling(q).max()\n\n    short_stop_  low.rolling(p).min() + x * atr_\n    short_stop  short_stop_.rolling(q).min()\n\n    # Offset\n    if offset ! 0:\n        long_stop  long_stop.shift(offset)\n        short_stop  short_stop.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        long_stop.fillna(kwargs[\"fillna\"], inplaceTrue)\n        short_stop.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        long_stop.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        short_stop.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _props  f\"_{p}_{x}_{q}\"\n    long_stop.name  f\"CKSPl{_props}\"\n    short_stop.name  f\"CKSPs{_props}\"\n    long_stop.category  short_stop.category  \"trend\"\n\n    # Prepare DataFrame to return\n    ckspdf  DataFrame({long_stop.name: long_stop, short_stop.name: short_stop})\n    ckspdf.name  f\"CKSP{_props}\"\n    ckspdf.category  long_stop.category\n\n    return ckspdf\n\n\ncksp.__doc__  \\\n\"\"\"Chande Kroll Stop (CKSP)\n\nThe Tushar Chande and Stanley Kroll in their book\n“The New Technical Trader”. It is a trend-following indicator,\nidentifying your stop by calculating the average true range of\nthe recent market volatility. The indicator defaults to the implementation\nfound on tradingview but it provides the original book implementation as well,\nwhich differs by the default periods and moving average mode. While the trading\nview implementation uses the Welles Wilder moving average, the book uses a\nsimple moving average.\n\nSources:\n    https://www.multicharts.com/discussion/viewtopic.php?t48914\n    \"The New Technical Trader\", Wikey 1st ed. ISBN 9780471597803, page 95\n\nCalculation:\n    Default Inputs:\n        p10, x1, q9, tvmodeTrue\n    ATR  Average True Range\n\n    LS0  high.rolling(p).max() - x * ATR(lengthp)\n    LS  LS0.rolling(q).max()\n\n    SS0  high.rolling(p).min() + x * ATR(lengthp)\n    SS  SS0.rolling(q).min()\n\nArgs:\n    close (pd.Series): Series of 'close's\n    p (int): ATR and first stop period. Default: 10 in both modes\n    x (float): ATR scalar. Default: 1 in TV mode, 3 otherwise\n    q (int): Second stop period. Default: 9 in TV mode, 20 otherwise\n    offset (int): How many periods to offset the result. Default: 0\n    tvmode (bool): Trading View or book implementation mode. Default: True\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: long and short columns.\n\"\"\"\n\n\n\npandas_ta/trend/decay.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import exp as npExp\nfrom pandas import DataFrame\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef decay(close, kindNone, lengthNone, modeNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Decay\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 5\n    mode  mode.lower() if isinstance(mode, str) else \"linear\"\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    _mode  \"L\"\n    if mode  \"exp\" or kind  \"exponential\":\n        _mode  \"EXP\"\n        diff  close.shift(1) - npExp(-length)\n    else:  # \"linear\"\n        diff  close.shift(1) - (1 / length)\n    diff[0]  close[0]\n    tdf  DataFrame({\"close\": close, \"diff\": diff, \"0\": 0})\n    ld  tdf.max(axis1)\n\n    # Offset\n    if offset ! 0:\n        ld  ld.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        ld.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        ld.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    ld.name  f\"{_mode}DECAY_{length}\"\n    ld.category  \"trend\"\n\n    return ld\n\n\ndecay.__doc__  \\\n\"\"\"Decay\n\nCreates a decay moving forward from prior signals like crosses. The default is\n\"linear\". Exponential is optional as \"exponential\" or \"exp\".\n\nSources:\n    https://tulipindicators.org/decay\n\nCalculation:\n    Default Inputs:\n        length5, modeNone\n\n    if mode  \"exponential\" or mode  \"exp\":\n        max(close, close[-1] - exp(-length), 0)\n    else:\n        max(close, close[-1] - (1 / length), 0)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 1\n    mamode (str): Option \"exponential\" (\"exp\"). Default: 'linear' or None\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/trend/decreasing.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef decreasing(close, lengthNone, strictNone, asintNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Decreasing\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 1\n    strict  strict if isinstance(strict, bool) else False\n    asint  asint if isinstance(asint, bool) else True\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    def stricly_decreasing(series, n):\n        return all([i > j for i,j in zip(series[-n:], series[1:])])\n\n    # Calculate Result\n    if strict:\n        # Returns value as float64? Have to cast to bool\n        decreasing  close.rolling(length, min_periodslength) \\\n            .apply(stricly_decreasing, args(length,), rawFalse)\n        decreasing.fillna(0, inplaceTrue)\n        decreasing  decreasing.astype(bool)\n    else:\n        decreasing  close.diff(length) < 0\n\n    if asint:\n        decreasing  decreasing.astype(int)\n\n    # Offset\n    if offset ! 0:\n        decreasing  decreasing.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        decreasing.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        decreasing.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    decreasing.name  f\"{'S' if strict else ''}DEC_{length}\"\n    decreasing.category  \"trend\"\n\n    return decreasing\n\n\ndecreasing.__doc__  \\\n\"\"\"Decreasing\n\nReturns True if the series is decreasing over a period, False otherwise.\nIf the kwarg 'strict' is True, it returns True if it is continuously decreasing\nover the period. When using the kwarg 'asint', then it returns 1 for True\nor 0 for False.\n\nCalculation:\n    if strict:\n        decreasing  all(i > j for i, j in zip(close[-length:], close[1:]))\n    else:\n        decreasing  close.diff(length) < 0\n\n    if asint:\n        decreasing  decreasing.astype(int)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 1\n    asint (bool): Returns as binary. Default: True\n    strict (bool): If True, checks if the series is continuously decreasing over the period. Default: False\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/trend/dpo.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import sma\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef dpo(close, lengthNone, centeredTrue, offsetNone, **kwargs):\n    \"\"\"Indicator: Detrend Price Oscillator (DPO)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 20\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    t  int(0.5 * length) + 1\n    ma  sma(close, length)\n\n    dpo  close - ma.shift(t)\n    if centered:\n        dpo  (close.shift(t) - ma).shift(-t)\n\n    # Offset\n    if offset ! 0:\n        dpo  dpo.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        dpo.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        dpo.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    dpo.name  f\"DPO_{length}\"\n    dpo.category  \"trend\"\n\n    return dpo\n\n\ndpo.__doc__  \\\n\"\"\"Detrend Price Oscillator (DPO)\n\nIs an indicator designed to remove trend from price and make it easier to\nidentify cycles.\n\nSources:\n    https://www.tradingview.com/scripts/detrendedpriceoscillator/\n    https://www.fidelity.com/learning-center/trading-investing/technical-analysis/technical-indicator-guide/dpo\n    http://stockcharts.com/school/doku.php?idchart_school:technical_indicators:detrended_price_osci\n\nCalculation:\n    Default Inputs:\n        length20, centeredTrue\n    SMA  Simple Moving Average\n    t  int(0.5 * length) + 1\n\n    DPO  close.shift(t) - SMA(close, length)\n    if centered:\n        DPO  DPO.shift(-t)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 1\n    centered (bool): Shift the dpo back by int(0.5 * length) + 1. Default: True\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/trend/increasing.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef increasing(close, lengthNone, strictNone, asintNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Increasing\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 1\n    strict  strict if isinstance(strict, bool) else False\n    asint  asint if isinstance(asint, bool) else True\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    def stricly_increasing(series, n):\n        return all([i < j for i,j in zip(series[-n:], series[1:])])\n\n    # Calculate Result\n    if strict:\n        # Returns value as float64? Have to cast to bool\n        increasing  close.rolling(length, min_periodslength) \\\n            .apply(stricly_increasing, args(length,), rawFalse)\n        increasing.fillna(0, inplaceTrue)\n        increasing  increasing.astype(bool)\n    else:\n        increasing  close.diff(length) > 0\n\n    if asint:\n        increasing  increasing.astype(int)\n\n    # Offset\n    if offset ! 0:\n        increasing  increasing.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        increasing.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        increasing.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    increasing.name  f\"{'S' if strict else ''}INC_{length}\"\n    increasing.category  \"trend\"\n\n    return increasing\n\n\nincreasing.__doc__  \\\n\"\"\"Increasing\n\nReturns True if the series is increasing over a period, False otherwise.\nIf the kwarg 'strict' is True, it returns True if it is continuously increasing\nover the period. When using the kwarg 'asint', then it returns 1 for True\nor 0 for False. \n\nCalculation:\n    if strict:\n        increasing  all(i < j for i, j in zip(close[-length:], close[1:]))\n    else:\n        increasing  close.diff(length) > 0\n\n    if asint:\n        increasing  increasing.astype(int)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 1\n    asint (bool): Returns as binary. Default: True\n    strict (bool): If True, checks if the series is continuously increasing over the period. Default: False\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/trend/long_run.py\n\n# -*- coding: utf-8 -*-\nfrom .decreasing import decreasing\nfrom .increasing import increasing\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef long_run(fast, slow, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Long Run\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 2\n    fast  verify_series(fast, length)\n    slow  verify_series(slow, length)\n    offset  get_offset(offset)\n\n    if fast is None or slow is None: return\n\n    # Calculate Result\n    pb  increasing(fast, length) & decreasing(slow, length)  # potential bottom or bottom\n    bi  increasing(fast, length) & increasing(slow, length)  # fast and slow are increasing\n    long_run  pb | bi\n\n    # Offset\n    if offset ! 0:\n        long_run  long_run.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        long_run.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        long_run.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    long_run.name  f\"LR_{length}\"\n    long_run.category  \"trend\"\n\n    return long_run\n\n\n\npandas_ta/trend/psar.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import NaN as npNaN\nfrom pandas import DataFrame, Series\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef psar(high, low, closeNone, afNone, max_afNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Parabolic Stop and Reverse (PSAR)\"\"\"\n    # Validate Arguments\n    high  verify_series(high)\n    low  verify_series(low)\n    af  float(af) if af and af > 0 else 0.02\n    max_af  float(max_af) if max_af and max_af > 0 else 0.2\n    offset  get_offset(offset)\n\n    # Initialize\n    m  high.shape[0]\n    af0  af\n    bullish  True\n    high_point  high.iloc[0]\n    low_point  low.iloc[0]\n\n    if close is not None:\n        close  verify_series(close)\n        sar  close.copy()\n    else:\n        sar  low.copy()\n\n    long  Series(npNaN, indexsar.index)\n    short  long.copy()\n    reversal  Series(False, indexsar.index)\n    _af  long.copy()\n    _af.iloc[0:2]  af0\n\n    # Calculate Result\n    for i in range(2, m):\n        reverse  False\n        _af.iloc[i]  af\n\n        if bullish:\n            sar.iloc[i]  sar.iloc[i - 1] + af * (high_point - sar.iloc[i - 1])\n\n            if low.iloc[i] < sar.iloc[i]:\n                bullish, reverse, af  False, True, af0\n                sar.iloc[i]  high_point\n                low_point  low.iloc[i]\n        else:\n            sar.iloc[i]  sar.iloc[i - 1] + af * (low_point - sar.iloc[i - 1])\n\n            if high.iloc[i] > sar.iloc[i]:\n                bullish, reverse, af  True, True, af0\n                sar.iloc[i]  low_point\n                high_point  high.iloc[i]\n\n        reversal.iloc[i]  reverse\n\n        if not reverse:\n            if bullish:\n                if high.iloc[i] > high_point:\n                    high_point  high.iloc[i]\n                    af  min(af + af0, max_af)\n                if low.iloc[i - 1] < sar.iloc[i]:\n                    sar.iloc[i]  low.iloc[i - 1]\n                if low.iloc[i - 2] < sar.iloc[i]:\n                    sar.iloc[i]  low.iloc[i - 2]\n            else:\n                if low.iloc[i] < low_point:\n                    low_point  low.iloc[i]\n                    af  min(af + af0, max_af)\n                if high.iloc[i - 1] > sar.iloc[i]:\n                    sar.iloc[i]  high.iloc[i - 1]\n                if high.iloc[i - 2] > sar.iloc[i]:\n                    sar.iloc[i]  high.iloc[i - 2]\n\n        if bullish:\n            long.iloc[i]  sar.iloc[i]\n        else:\n            short.iloc[i]  sar.iloc[i]\n\n    # Offset\n    if offset ! 0:\n        _af  _af.shift(offset)\n        long  long.shift(offset)\n        short  short.shift(offset)\n        reversal  reversal.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        _af.fillna(kwargs[\"fillna\"], inplaceTrue)\n        long.fillna(kwargs[\"fillna\"], inplaceTrue)\n        short.fillna(kwargs[\"fillna\"], inplaceTrue)\n        reversal.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        _af.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        long.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        short.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        reversal.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Prepare DataFrame to return\n    _params  f\"_{af0}_{max_af}\"\n    data  {\n        f\"PSARl{_params}\": long,\n        f\"PSARs{_params}\": short,\n        f\"PSARaf{_params}\": _af,\n        f\"PSARr{_params}\": reversal,\n    }\n    psardf  DataFrame(data)\n    psardf.name  f\"PSAR{_params}\"\n    psardf.category  long.category  short.category  \"trend\"\n\n    return psardf\n\n\npsar.__doc__  \\\n\"\"\"Parabolic Stop and Reverse (psar)\n\nParabolic Stop and Reverse\n\nSource:\n    https://github.com/virtualizedfrog/blog_code/blob/master/PSAR/psar.py\n\nCalculation:\n    Default Inputs:\n        af0.02\n        max_af0.2\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series, optional): Series of 'close's. Optional\n    af (float): Acceleration Factor. Default: 0.02\n    max_af (float): Maximum Acceleration Factor. Default: 0.2\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: long, short, af, and reversal columns.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Este conteúdo está no diretório pandas_ta/trend e pandas_ta/utils, que fazem parte de uma biblioteca de análise técnica para séries temporais financeiras. Os arquivos implementam indicadores de tendência como QStick, Short Run, TTM Trend e Vortex, além de utilitários usados nessas fórmulas, envolvendo médias móveis, diferenciação de séries e manipulação de dados com pandas. As tecnologias principais incluem Python e pandas.')\npandas_ta/trend/qstick.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import dema, ema, hma, rma, sma\nfrom pandas_ta.utils import get_offset, non_zero_range, verify_series\n\n\ndef qstick(open_, close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Q Stick\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 10\n    ma  kwargs.pop(\"ma\", \"sma\")\n    open_  verify_series(open_, length)\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if open_ is None or close is None: return\n\n    # Calculate Result\n    diff  non_zero_range(close, open_)\n\n    if ma  \"dema\":\n        qstick  dema(diff, lengthlength, **kwargs)\n    elif ma  \"ema\":\n        qstick  ema(diff, lengthlength, **kwargs)\n    elif ma  \"hma\":\n        qstick  hma(diff, lengthlength)\n    elif ma  \"rma\":\n        qstick  rma(diff, lengthlength)\n    else: # \"sma\"\n        qstick  sma(diff, lengthlength)\n\n    # Offset\n    if offset ! 0:\n        qstick  qstick.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        qstick.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        qstick.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    qstick.name  f\"QS_{length}\"\n    qstick.category  \"trend\"\n\n    return qstick\n\n\nqstick.__doc__  \\\n\"\"\"Q Stick\n\nThe Q Stick indicator, developed by Tushar Chande, attempts to quantify and\nidentify trends in candlestick charts.\n\nSources:\n    https://library.tradingtechnologies.com/trade/chrt-ti-qstick.html\n\nCalculation:\n    Default Inputs:\n        length10\n    xMA is one of: sma (default), dema, ema, hma, rma\n    qstick  xMA(close - open, length)\n\nArgs:\n    open (pd.Series): Series of 'open's\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 1\n    ma (str): The type of moving average to use. Default: None, which is 'sma'\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/trend/short_run.py\n\n# -*- coding: utf-8 -*-\nfrom .decreasing import decreasing\nfrom .increasing import increasing\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef short_run(fast, slow, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Short Run\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 2\n    fast  verify_series(fast, length)\n    slow  verify_series(slow, length)\n    offset  get_offset(offset)\n\n    if fast is None or slow is None: return\n\n    # Calculate Result\n    pt  decreasing(fast, length) & increasing(slow, length)  # potential top or top\n    bd  decreasing(fast, length) & decreasing(slow, length)  # fast and slow are decreasing\n    short_run  pt | bd\n\n    # Offset\n    if offset ! 0:\n        short_run  short_run.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        short_run.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        short_run.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    short_run.name  f\"SR_{length}\"\n    short_run.category  \"trend\"\n\n    return short_run\n\n\n\npandas_ta/trend/ttm_trend.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import hl2\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef ttm_trend(high, low, close, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: TTM Trend (TTM_TRND)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 6\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    trend_avg  hl2(high, low)\n    for i in range(1, length):\n        trend_avg  trend_avg + hl2(high.shift(i), low.shift(i))\n\n    trend_avg  trend_avg / length\n\n    tm_trend  (close > trend_avg).astype(int)\n    tm_trend.replace(0, -1, inplaceTrue)\n\n    # Offset\n    if offset ! 0:\n        tm_trend  tm_trend.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        tm_trend.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        tm_trend.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    tm_trend.name  f\"TTM_TRND_{length}\"\n    tm_trend.category  \"momentum\"\n\n    # Prepare DataFrame to return\n    data  {tm_trend.name: tm_trend}\n    df  DataFrame(data)\n    df.name  f\"TTMTREND_{length}\"\n    df.category  tm_trend.category\n\n    return df\n\n\nttm_trend.__doc__  \\\n\"\"\"TTM Trend (TTM_TRND)\n\nThis indicator is from John Carters book “Mastering the Trade” and plots the\nbars green or red. It checks if the price is above or under the average price of\nthe previous 5 bars. The indicator should hep you stay in a trade until the\ncolors chance. Two bars of the opposite color is the signal to get in or out.\n\nSources:\n    https://www.prorealcode.com/prorealtime-indicators/ttm-trend-price/\n\nCalculation:\n    Default Inputs:\n        length6\n    averageprice  (((high[5]+low[5])/2)+((high[4]+low[4])/2)+((high[3]+low[3])/2)+((high[2]+low[2])/2)+((high[1]+low[1])/2)+((high[6]+low[6])/2)) / 6\n\n    if close > averageprice:\n        drawcandle(open,high,low,close) coloured(0,255,0)\n\n    if close < averageprice:\n        drawcandle(open,high,low,close) coloured(255,0,0)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 6\n    offset (int): How many periods to offset the result. Default: 0\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\nReturns:\n    pd.DataFrame: ttm_trend.\n\"\"\"\n\n\n\npandas_ta/trend/vortex.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.volatility import true_range\nfrom pandas_ta.utils import get_drift, get_offset, verify_series, zero\n\n\ndef vortex(high, low, close, lengthNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Vortex\"\"\"\n    # Validate arguments\n    length  length if length and length > 0 else 14\n    min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    _length  max(length, min_periods)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    tr  true_range(highhigh, lowlow, closeclose)\n    tr_sum  tr.rolling(length, min_periodsmin_periods).sum()\n\n    vmp  (high - low.shift(drift)).abs()\n    vmm  (low - high.shift(drift)).abs()\n\n    vip  vmp.rolling(length, min_periodsmin_periods).sum() / tr_sum\n    vim  vmm.rolling(length, min_periodsmin_periods).sum() / tr_sum\n\n    # Offset\n    if offset ! 0:\n        vip  vip.shift(offset)\n        vim  vim.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        vip.fillna(kwargs[\"fillna\"], inplaceTrue)\n        vim.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        vip.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        vim.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    vip.name  f\"VTXP_{length}\"\n    vim.name  f\"VTXM_{length}\"\n    vip.category  vim.category  \"trend\"\n\n    # Prepare DataFrame to return\n    data  {vip.name: vip, vim.name: vim}\n    vtxdf  DataFrame(data)\n    vtxdf.name  f\"VTX_{length}\"\n    vtxdf.category  \"trend\"\n\n    return vtxdf\n\n\nvortex.__doc__  \\\n\"\"\"Vortex\n\nTwo oscillators that capture positive and negative trend movement.\n\nSources:\n    https://stockcharts.com/school/doku.php?idchart_school:technical_indicators:vortex_indicator\n\nCalculation:\n    Default Inputs:\n        length14, drift1\n    TR  True Range\n    SMA  Simple Moving Average\n    tr  TR(high, low, close)\n    tr_sum  tr.rolling(length).sum()\n\n    vmp  (high - low.shift(drift)).abs()\n    vmn  (low - high.shift(drift)).abs()\n\n    VIP  vmp.rolling(length).sum() / tr_sum\n    VIM  vmn.rolling(length).sum() / tr_sum\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): ROC 1 period. Default: 14\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: vip and vim columns\n\"\"\"\n\n\n\npandas_ta/utils/__init__.py\n\n# -*- coding: utf-8 -*-\nfrom ._candles import *\nfrom ._core import *\nfrom ._data import *\nfrom ._math import *\nfrom ._signals import *\nfrom ._time import *\nfrom ._metrics import *\n\n\n\npandas_ta/utils/_candles.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import Series\n\nfrom ._core import non_zero_range\n\n\ndef candle_color(open_: Series, close: Series) -> Series:\n    color  close.copy().astype(int)\n    color[close > open_]  1\n    color[close < open_]  -1\n    return color\n\n\ndef high_low_range(high: Series, low: Series) -> Series:\n    return non_zero_range(high, low)\n\n\ndef real_body(open_: Series, close: Series) -> Series:\n    return non_zero_range(close, open_)\n\n\n\npandas_ta/utils/_core.py\n\n# -*- coding: utf-8 -*-\nimport re as re_\nfrom pathlib import Path\nfrom sys import float_info as sflt\n\nfrom numpy import argmax, argmin\nfrom numpy import NaN as npNaN\nfrom pandas import DataFrame, Series\nfrom pandas.api.types import is_datetime64_any_dtype\n\n\ndef _camelCase2Title(x: str):\n    \"\"\"https://stackoverflow.com/questions/5020906/python-convert-camel-case-to-space-delimited-using-regex-and-taking-acronyms-in\"\"\"\n    return re_.sub(\"([a-z])([A-Z])\",\"\\g<1> \\g<2>\", x).title()\n\n\ndef category_files(category: str) -> list:\n    \"\"\"Helper function to return all filenames in the category directory.\"\"\"\n    files  [\n        x.stem\n        for x in list(Path(f\"pandas_ta/{category}/\").glob(\"*.py\"))\n        if x.stem ! \"__init__\"\n    ]\n    return files\n\n\ndef get_drift(x: int) -> int:\n    \"\"\"Returns an int if not zero, otherwise defaults to one.\"\"\"\n    return int(x) if isinstance(x, int) and x ! 0 else 1\n\n\ndef get_offset(x: int) -> int:\n    \"\"\"Returns an int, otherwise defaults to zero.\"\"\"\n    return int(x) if isinstance(x, int) else 0\n\n\ndef is_datetime_ordered(df: DataFrame or Series) -> bool:\n    \"\"\"Returns True if the index is a datetime and ordered.\"\"\"\n    index_is_datetime  is_datetime64_any_dtype(df.index)\n    try:\n        ordered  df.index[0] < df.index[-1]\n    except RuntimeWarning:\n        pass\n    finally:\n        return True if index_is_datetime and ordered else False\n\n\ndef is_percent(x: int or float) -> bool:\n    if isinstance(x, (int, float)):\n        return x is not None and x > 0 and x < 100\n    return False\n\n\ndef non_zero_range(high: Series, low: Series) -> Series:\n    \"\"\"Returns the difference of two series and adds epsilon to any zero values.  This occurs commonly in crypto data when 'high'  'low'.\"\"\"\n    diff  high - low\n    if diff.eq(0).any().any():\n        diff + sflt.epsilon\n    return diff\n\n\ndef recent_maximum_index(x):\n    return int(argmax(x[::-1]))\n\n\ndef recent_minimum_index(x):\n    return int(argmin(x[::-1]))\n\n\ndef signed_series(series: Series, initial: int  None) -> Series:\n    \"\"\"Returns a Signed Series with or without an initial value\n\n    Default Example:\n    series  Series([3, 2, 2, 1, 1, 5, 6, 6, 7, 5])\n    and returns:\n    sign  Series([NaN, -1.0, 0.0, -1.0, 0.0, 1.0, 1.0, 0.0, 1.0, -1.0])\n    \"\"\"\n    series  verify_series(series)\n    sign  series.diff(1)\n    sign[sign > 0]  1\n    sign[sign < 0]  -1\n    sign.iloc[0]  initial\n    return sign\n\n\ndef unsigned_differences(series: Series, amount: int  None, **kwargs) -> Series:\n    \"\"\"Unsigned Differences\n    Returns two Series, an unsigned positive and unsigned negative series based\n    on the differences of the original series. The positive series are only the\n    increases and the negative series is only the decreases.\n\n    Default Example:\n    series    Series([3, 2, 2, 1, 1, 5, 6, 6, 7, 5, 3]) and returns\n    postive   Series([0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0])\n    negative  Series([0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1])\n    \"\"\"\n    amount  int(amount) if amount is not None else 1\n    negative  series.diff(amount)\n    negative.fillna(0, inplaceTrue)\n    positive  negative.copy()\n\n    positive[positive < 0]  0\n    positive[positive > 0]  1\n\n    negative[negative > 0]  0\n    negative[negative < 0]  1\n\n    if kwargs.pop(\"asint\", False):\n        positive  positive.astype(int)\n        negative  negative.astype(int)\n\n    return positive, negative\n\n\ndef verify_series(series: Series, min_length: int  None) -> Series:\n    \"\"\"If a Pandas Series and it meets the min_length of the indicator return it.\"\"\"\n    has_length  min_length is not None and isinstance(min_length, int)\n    if series is not None and isinstance(series, Series):\n        return None if has_length and series.size < min_length else series\n\n\n",
        "AgentRunResult(output='Este trecho pertence ao arquivo `pandas_ta/utils/_data.py` (parte 1 de 2), localizado na pasta `pandas_ta`. Ele trata da obtenção de dados financeiros usando as APIs Alpha Vantage e yfinance.')\npandas_ta/utils/_data.py - Parte (1/2)\npandas_ta/utils/_data.py\n\n# -*- coding: utf-8 -*-\nfrom packaging import version\nfrom pandas import DataFrame\nfrom pandas_ta import Imports, RATE, version\nfrom ._core import _camelCase2Title\nfrom ._time import ytd_df\n\ndef av(ticker: str, **kwargs):\n    print(f\"[!] kwargs: {kwargs}\")\n    verbose  kwargs.pop(\"verbose\", False)\n    kind  kwargs.pop(\"kind\", \"history\")\n    kind  kind.lower()\n    interval  kwargs.pop(\"interval\", \"D\")\n    show  kwargs.pop(\"show\", None)\n    # last  kwargs.pop(\"last\", RATE[\"TRADING_DAYS_PER_YEAR\"])\n\n    ticker  ticker.upper() if ticker is not None and isinstance(ticker, str) else None\n\n    if Imports[\"alphaVantage-api\"] and ticker is not None:\n        # from alphaVantageAPI import alphavantage\n        import alphaVantageAPI as AV\n        AVC  {\"api_key\": \"YOUR API KEY\", \"clean\": True, \"export\": False, \"output_size\": \"full\", \"premium\": False}\n        _config  kwargs.pop(\"av_kwargs\", AVC)\n        av  AV.AlphaVantage(**_config)\n\n        period  kwargs.pop(\"period\", av.output_size)\n\n        _all, div  [\"all\"], \"\" * 53 # Max div width is 80\n\n        if kind in _all or verbose: pass\n\n        if kind in _all + [\"history\", \"h\"]:\n            if verbose:\n                print(\"\\n  Chart History       \" + div + f\"\\n[*] Pandas TA v{version} & alphaVantage-api\")\n                print(f\"[+] Downloading {ticker}[{interval}:{period}] from {av.API_NAME} (https://www.alphavantage.co/)\")\n            df  av.data(ticker, interval)\n            df.name  ticker\n            if show is not None and isinstance(show, int) and show > 0:\n                print(f\"\\n{df.name}\\n{df.tail(show)}\\n\")\n            return df\n\n    return DataFrame()\n\n\ndef yf(ticker: str, **kwargs):\n    \"\"\"yf - yfinance wrapper\n\n    It retrieves market data (ohlcv) from Yahoo Finance using yfinance.\n    To install yfinance. (pip install yfinance) This method can also pull\n    additional data using the 'kind' kwarg. By default kindNone and retrieves\n    Historical Chart Data.\n\n    Other options of 'kind' include:\n    * All: \"all\"\n        - Prints everything below but only returns Chart History to Pandas TA\n    * Company Information: \"info\"\n    * Institutional Holders: \"institutional_holders\" or \"ih\"\n    * Major Holders: \"major_holders\" or \"mh\"\n    * Mutual Fund Holders: \"mutualfund_holders\" or \"mfh\"\n    * Recommendations (YTD): \"recommendations\" or \"rec\"\n    * Earnings Calendar: \"calendar\" or \"cal\"\n    * Earnings: \"earnings\" or \"earn\"\n    * Sustainability/ESG Scores: \"sustainability\", \"sus\" or \"esg\"\n    * Financials: \"financials\" or \"fin\"\n        - Returns in order: Income Statement, Balance Sheet and Cash Flow\n    * Option Chain: \"option_chain\" or \"oc\"\n        - Uses the nearest expiration date by default\n        - Change the expiration date using kwarg \"exp\"\n        - Show ITM options, set kwarg \"itm\" to True. Or OTM options, set\n        kwarg \"itm\" to False.\n    * Chart History:\n        - The only data returned to Pandas TA.\n\n    Args:\n        ticker (str): Any string for a ticker you would use with yfinance.\n            Default: \"SPY\"\n    Kwargs:\n        calls (bool): When True, prints only Option Calls for the Option Chain.\n            Default: None\n        desc (bool): Will print Company Description when printing Company\n            Information. Default: False\n        exp (str): Used to print other Option Chains for the given Expiration\n            Date. Default: Nearest Expiration Date for the Option Chains\n        interval (str): A yfinance argument. Default: \"1d\"\n        itm (bool): When printing Option Chains, shows ITM Options when True.\n            When False, it shows OTM Options: Default: None\n        kind (str): Options see above. Default: None\n        period (str): A yfinance argument. Default: \"max\"\n        proxy (dict): Proxy for yfinance to use. Default: {}\n        puts (bool): When True, prints only Option Puts for the Option Chain.\n            Default: None\n        show (int > 0): How many last rows of Chart History to show.\n            Default: None\n        snd (int): How many recent Splits and Dividends to show in Company\n            Information. Default: 5\n        verbose (bool): Prints Company Information \"info\" and a Chart History\n            header to the screen. Default: False\n\n    Returns:\n        Exits if the DataFrame is empty or None\n        Otherwise it returns a DataFrame of the Chart History\n    \"\"\"\n    verbose  kwargs.pop(\"verbose\", False)\n    if ticker is not None and isinstance(ticker, str) and len(ticker):\n        ticker  ticker.upper()\n    else:\n        ticker  \"SPY\"\n\n    kind  kwargs.pop(\"kind\", None)\n    if kind is not None and isinstance(kind, str) and len(kind):\n        kind  kind.lower()\n\n    period  kwargs.pop(\"period\", \"max\")\n    interval  kwargs.pop(\"interval\", \"1d\")\n    proxy  kwargs.pop(\"proxy\", {})\n    show  kwargs.pop(\"show\", None)\n\n    if not Imports[\"yfinance\"]:\n        print(f\"[X] Please install yfinance to use this method. (pip install yfinance)\")\n        return\n    if Imports[\"yfinance\"] and ticker is not None:\n        import yfinance as yfra\n        yfra.pdr_override()\n\n        # Ticker Info & Chart History\n        yfd  yfra.Ticker(ticker)\n        df  yfd.history(periodperiod, intervalinterval, proxyproxy, **kwargs)\n        print(f\"[X] df[{type(df)}:{df.empty}]\\n{df}\\n\")\n        if df.empty: return\n        df.name  ticker\n\n        try:\n            ticker_info  yfd.info\n        except KeyError as ke:\n            print(f\"[X] Ticker '{ticker}' not found.\")\n            return\n        print(f\"[X] ticker_info[{type(ticker_info)}:{len(ticker_info.keys())}]\\n{ticker_info}\\n\")\n\n        try:\n            infodf  DataFrame.from_dict(ticker_info, orient\"index\")\n        except TypeError as te:\n            print(f\"[X] TypeError: {te}\")\n        # else:\n        #     infodf  DataFrame(ticker_info)\n\n        print(f\"[X] infodf.empty: {infodf.empty}\")\n        if infodf.empty: return\n        print(f\"[X] infodf[{type(infodf)}:{len(infodf.keys())}]\\n{infodf}\\n\")\n        infodf.name, infodf.columns  ticker, [ticker]\n\n        # Dividends and Splits\n        dividends, splits  yfd.splits, yfd.dividends\n\n        _all, div  [\"all\"], \"\" * 53 # Max div width is 80\n        if kind in _all + [\"info\"] or verbose:\n            description  kwargs.pop(\"desc\", False)\n            snd_length  kwargs.pop(\"snd\", 5)\n\n            [print(f\"{_[0]}: {_[1]}\") for _ in sorted(ticker_info.items())]\n            print()\n\n            print(\"\\n  Company Information  \" + div)\n            print(f\"{ticker_info['longName']} ({ticker_info['shortName']}) [{ticker_info['symbol']}]\")\n            print(f\"[i] {type(ticker_info['longBusinessSummary'])}: {ticker_info['longBusinessSummary']}\")\n            if description:\n                print(f\"{ticker_info['longBusinessSummary']}\\n\")\n            if \"address1\" in ticker_info and len(ticker_info[\"address1\"]):\n                if \"address2\" in ticker_info and len(ticker_info[\"address2\"]):\n                    print(f\"{ticker_info['address1']} {ticker_info['address2']}\")\n                else:\n                    print(f\"{ticker_info['address1']}\")\n\n                if \"city\" in ticker_info and len(ticker_info[\"city\"]) and \"state\" in ticker_info and len(ticker_info[\"state\"]) \\\n                    and \"zip\" in ticker_info and len(ticker_info[\"zip\"]) and \"country\" in ticker_info and len(ticker_info[\"country\"]):\n                    print(f\"{ticker_info['city']}, {ticker_info['state']} {ticker_info['zip']}, {ticker_info['country']}\")\n                else:\n                    print(f\"{ticker_info['state']} {ticker_info['zip']}, {ticker_info['country']}\")\n                print(f\"Phone (Fax): {ticker_info['phone']} ({ticker_info['fax'] if 'fax' in ticker_info else 'N/A'})\")\n\n            if \"website\" in ticker_info and len(ticker_info['website']):\n                s  f\"Website: {ticker_info['website']}\".ljust(40)\n                if \"fullTimeEmployees\" in ticker_info:\n                    s + f\"FT Employees: {ticker_info['fullTimeEmployees']:,}\".rjust(40)\n                print(s)\n            elif \"fullTimeEmployees\" in ticker_info:\n                print(f\"FT Employees: {ticker_info['fullTimeEmployees']:,}\")\n\n            if \"companyOfficers\" in ticker_info and len(ticker_info['companyOfficers']):\n                print(f\"Company Officers: {', '.join(ticker_info['companyOfficers'])}\".ljust(40))\n            if \"sector\" in ticker_info and len(ticker_info[\"sector\"]) and \"industry\" in ticker_info and len(ticker_info[\"industry\"]):\n                # print(f\"Sector: {ticker_info['sector']}\".ljust(39), f\"Industry: {ticker_info['industry']}\".rjust(40))\n                print(f\"Sector | Industry\".ljust(29), f\"{ticker_info['sector']} | {ticker_info['industry']}\".rjust(50))\n\n            print(\"\\n  Market Information   \" + div)\n            _category  f\" | {ticker_info['category']}\" if \"category\" in ticker_info and ticker_info[\"category\"] is not None else \"\"\n            print(\n                f\"Market | Exchange | Symbol{' | Category' if 'category' in ticker_info and ticker_info['category'] is not None else ''}\".ljust(39),\n                f\"{ticker_info['market'].split('_')[0].upper()} | {ticker_info['exchange']} | {ticker_info['symbol']}{_category}\".rjust(40)\n            )\n\n            print()\n            if \"marketCap\" in ticker_info and ticker_info[\"marketCap\"] is not None:\n                print(f\"Market Cap.\".ljust(39), f\"{ticker_info['marketCap']:,} ({ticker_info['marketCap']/1000000:,.2f} MM)\".rjust(40))\n            if \"navPrice\" in ticker_info and ticker_info[\"navPrice\"] is not None or \"yield\" in ticker_info and ticker_info[\"yield\"] is not None:\n                print(f\"NAV | Yield\".ljust(39), f\"{ticker_info['navPrice']} | {100 * ticker_info['yield']:.4f}%\".rjust(40))\n            if \"sharesOutstanding\" in ticker_info and ticker_info[\"sharesOutstanding\"] is not None and \"floatShares\" in ticker_info and ticker_info[\"floatShares\"] is not None:\n                print(f\"Shares Outstanding | Float\".ljust(39), f\"{ticker_info['sharesOutstanding']:,} | {ticker_info['floatShares']:,}\".rjust(40))\n            if \"impliedSharesOutstanding\" in ticker_info and ticker_info[\"impliedSharesOutstanding\"] is not None:\n                print(f\"Implied Shares Outstanding\".ljust(39), f\"{ticker_info['impliedSharesOutstanding']:,}\".rjust(40))\n            if \"sharesShort\" in ticker_info and \"shortRatio\" in ticker_info and ticker_info[\"sharesShort\"] is not None and ticker_info[\"shortRatio\"] is not None:\n                print(f\"Shares Short | Ratio\".ljust(39), f\"{ticker_info['sharesShort']:,} | {ticker_info['shortRatio']:,}\".rjust(40))\n            if \"shortPercentOfFloat\" in ticker_info and ticker_info['shortPercentOfFloat'] is not None and \"sharesShortPriorMonth\" in ticker_info and ticker_info['sharesShortPriorMonth'] is not None:\n                print(f\"Short % of Float | Short prior Month\".ljust(39), f\"{100 * ticker_info['shortPercentOfFloat']:.4f}% | {ticker_info['sharesShortPriorMonth']:,}\".rjust(40))\n            if \"heldPercentInstitutions\" in ticker_info and ticker_info['heldPercentInstitutions'] is not None or \"heldPercentInsiders\" in ticker_info and ticker_info['heldPercentInsiders'] is not None:\n                print(f\"Insiders % | Institution %\".ljust(39), f\"{100 * ticker_info['heldPercentInsiders']:.4f}% | {100 * ticker_info['heldPercentInstitutions']:.4f}\".rjust(40))\n\n            print()\n            if \"bookValue\" in ticker_info and ticker_info['bookValue'] is not None or \"priceToBook\" in ticker_info and ticker_info['priceToBook'] is not None or \"pegRatio\" in ticker_info and ticker_info['pegRatio'] is not None:\n                print(f\"Book Value | Price to Book | Peg Ratio\".ljust(39), f\"{ticker_info['priceToBook']} | {ticker_info['priceToBook']} | {ticker_info['pegRatio']}\".rjust(40))\n            if \"forwardPE\" in ticker_info and ticker_info['forwardPE'] is not None:\n                print(f\"Forward PE\".ljust(39), f\"{ticker_info['forwardPE']}\".rjust(40))\n            if \"forwardEps\" in ticker_info and ticker_info['forwardEps'] is not None or \"trailingEps\" in ticker_info and ticker_info['trailingEps'] is not None:\n                print(f\"Forward EPS | Trailing EPS\".ljust(39), f\"{ticker_info['forwardEps']} | {ticker_info['trailingEps']}\".rjust(40))\n            if \"enterpriseValue\" in ticker_info and ticker_info['enterpriseValue'] is not None:\n                print(f\"Enterprise Value\".ljust(39), f\"{ticker_info['enterpriseValue']:,}\".rjust(40))\n            if \"enterpriseToRevenue\" in ticker_info and ticker_info['enterpriseToRevenue'] is not None or \"enterpriseToEbitda\" in ticker_info and ticker_info['enterpriseToEbitda'] is not None:\n                print(f\"Enterprise to Revenue | to EBITDA\".ljust(39), f\"{ticker_info['enterpriseToRevenue']} | {ticker_info['enterpriseToEbitda']}\".rjust(40))\n\n            print()\n            if \"netIncomeToCommon\" in ticker_info and ticker_info['netIncomeToCommon'] is not None:\n                print(f\"Net Income to Common\".ljust(39), f\"{ticker_info['netIncomeToCommon']:,}\".rjust(40))\n            if \"re",
        "AgentRunResult(output='Fragmento da segunda parte do arquivo `pandas_ta/utils/_data.py` no diretório raiz `pandas_ta`. Oferece funções de análise técnica baseadas principalmente em dados do `yfinance`, incluindo estatísticas de preço, indicadores como média móvel, dividendos, splits, detentores institucionais, recomendações, calendário de lucros, sustentabilidade ESG, demonstrações financeiras e opções. Utiliza intensamente `pandas` para exibir e formatar esses dados.')\npandas_ta/utils/_data.py - Parte (2/2)\nvenueQuarterlyGrowth\" in ticker_info and ticker_info['revenueQuarterlyGrowth'] is not None:\n                print(f\"Revenue Quarterly Growth\".ljust(39), f\"{ticker_info['revenueQuarterlyGrowth']}\".rjust(40))\n            if \"profitMargins\" in ticker_info and ticker_info['profitMargins'] is not None:\n                print(f\"Profit Margins\".ljust(39), f\"{100 * ticker_info['profitMargins']:.4f}%\".rjust(40))\n            if \"earningsQuarterlyGrowth\" in ticker_info and ticker_info['earningsQuarterlyGrowth'] is not None:\n                print(f\"Quarterly Earnings Growth\".ljust(39), f\"{ticker_info['earningsQuarterlyGrowth']}\".rjust(40))\n            if \"annualReportExpenseRatio\" in ticker_info and ticker_info['annualReportExpenseRatio'] is not None:\n                print(f\"Annual Expense Ratio\".ljust(39), f\"{ticker_info['annualReportExpenseRatio']}\".rjust(40))\n\n            print(\"\\n  Price Information    \" + div)\n            _o, _h, _l, _c, _v  ticker_info['open'], ticker_info['dayHigh'], ticker_info['dayLow'], ticker_info['regularMarketPrice'], ticker_info['regularMarketVolume']\n            print(f\"Open High Low Close\".ljust(39), f\"{_o:.4f}, {_o:.4f}, {_l:.4f}, {_c:.4f}\".rjust(40))\n            print(f\"HL2 | HLC3 | OHLC4 | C - OHLC4\".ljust(39), f\"{0.5 * (_h + _l):.4f}, {(_h + _l + _c) / 3.:.4f}, {0.25 * (_o + _h + _l + _c):.4f}, {_c - 0.25 * (_o + _h + _l + _c):.4f}\".rjust(40))\n            print(f\"Change (%)\".ljust(39), f\"{_c - ticker_info['previousClose']:.4f} ({100 * ((_c / ticker_info['previousClose']) - 1):.4f}%)\".rjust(40))\n            print(f\"Volume | Avg Vol (10Day)\".ljust(39), f\"{ticker_info['volume']:,} | {ticker_info['averageVolume']:,} ({ticker_info['averageDailyVolume10Day']:,})\".rjust(40))\n            print(f\"Bid | Ask | Spread\".ljust(39), f\"{ticker_info['bid']} x {ticker_info['bidSize']} | {ticker_info['ask']} x {ticker_info['askSize']} | {ticker_info['ask'] - ticker_info['bid']:.4f}\".rjust(40))\n\n            print()\n            if \"52WeekChange\" in ticker_info and ticker_info['52WeekChange'] is not None:\n                print(f\"52Wk % Change\".ljust(39), f\"{100 * ticker_info['52WeekChange']:.4f}%\".rjust(40))\n            if \"SandP52WeekChange\" in ticker_info and ticker_info['SandP52WeekChange'] is not None:\n                print(f\"52Wk % Change vs S&P500\".ljust(39), f\"{100 *ticker_info['SandP52WeekChange']:.4f}%\".rjust(40))\n            if \"fiftyTwoWeekHigh\" in ticker_info and \"fiftyTwoWeekLow\" in ticker_info and \"previousClose\" in ticker_info: # or 'regularMarketPrice'\n                print(f\"52Wk Range (% from 52Wk Low)\".ljust(39), f\"{ticker_info['fiftyTwoWeekLow']} - {ticker_info['fiftyTwoWeekHigh']} : {ticker_info['fiftyTwoWeekHigh'] - ticker_info['fiftyTwoWeekLow']:.4f} ({100 * (ticker_info['regularMarketPrice'] / ticker_info['fiftyTwoWeekLow'] - 1):.4f}%)\".rjust(40))\n\n            avg50   \"fiftyDayAverage\" in ticker_info and ticker_info['fiftyDayAverage'] is not None\n            avg200  \"twoHundredDayAverage\" in ticker_info and ticker_info['twoHundredDayAverage'] is not None\n            if avg50 and avg200:\n                print(f\"SMA 50 | SMA 200\".ljust(39), f\"{ticker_info['fiftyDayAverage']:.4f} | {ticker_info['twoHundredDayAverage']:.4f}\".rjust(40))\n            elif avg50:\n                print(f\"SMA 50\".ljust(39), f\"{ticker_info['fiftyDayAverage']:.4f}\".rjust(40))\n            elif avg200:\n                print(f\"SMA 200\".ljust(39), f\"{ticker_info['twoHundredDayAverage']:.4f}\".rjust(40))\n            if \"beta\" in ticker_info and ticker_info['beta'] is not None:\n                print(f\"Beta | 3Yr\".ljust(39), f\"{ticker_info['beta']} | {ticker_info['beta3Year']}\".rjust(40))\n            if \"threeYearAverageReturn\" in ticker_info and ticker_info['threeYearAverageReturn'] is not None or \"fiveYearAverageReturn\" in ticker_info and ticker_info['fiveYearAverageReturn'] is not None:\n                print(f\"Avg. Return 3Yr | 5Yr\".ljust(39), f\"{100 * ticker_info['threeYearAverageReturn']:.4f}% | {100 * ticker_info['fiveYearAverageReturn']:.4f}%\".rjust(40))\n\n            # Dividends and Splits\n            if not dividends.empty or not splits.empty:\n                print(\"\\n  Dividends / Splits   \" + div)\n                if \"dividendRate\" in ticker_info and ticker_info['dividendRate'] is not None and \"dividendYield\" in ticker_info and ticker_info['dividendYield'] is not None and \"payoutRatio\" in ticker_info and ticker_info['payoutRatio'] is not None:\n                    print(f\"Rate | Yield | Payout Ratio\".ljust(39), f\"{ticker_info['dividendRate']} | {100 * ticker_info['dividendYield']:.4f}% | {ticker_info['payoutRatio']}\".rjust(40))\n                if \"trailingAnnualDividendRate\" in ticker_info and ticker_info['trailingAnnualDividendRate'] is not None and \"trailingAnnualDividendYield\" in ticker_info and ticker_info['trailingAnnualDividendYield'] is not None:\n                    print(f\"Trailing Annual Dividend Rate | Yield\".ljust(40), f\"{ticker_info['trailingAnnualDividendRate']} | {100 * ticker_info['trailingAnnualDividendYield']:.4f}%\\n\".rjust(40))\n            if not dividends.empty:\n                dividends.name  \"Value\"\n                total_dividends  dividends.size\n                dividendsdf  DataFrame(dividends.tail(snd_length)[::-1]).T\n                print(f\"Dividends (Last {snd_length} of {total_dividends}):\\n{dividendsdf}\")\n\n            if not splits.empty:\n                splits.name  \"Ratio\"\n                total_splits  splits.size\n                splitsdf  DataFrame(splits.tail(snd_length)[::-1]).T\n                print(f\"\\nStock Splits (Last {snd_length} of {total_splits}):\\n{splitsdf}\")\n\n        if kind in _all + [\"institutional_holders\", \"ih\"]:\n            ihdf  yfd.institutional_holders\n            if ihdf is not None and \"Date Reported\" in ihdf.columns:\n                ihdf.set_index(\"Date Reported\", inplaceTrue)\n                ihdf[\"Shares\"]  ihdf.apply(lambda x: f\"{x['Shares']:,}\", axis1)\n                ihdf[\"Value\"]  ihdf.apply(lambda x: f\"{x['Value']:,}\", axis1)\n                if kind not in _all: print(f\"\\n{ticker_info['symbol']}\")\n                print(\"\\n  Instl. Holders       \" + div + f\"\\n{ihdf}\")\n\n        if kind in _all + [\"major_holders\", \"mh\"]:\n            mhdf  yfd.major_holders\n            if mhdf is not None and \"Major Holders\" in mhdf.columns:\n                mhdf.columns  [\"Percentage\", \"Major Holders\"]\n                mhdf.set_index(\"Major Holders\", inplaceTrue)\n                mhdf[\"Shares\"]  mhdf.apply(lambda x: f\"{x['Shares']:,}\", axis1)\n                mhdf[\"Value\"]  mhdf.apply(lambda x: f\"{x['Value']:,}\", axis1)\n                if kind not in _all: print(f\"\\n{ticker_info['symbol']}\")\n                print(\"\\n  Major Holders       \" + div + f\"\\n{mhdf}\")\n\n        if kind in _all + [\"mutualfund_holders\", \"mfh\"]:\n            mfhdf  yfd.get_mutualfund_holders()\n            if mfhdf is not None and \"Holder\" in mfhdf.columns:\n                mfhdf.set_index(\"Date Reported\", inplaceTrue)\n                mfhdf[\"Shares\"]  mfhdf.apply(lambda x: f\"{x['Shares']:,}\", axis1)\n                mfhdf[\"Value\"]  mfhdf.apply(lambda x: f\"{x['Value']:,}\", axis1)\n                if kind not in _all: print(f\"\\n{ticker_info['symbol']}\")\n                print(\"\\n  Mutual Fund Holders  \" + div + f\"\\n{mfhdf}\")\n\n        if kind in _all + [\"recommendations\", \"rec\"]:\n            recdf  yfd.recommendations\n            if recdf is not None:\n                recdf  ytd_df(recdf)\n                # recdf_grade  recdf[\"To Grade\"].value_counts().T\n                # recdf_grade.name  \"Grades\"\n                if kind not in _all: print(f\"\\n{ticker_info['symbol']}\")\n                print(\"\\n  Recommendation(YTD)  \" + div + f\"\\n{recdf}\")\n\n        if kind in _all + [\"calendar\", \"cal\"]:\n            caldf  yfd.calendar\n            if caldf is not None and \"Earnings Date\" in caldf.columns:\n                    caldf.set_index(\"Earnings Date\", inplaceTrue)\n                    if kind not in _all: print(f\"\\n{ticker_info['symbol']}\")\n                    print(\"\\n  Earnings Calendar    \" + div + f\"\\n{caldf}\")\n\n        if kind in _all + [\"earnings\", \"earn\"]:\n            earndf  yfd.earnings\n            if not earndf.empty:\n                earndf[\"Revenue\"]  earndf.apply(lambda x: f\"{x['Revenue']:,}\", axis1)\n                earndf[\"Earnings\"]  earndf.apply(lambda x: f\"{x['Earnings']:,}\", axis1)\n                if kind not in _all: print(f\"\\n{ticker_info['symbol']}\")\n                print(\"\\n  Earnings             \" + div + f\"\\n{earndf}\")\n\n        if kind in _all + [\"sustainability\", \"sus\", \"esg\"]:\n            susdf  yfd.sustainability\n            if susdf is not None:\n                susdf.replace({None: False}, inplaceTrue)\n                susdf.columns  [\"Score\"]\n                susdf.drop(susdf[susdf[\"Score\"]  False].index, inplaceTrue)\n                susdf.rename(index_camelCase2Title, errors\"ignore\", inplaceTrue)\n                susdf.index.name  \"Source\"\n                if kind not in _all: print(f\"\\n{ticker_info['symbol']}\")\n                print(\"\\n  Sustainability/ESG   \" + div + f\"\\n{susdf}\")\n\n        if kind in _all + [\"financials\", \"fin\"]:\n            icdf  yfd.financials\n            bsdf  yfd.balance_sheet\n            cfdf  yfd.cashflow\n\n            if icdf.empty or bsdf.empty or cfdf.empty:\n                if yfra.__version__ < \"0.1.54\":\n                    print(f\"[!] Best choice: update yfinance to the latest version.\")\n                    print(f\"[!] Ignore if aleady patched. Some tickers do not have financials.\")\n                    print(f\"[!] Otherwise to enable Company Financials, see yfinance Issue #517 patch.\")\n                    print(f\"[!] https://github.com/ranaroussi/yfinance/pull/517/files\")\n            else:\n                print(\"\\n  Company Financials   \" + div)\n                if not icdf.empty: print(f\"Income Statement:\\n{icdf}\\n\")\n                if not bsdf.empty: print(f\"Balance Sheet:\\n{bsdf}\\n\")\n                if not cfdf.empty: print(f\"Cash Flow:\\n{cfdf}\\n\")\n\n        if kind in _all + [\"option_chain\", \"oc\"]:\n            try:\n                yfd_options  yfd.options\n            except IndexError as ie:\n                yfd_options  None\n\n            if yfd_options is not None:\n                opt_expirations  list(yfd_options)\n                just_calls  kwargs.pop(\"calls\", None)\n                just_puts  kwargs.pop(\"puts\", None)\n                itm  kwargs.pop(\"itm\", None)\n                opt_date  kwargs.pop(\"exp\", opt_expirations[0])\n                opt_expirations_str  f\"{ticker} Option Expirations:\\n\\t{', '.join(opt_expirations)}\\n\"\n\n                if kind not in _all: print(f\"\\n{ticker_info['symbol']}\")\n                if isinstance(itm, bool) and itm: print(\"\\n  ITM Option Chains    \" + div)\n                elif isinstance(itm, bool) and not itm: print(\"\\n  OTM Option Chains    \" + div)\n                else: print(\"\\n  Option Chains        \" + div)\n                print(opt_expirations_str)\n\n                if opt_date not in opt_expirations:\n                    print(f\"[X] No Options for {ticker_info['quoteType']} {ticker_info['symbol']}\")\n                else:\n                    option_columns  [\"Contract\", \"Last Trade\", \"Strike\", \"Price\", \"Bid\", \"Ask\", \"Change\", \"Percent Change\", \"Volume\", \"OI\", \"IV\", \"ITM\", \"Size\", \"Currency\"]\n                    cp_chain  yfd.option_chain(proxyproxy)\n                    calls, puts  cp_chain.calls, cp_chain.puts\n                    calls.columns  puts.columns  option_columns\n                    calls.set_index(\"Contract\", inplaceTrue)\n                    puts.set_index(\"Contract\", inplaceTrue)\n\n                    calls.name  f\"{ticker} Calls for {opt_date}\"\n                    puts.name  f\"{ticker} Puts for {opt_date}\"\n\n                    if isinstance(itm, bool):\n                        in_or_out  \"ITM\" if itm else \"OTM\"\n                        calls.name, puts.name  f\"{calls.name} {in_or_out}\", f\"{puts.name} {in_or_out}\"\n                        itm_calls  f\"{calls.name}\\n{calls[calls['ITM']  itm]}\"\n                        itm_puts  f\"{puts.name}\\n{puts[puts['ITM']  itm]}\"\n\n                        if    just_calls: print(itm_calls)\n                        elif  just_puts: print(itm_puts)\n                        else: print(f\"{itm_calls}\\n\\n{itm_puts}\")\n                    else:\n                        all_calls, all_puts  f\"{calls.name}\\n{calls}\", f\"{puts.name}\\n{puts}\"\n                        if    just_calls: print(all_calls)\n                        elif  just_puts: print(all_puts)\n                        else: print(f\"{all_calls}\\n\\n{all_puts}\")\n\n        if verbose:\n            print(\"\\n  Chart History        \" + div + f\"\\n[*] Pandas TA v{version} & yfinance v{yfra.__version__}\")\n            print(f\"[+] Downloading {ticker}[{interval}:{period}] from Yahoo Finance\")\n        if show is not None and isinstance(show, int) and show > 0:\n            print(f\"\\n{df.name}\\n{df.tail(show)}\\n\")\n        if verbose: print(\"\" * 80 + \"\\n\")\n        else: print()\n        return df\n\n    else:\n        return DataFrame()\n\n\n\n",
        "AgentRunResult(output='Este conteúdo pertence ao diretório pandas_ta/utils e inclui os arquivos _math.py, _metrics.py e _signals.py. Os tópicos abordados são: funções auxiliares matemáticas (_math.py), métricas financeiras como CAGR e Sharpe Ratio (_metrics.py) e geração de sinais de cruzamento e comparação de séries temporais (_signals.py). Tecnologias utilizadas incluem Numpy, Pandas e, opcionalmente, Scikit-Learn.')\npandas_ta/utils/_math.py\n\n# -*- coding: utf-8 -*-\nfrom functools import reduce\nfrom math import floor as mfloor\nfrom operator import mul\nfrom sys import float_info as sflt\nfrom typing import List, Optional, Tuple\n\nfrom numpy import ones, triu\nfrom numpy import all as npAll\nfrom numpy import append as npAppend\nfrom numpy import array as npArray\nfrom numpy import corrcoef as npCorrcoef\nfrom numpy import dot as npDot\nfrom numpy import fabs as npFabs\nfrom numpy import floor as npFloor\nfrom numpy import exp as npExp\nfrom numpy import log as npLog\nfrom numpy import NaN as npNaN\nfrom numpy import ndarray as npNdArray\nfrom numpy import seterr\nfrom numpy import sqrt as npSqrt\nfrom numpy import sum as npSum\n\nfrom pandas import DataFrame, Series\n\nfrom pandas_ta import Imports\nfrom ._core import verify_series\n\n\ndef combination(**kwargs: dict) -> int:\n    \"\"\"https://stackoverflow.com/questions/4941753/is-there-a-math-ncr-function-in-python\"\"\"\n    n  int(npFabs(kwargs.pop(\"n\", 1)))\n    r  int(npFabs(kwargs.pop(\"r\", 0)))\n\n    if kwargs.pop(\"repetition\", False) or kwargs.pop(\"multichoose\", False):\n        n  n + r - 1\n\n    # if r < 0: return None\n    r  min(n, n - r)\n    if r  0:\n        return 1\n\n    numerator  reduce(mul, range(n, n - r, -1), 1)\n    denominator  reduce(mul, range(1, r + 1), 1)\n    return numerator // denominator\n\n\ndef fibonacci(n: int  2, **kwargs: dict) -> npNdArray:\n    \"\"\"Fibonacci Sequence as a numpy array\"\"\"\n    n  int(npFabs(n)) if n > 0 else 2\n\n    zero  kwargs.pop(\"zero\", False)\n    if zero:\n        a, b  0, 1\n    else:\n        n - 1\n        a, b  1, 1\n\n    result  npArray([a])\n    for _ in range(0, n):\n        a, b  b, a + b\n        result  npAppend(result, a)\n\n    weighted  kwargs.pop(\"weighted\", False)\n    if weighted:\n        fib_sum  npSum(result)\n        if fib_sum > 0:\n            return result / fib_sum\n        else:\n            return result\n    else:\n        return result\n\n\ndef geometric_mean(series: Series) -> float:\n    \"\"\"Returns the Geometric Mean for a Series of positive values.\"\"\"\n    n  series.size\n    if n < 1:\n        return series.iloc[0]\n\n    has_zeros  0 in series.values\n    if has_zeros:\n        series  series.fillna(0) + 1\n    if npAll(series > 0):\n        mean  series.prod() ** (1 / n)\n        return mean if not has_zeros else mean - 1\n    return 0\n\n\ndef linear_regression(x: Series, y: Series) -> dict:\n    \"\"\"Classic Linear Regression in Numpy or Scikit-Learn\"\"\"\n    x, y  verify_series(x), verify_series(y)\n    m, n  x.size, y.size\n\n    if m ! n:\n        print(f\"[X] Linear Regression X and y have unequal total observations: {m} ! {n}\")\n        return {}\n\n    if Imports[\"sklearn\"]:\n        return _linear_regression_sklearn(x, y)\n    else:\n        return _linear_regression_np(x, y)\n\n\ndef log_geometric_mean(series: Series) -> float:\n    \"\"\"Returns the Logarithmic Geometric Mean\"\"\"\n    n  series.size\n    if n < 2: return 0\n    else:\n        series  series.fillna(0) + 1\n        if npAll(series > 0):\n            return npExp(npLog(series).sum() / n) - 1\n        return 0\n\n\ndef pascals_triangle(n: int  None, **kwargs: dict) -> npNdArray:\n    \"\"\"Pascal's Triangle\n\n    Returns a numpy array of the nth row of Pascal's Triangle.\n    n4  > triangle: [1, 4, 6, 4, 1]\n         > weighted: [0.0625, 0.25, 0.375, 0.25, 0.0625]\n         > inverse weighted: [0.9375, 0.75, 0.625, 0.75, 0.9375]\n    \"\"\"\n    n  int(npFabs(n)) if n is not None else 0\n\n    # Calculation\n    triangle  npArray([combination(nn, ri) for i in range(0, n + 1)])\n    triangle_sum  npSum(triangle)\n    triangle_weights  triangle / triangle_sum\n    inverse_weights  1 - triangle_weights\n\n    weighted  kwargs.pop(\"weighted\", False)\n    inverse  kwargs.pop(\"inverse\", False)\n    if weighted and inverse:\n        return inverse_weights\n    if weighted:\n        return triangle_weights\n    if inverse:\n        return None\n\n    return triangle\n\n\ndef symmetric_triangle(n: int  None, **kwargs: dict) -> Optional[List[int]]:\n    \"\"\"Symmetric Triangle with n > 2\n\n    Returns a numpy array of the nth row of Symmetric Triangle.\n    n4  > triangle: [1, 2, 2, 1]\n         > weighted: [0.16666667 0.33333333 0.33333333 0.16666667]\n    \"\"\"\n    n  int(npFabs(n)) if n is not None else 2\n\n    triangle  None\n    if n  2:\n        triangle  [1, 1]\n\n    if n > 2:\n        if n % 2  0:\n            front  [i + 1 for i in range(0, mfloor(n / 2))]\n            triangle  front + front[::-1]\n        else:\n            front  [i + 1 for i in range(0, mfloor(0.5 * (n + 1)))]\n            triangle  front.copy()\n            front.pop()\n            triangle + front[::-1]\n\n    if kwargs.pop(\"weighted\", False) and isinstance(triangle, list):\n        triangle_sum  npSum(triangle)\n        triangle_weights  triangle / triangle_sum\n        return triangle_weights\n\n    return triangle\n\n\ndef weights(w: npNdArray):\n    \"\"\"Calculates the dot product of weights with values x\"\"\"\n    def _dot(x):\n        return npDot(w, x)\n    return _dot\n\n\ndef zero(x: Tuple[int, float]) -> Tuple[int, float]:\n    \"\"\"If the value is close to zero, then return zero. Otherwise return itself.\"\"\"\n    return 0 if abs(x) < sflt.epsilon else x\n\n\n# TESTING\n\n\ndef df_error_analysis(dfA: DataFrame, dfB: DataFrame, **kwargs: dict) -> DataFrame:\n    \"\"\"DataFrame Correlation Analysis helper\"\"\"\n    corr_method  kwargs.pop(\"corr_method\", \"pearson\")\n\n    # Find their differences and correlation\n    diff  dfA - dfB\n    corr  dfA.corr(dfB, methodcorr_method)\n\n    # For plotting\n    if kwargs.pop(\"plot\", False):\n        diff.hist()\n        if diff[diff > 0].any():\n            diff.plot(kind\"kde\")\n\n    if kwargs.pop(\"triangular\", False):\n        return corr.where(triu(ones(corr.shape)).astype(bool))\n\n    return corr\n\n\n# PRIVATE\ndef _linear_regression_np(x: Series, y: Series) -> dict:\n    \"\"\"Simple Linear Regression in Numpy for two 1d arrays for environments without the sklearn package.\"\"\"\n    result  {\"a\": npNaN, \"b\": npNaN, \"r\": npNaN, \"t\": npNaN, \"line\": npNaN}\n    x_sum  x.sum()\n    y_sum  y.sum()\n\n    if int(x_sum) ! 0:\n        # 1st row, 2nd col value corr(x, y)\n        r  npCorrcoef(x, y)[0, 1]\n\n        m  x.size\n        r_mix  m * (x * y).sum() - x_sum * y_sum\n        b  r_mix // (m * (x * x).sum() - x_sum * x_sum)\n        a  y.mean() - b * x.mean()\n        line  a + b * x\n\n        _np_err  seterr()\n        seterr(divide\"ignore\", invalid\"ignore\")\n        result  {\n            \"a\": a, \"b\": b, \"r\": r,\n            \"t\": r / npSqrt((1 - r * r) / (m - 2)),\n            \"line\": line,\n        }\n        seterr(divide_np_err[\"divide\"], invalid_np_err[\"invalid\"])\n\n    return result\n\ndef _linear_regression_sklearn(x: Series, y: Series) -> dict:\n    \"\"\"Simple Linear Regression in Scikit Learn for two 1d arrays for\n    environments with the sklearn package.\"\"\"\n    from sklearn.linear_model import LinearRegression\n\n    X  DataFrame(x)\n    lr  LinearRegression().fit(X, yy)\n    r  lr.score(X, yy)\n    a, b  lr.intercept_, lr.coef_[0]\n\n    result  {\n        \"a\": a, \"b\": b, \"r\": r,\n        \"t\": r / npSqrt((1 - r * r) / (x.size - 2)),\n        \"line\": a + b * x\n    }\n    return result\n\n\n\npandas_ta/utils/_metrics.py\n\n# -*- coding: utf-8 -*-\nfrom typing import Tuple\n\nfrom numpy import log as npLog\nfrom numpy import NaN as npNaN\nfrom numpy import sqrt as npSqrt\nfrom pandas import Series, Timedelta\n\nfrom ._core import verify_series\nfrom ._time import total_time\nfrom ._math import linear_regression, log_geometric_mean\nfrom pandas_ta import RATE\nfrom pandas_ta.performance import drawdown, log_return, percent_return\n\n\ndef cagr(close: Series) -> float:\n    \"\"\"Compounded Annual Growth Rate\n\n    Args:\n        close (pd.Series): Series of 'close's\n\n    >>> result  ta.cagr(df.close)\n    \"\"\"\n    close  verify_series(close)\n    start, end  close.iloc[0], close.iloc[-1]\n    return ((end / start) ** (1 / total_time(close))) - 1\n\n\ndef calmar_ratio(close: Series, method: str  \"percent\", years: int  3) -> float:\n    \"\"\"The Calmar Ratio is the percent Max Drawdown Ratio 'typically' over\n    the past three years.\n\n    Args:\n        close (pd.Series): Series of 'close's\n        method (str): Max DD calculation options: 'dollar', 'percent', 'log'. Default: 'dollar'\n        years (int): The positive number of years to use. Default: 3\n\n    >>> result  ta.calmar_ratio(close, method\"percent\", years3)\n    \"\"\"\n    if years < 0:\n        print(f\"[!] calmar_ratio 'years' argument must be greater than zero.\")\n        return\n    close  verify_series(close)\n\n    n_years_ago  close.index[-1] - Timedelta(days365.25 * years)\n    close  close[close.index > n_years_ago]\n\n    return cagr(close) / max_drawdown(close, methodmethod)\n\n\ndef downside_deviation(returns: Series, benchmark_rate: float  0.0, tf: str  \"years\") -> float:\n    \"\"\"Downside Deviation for the Sortino ratio.\n    Benchmark rate is assumed to be annualized. Adjusted according for the\n    number of periods per year seen in the data.\n\n    Args:\n        close (pd.Series): Series of 'close's\n        benchmark_rate (float): Benchmark Rate to use. Default: 0.0\n        tf (str): Time Frame options: 'days', 'weeks', 'months', and 'years'. Default: 'years'\n\n    >>> result  ta.downside_deviation(returns, benchmark_rate0.0, tf\"years\")\n    \"\"\"\n    # For both de-annualizing the benchmark rate and annualizing result\n    returns  verify_series(returns)\n    days_per_year  returns.shape[0] / total_time(returns, tf)\n\n    adjusted_benchmark_rate  ((1 + benchmark_rate) ** (1 / days_per_year)) - 1\n\n    downside  adjusted_benchmark_rate - returns\n    downside_sum_of_squares  (downside[downside > 0] ** 2).sum()\n    downside_deviation  npSqrt(downside_sum_of_squares / (returns.shape[0] - 1))\n    return downside_deviation * npSqrt(days_per_year)\n\n\ndef jensens_alpha(returns: Series, benchmark_returns: Series) -> float:\n    \"\"\"Jensen's 'Alpha' of a series and a benchmark.\n\n    Args:\n        returns (pd.Series): Series of 'returns's\n        benchmark_returns (pd.Series): Series of 'benchmark_returns's\n\n    >>> result  ta.jensens_alpha(returns, benchmark_returns)\n    \"\"\"\n    returns  verify_series(returns)\n    benchmark_returns  verify_series(benchmark_returns)\n\n    benchmark_returns.interpolate(inplaceTrue)\n    return linear_regression(benchmark_returns, returns)[\"a\"]\n\n\ndef log_max_drawdown(close: Series) -> float:\n    \"\"\"Log Max Drawdown of a series.\n\n    Args:\n        close (pd.Series): Series of 'close's\n\n    >>> result  ta.log_max_drawdown(close)\n    \"\"\"\n    close  verify_series(close)\n    log_return  npLog(close.iloc[-1]) - npLog(close.iloc[0])\n    return log_return - max_drawdown(close, method\"log\")\n\n\ndef max_drawdown(close: Series, method:str  None, all:bool  False) -> float:\n    \"\"\"Maximum Drawdown from close. Default: 'dollar'.\n\n    Args:\n        close (pd.Series): Series of 'close's\n        method (str): Max DD calculation options: 'dollar', 'percent', 'log'. Default: 'dollar'\n        all (bool): If True, it returns all three methods as a dict. Default: False\n\n    >>> result  ta.max_drawdown(close, method\"dollar\", allFalse)\n    \"\"\"\n    close  verify_series(close)\n    max_dd  drawdown(close).max()\n\n    max_dd_  {\n        \"dollar\": max_dd.iloc[0],\n        \"percent\": max_dd.iloc[1],\n        \"log\": max_dd.iloc[2]\n    }\n    if all: return max_dd_\n\n    if isinstance(method, str) and method in max_dd_.keys():\n        return max_dd_[method]\n    return max_dd_[\"dollar\"]\n\n\ndef optimal_leverage(\n        close: Series, benchmark_rate: float  0.0,\n        period: Tuple[float, int]  RATE[\"TRADING_DAYS_PER_YEAR\"],\n        log: bool  False, capital: float  1., **kwargs\n    ) -> float:\n    \"\"\"Optimal Leverage of a series. NOTE: Incomplete. Do NOT use.\n\n    Args:\n        close (pd.Series): Series of 'close's\n        benchmark_rate (float): Benchmark Rate to use. Default: 0.0\n        period (int, float): Period to use to calculate Mean Annual Return and Annual Standard Deviation. Default: None or the default sharpe_ratio.period()\n        log (bool): If True, calculates log_return. Otherwise it returns percent_return. Default: False\n\n    >>> result  ta.optimal_leverage(close, benchmark_rate0.0, logFalse)\n    \"\"\"\n    close  verify_series(close)\n\n    use_cagr  kwargs.pop(\"use_cagr\", False)\n    returns  percent_return(closeclose) if not log else log_return(closeclose)\n    # sharpe  sharpe_ratio(close, benchmark_ratebenchmark_rate, loglog, use_cagruse_cagr, periodperiod)\n\n    period_mu  period * returns.mean()\n    period_std  npSqrt(period) * returns.std()\n\n    mean_excess_return  period_mu - benchmark_rate\n    # sharpe  mean_excess_return / period_std\n    opt_leverage  (period_std ** -2) * mean_excess_return\n\n    amount  int(capital * opt_leverage)\n    return amount\n\n\ndef pure_profit_score(close: Series) -> Tuple[float, int]:\n    \"\"\"Pure Profit Score of a series.\n\n    Args:\n        close (pd.Series): Series of 'close's\n\n    >>> result  ta.pure_profit_score(df.close)\n    \"\"\"\n    close  verify_series(close)\n    close_index  Series(0, indexclose.reset_index().index)\n\n    r  linear_regression(close_index, close)[\"r\"]\n    if r is not npNaN:\n        return r * cagr(close)\n    return 0\n\n\ndef sharpe_ratio(close: Series, benchmark_rate: float  0.0, log: bool  False, use_cagr: bool  False, period: int  RATE[\"TRADING_DAYS_PER_YEAR\"]) -> float:\n    \"\"\"Sharpe Ratio of a series.\n\n    Args:\n        close (pd.Series): Series of 'close's\n        benchmark_rate (float): Benchmark Rate to use. Default: 0.0\n        log (bool): If True, calculates log_return. Otherwise it returns percent_return. Default: False\n        use_cagr (bool): Use cagr - benchmark_rate instead. Default: False\n        period (int, float): Period to use to calculate Mean Annual Return and Annual Standard Deviation. Default: RATE[\"TRADING_DAYS_PER_YEAR\"] (currently 252)\n\n    >>> result  ta.sharpe_ratio(close, benchmark_rate0.0, logFalse)\n    \"\"\"\n    close  verify_series(close)\n    returns  percent_return(closeclose) if not log else log_return(closeclose)\n\n    if use_cagr:\n        return cagr(close) / volatility(close, returns, loglog)\n    else:\n        period_mu  period * returns.mean()\n        period_std  npSqrt(period) * returns.std()\n        return (period_mu - benchmark_rate) / period_std\n\n\ndef sortino_ratio(close: Series, benchmark_rate: float  0.0, log: bool  False) -> float:\n    \"\"\"Sortino Ratio of a series.\n\n    Args:\n        close (pd.Series): Series of 'close's\n        benchmark_rate (float): Benchmark Rate to use. Default: 0.0\n        log (bool): If True, calculates log_return. Otherwise it returns percent_return. Default: False\n\n    >>> result  ta.sortino_ratio(close, benchmark_rate0.0, logFalse)\n    \"\"\"\n    close  verify_series(close)\n    returns  percent_return(closeclose) if not log else log_return(closeclose)\n\n    result   cagr(close) - benchmark_rate\n    result / downside_deviation(returns)\n    return result\n\n\ndef volatility(close: Series, tf: str  \"years\", returns: bool  False, log: bool  False, **kwargs) -> float:\n    \"\"\"Volatility of a series. Default: 'years'\n\n    Args:\n        close (pd.Series): Series of 'close's\n        tf (str): Time Frame options: 'days', 'weeks', 'months', and 'years'. Default: 'years'\n        returns (bool): If True, then it replace the close Series with the user defined Series; typically user generated returns or percent returns or log returns. Default: False\n        log (bool): If True, calculates log_return. Otherwise it calculates percent_return. Default: False\n\n    >>> result  ta.volatility(close, tf\"years\", returnsFalse, logFalse, **kwargs)\n    \"\"\"\n    close  verify_series(close)\n\n    if not returns:\n        returns  percent_return(closeclose) if not log else log_return(closeclose)\n    else:\n        returns  close\n\n    returns  log_geometric_mean(returns).std()\n    # factor  returns.shape[0] / total_time(returns, tf)\n    # if kwargs.pop(\"nearest_day\", False) and tf.lower()  \"years\":\n        # factor  int(factor + 1)\n    # return npSqrt(factor) * returns.std()\n    return returns\n\n\n\npandas_ta/utils/_signals.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame, Series\n\nfrom ._core import get_offset, verify_series\nfrom ._math import zero\n\n\ndef _above_below(series_a: Series, series_b: Series, above: bool  True, asint: bool  True, offset: int  None, **kwargs):\n    series_a  verify_series(series_a)\n    series_b  verify_series(series_b)\n    offset  get_offset(offset)\n\n    series_a.apply(zero)\n    series_b.apply(zero)\n\n    # Calculate Result\n    if above:\n        current  series_a > series_b\n    else:\n        current  series_a < series_b\n\n    if asint:\n        current  current.astype(int)\n\n    # Offset\n    if offset ! 0:\n        current  current.shift(offset)\n\n    # Name & Category\n    current.name  f\"{series_a.name}_{'A' if above else 'B'}_{series_b.name}\"\n    current.category  \"utility\"\n\n    return current\n\n\ndef above(series_a: Series, series_b: Series, asint: bool  True, offset: int  None, **kwargs):\n    return _above_below(series_a, series_b, aboveTrue, asintasint, offsetoffset, **kwargs)\n\n\ndef above_value(series_a: Series, value: float, asint: bool  True, offset: int  None, **kwargs):\n    if not isinstance(value, (int, float, complex)):\n        print(\"[X] value is not a number\")\n        return\n    series_b  Series(value, indexseries_a.index, namef\"{value}\".replace(\".\", \"_\"))\n\n    return _above_below(series_a, series_b, aboveTrue, asintasint, offsetoffset, **kwargs)\n\n\ndef below(series_a: Series, series_b: Series, asint: bool  True, offset: int  None, **kwargs):\n    return _above_below(series_a, series_b, aboveFalse, asintasint, offsetoffset, **kwargs)\n\n\ndef below_value(series_a: Series, value: float, asint: bool  True, offset: int  None, **kwargs):\n    if not isinstance(value, (int, float, complex)):\n        print(\"[X] value is not a number\")\n        return\n    series_b  Series(value, indexseries_a.index, namef\"{value}\".replace(\".\", \"_\"))\n    return _above_below(series_a, series_b, aboveFalse, asintasint, offsetoffset, **kwargs)\n\n\ndef cross_value(series_a: Series, value: float, above: bool  True, asint: bool  True, offset: int  None, **kwargs):\n    series_b  Series(value, indexseries_a.index, namef\"{value}\".replace(\".\", \"_\"))\n\n    return cross(series_a, series_b, above, asint, offset, **kwargs)\n\n\ndef cross(series_a: Series, series_b: Series, above: bool  True, asint: bool  True, offset: int  None, **kwargs):\n    series_a  verify_series(series_a)\n    series_b  verify_series(series_b)\n    offset  get_offset(offset)\n\n    series_a.apply(zero)\n    series_b.apply(zero)\n\n    # Calculate Result\n    current  series_a > series_b  # current is above\n    previous  series_a.shift(1) < series_b.shift(1)  # previous is below\n    # above if both are true, below if both are false\n    cross  current & previous if above else ~current & ~previous\n\n    if asint:\n        cross  cross.astype(int)\n\n    # Offset\n    if offset ! 0:\n        cross  cross.shift(offset)\n\n    # Name & Category\n    cross.name  f\"{series_a.name}_{'XA' if above else 'XB'}_{series_b.name}\"\n    cross.category  \"utility\"\n\n    return cross\n\n\ndef signals(indicator, xa, xb, cross_values, xserie, xserie_a, xserie_b, cross_series, offset) -> DataFrame:\n    df  DataFrame()\n    if xa is not None and isinstance(xa, (int, float)):\n        if cross_values:\n            crossed_above_start  cross_value(indicator, xa, aboveTrue, offsetoffset)\n            crossed_above_end  cross_value(indicator, xa, aboveFalse, offsetoffset)\n            df[crossed_above_start.name]  crossed_above_start\n            df[crossed_above_end.name]  crossed_above_end\n        else:\n            crossed_above  above_value(indicator, xa, offsetoffset)\n            df[crossed_above.name]  crossed_above\n\n    if xb is not None and isinstance(xb, (int, float)):\n        if cross_values:\n            crossed_below_start  cross_value(indicator, xb, aboveTrue, offsetoffset)\n            crossed_below_end  cross_value(indicator, xb, aboveFalse, offsetoffset)\n            df[crossed_below_start.name]  crossed_below_start\n            df[crossed_below_end.name]  crossed_below_end\n        else:\n            crossed_below  below_value(indicator, xb, offsetoffset)\n            df[crossed_below.name]  crossed_below\n\n    # xseries is the default value for both xserie_a and xserie_b\n    if xserie_a is None:\n        xserie_a  xserie\n    if xserie_b is None:\n        xserie_b  xserie\n\n    if xserie_a is not None and verify_series(xserie_a):\n        if cross_series:\n            cross_serie_above  cross(indicator, xserie_a, aboveTrue, offsetoffset)\n        else:\n            cross_serie_above  above(indicator, xserie_a, offsetoffset)\n\n        df[cross_serie_above.name]  cross_serie_above\n\n    if xserie_b is not None and verify_series(xserie_b):\n        if cross_series:\n            cross_serie_below  cross(indicator, xserie_b, aboveFalse, offsetoffset)\n        else:\n            cross_serie_below  below(indicator, xserie_b, offsetoffset)\n\n        df[cross_serie_below.name]  cross_serie_below\n\n    return df\n\n\n\n",
        "AgentRunResult(output='Esse trecho abrange arquivos do diretório pandas_ta, que contém utilitários e indicadores de análise técnica no pacote Pandas TA. O arquivo utils/_time.py fornece funções auxiliares para manipulação de datas e cálculo de tempo relativo em DataFrames do Pandas. Já a subpasta volatility contém módulos que implementam diversos indicadores de volatilidade, como Aberration, Acceleration Bands (ACCBANDS), Average True Range (ATR), Bollinger Bands (BBANDS) e Donchian Channels. As tecnologias centrais envolvidas são Pandas, análise de séries temporais e cálculo de indicadores técnicos financeiros.')\npandas_ta/utils/_time.py\n\n# -*- coding: utf-8 -*-\nfrom datetime import datetime\nfrom time import localtime, perf_counter\nfrom typing import Tuple\n\nfrom pandas import DataFrame, DatetimeIndex, Timestamp\n\nfrom pandas_ta import EXCHANGE_TZ, RATE\nfrom pandas_ta.utils import verify_series\n\n\ndef df_dates(df: DataFrame, dates: Tuple[str, list]  None) -> DataFrame:\n    \"\"\"Yields the DataFrame with the given dates\"\"\"\n    if dates is None: return None\n    if not isinstance(dates, list):\n        dates  [dates]\n    return df[df.index.isin(dates)]\n\n\ndef df_month_to_date(df: DataFrame) -> DataFrame:\n    \"\"\"Yields the Month-to-Date (MTD) DataFrame\"\"\"\n    return df[df.index > Timestamp.now().strftime(\"%Y-%m-01\")]\n\n\ndef df_quarter_to_date(df: DataFrame) -> DataFrame:\n    \"\"\"Yields the Quarter-to-Date (QTD) DataFrame\"\"\"\n    now  Timestamp.now()\n    for m in [1, 4, 7, 10]:\n        if now.month < m:\n            return df[df.index > datetime(now.year, m, 1).strftime(\"%Y-%m-01\")]\n    return df[df.index > now.strftime(\"%Y-%m-01\")]\n\n\ndef df_year_to_date(df: DataFrame) -> DataFrame:\n    \"\"\"Yields the Year-to-Date (YTD) DataFrame\"\"\"\n    return df[df.index > Timestamp.now().strftime(\"%Y-01-01\")]\n\n\ndef final_time(stime: float) -> str:\n    \"\"\"Human readable elapsed time. Calculates the final time elasped since\n    stime and returns a string with microseconds and seconds.\"\"\"\n    time_diff  perf_counter() - stime\n    return f\"{time_diff * 1000:2.4f} ms ({time_diff:2.4f} s)\"\n\n\ndef get_time(exchange: str  \"NYSE\", full:bool  True, to_string:bool  False) -> Tuple[None, str]:\n    \"\"\"Returns Current Time, Day of the Year and Percentage, and the current\n    time of the selected Exchange.\"\"\"\n    tz  EXCHANGE_TZ[\"NYSE\"] # Default is NYSE (Eastern Time Zone)\n    if isinstance(exchange, str):\n        exchange  exchange.upper()\n        tz  EXCHANGE_TZ[exchange]\n\n    # today  Timestamp.utcnow()\n    today  Timestamp.now()\n    date  f\"{today.day_name()} {today.month_name()} {today.day}, {today.year}\"\n\n    _today  today.timetuple()\n    exchange_time  f\"{(_today.tm_hour + tz) % 24}:{_today.tm_min:02d}:{_today.tm_sec:02d}\"\n\n    if full:\n        lt  localtime()\n        local_  f\"Local: {lt.tm_hour}:{lt.tm_min:02d}:{lt.tm_sec:02d} {lt.tm_zone}\"\n        doy  f\"Day {today.dayofyear}/365 ({100 * round(today.dayofyear/365, 2)}%)\"\n        exchange_  f\"{exchange}: {exchange_time}\"\n\n        s  f\"{date}, {exchange_}, {local_}, {doy}\"\n    else:\n        s  f\"{exchange}: {exchange_time}\"\n\n    return s if to_string else print(s)\n\n\ndef total_time(df: DataFrame, tf: str  \"years\") -> float:\n    \"\"\"Calculates the total time of a DataFrame. Difference of the Last and\n    First index. Options: 'months', 'weeks', 'days', 'hours', 'minutes'\n    and 'seconds'. Default: 'years'.\n    Useful for annualization.\"\"\"\n    time_diff  df.index[-1] - df.index[0]\n    TimeFrame  {\n        \"years\": time_diff.days / RATE[\"TRADING_DAYS_PER_YEAR\"],\n        \"months\": time_diff.days / 30.417,\n        \"weeks\": time_diff.days / 7,\n        \"days\": time_diff.days,\n        \"hours\": time_diff.days * 24,\n        \"minutes\": time_diff.total_seconds() / 60,\n        \"seconds\": time_diff.total_seconds()\n    }\n\n    if isinstance(tf, str) and tf in TimeFrame.keys():\n        return TimeFrame[tf]\n    return TimeFrame[\"years\"]\n\n\ndef to_utc(df: DataFrame) -> DataFrame:\n    \"\"\"Either localizes the DataFrame Index to UTC or it applies\n    tz_convert to set the Index to UTC.\n    \"\"\"\n    if not df.empty:\n        try:\n            df.index  df.index.tz_localize(\"UTC\")\n        except TypeError:\n            df.index  df.index.tz_convert(\"UTC\")\n    return df\n\n\n# Aliases\nmtd_df  df_month_to_date\nqtd_df  df_quarter_to_date\nytd_df  df_year_to_date\n\n\npandas_ta/volatility/__init__.py\n\n# -*- coding: utf-8 -*-\nfrom .aberration import aberration\nfrom .accbands import accbands\nfrom .atr import atr\nfrom .bbands import bbands\nfrom .donchian import donchian\nfrom .hwc import hwc\nfrom .kc import kc\nfrom .massi import massi\nfrom .pdist import pdist\nfrom .natr import natr\nfrom .rvi import rvi\nfrom .thermo import thermo\nfrom .true_range import true_range\nfrom .ui import ui\n\n\n\npandas_ta/volatility/aberration.py\n\n# -*- coding: utf-8 -*-\n# from numpy import sqrt as npsqrt\nfrom pandas import DataFrame\nfrom .atr import atr\nfrom pandas_ta.overlap import hlc3, sma\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef aberration(high, low, close, lengthNone, atr_lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Aberration (ABER)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 5\n    atr_length  int(atr_length) if atr_length and atr_length > 0 else 15\n    _length  max(atr_length, length)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    atr_  atr(highhigh, lowlow, closeclose, lengthatr_length)\n    jg  hlc3(highhigh, lowlow, closeclose)\n\n    zg  sma(jg, length)\n    sg  zg + atr_\n    xg  zg - atr_\n\n    # Offset\n    if offset ! 0:\n        zg  zg.shift(offset)\n        sg  sg.shift(offset)\n        xg  xg.shift(offset)\n        atr_  atr_.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        zg.fillna(kwargs[\"fillna\"], inplaceTrue)\n        sg.fillna(kwargs[\"fillna\"], inplaceTrue)\n        xg.fillna(kwargs[\"fillna\"], inplaceTrue)\n        atr_.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        zg.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        sg.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        xg.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        atr_.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _props  f\"_{length}_{atr_length}\"\n    zg.name  f\"ABER_ZG{_props}\"\n    sg.name  f\"ABER_SG{_props}\"\n    xg.name  f\"ABER_XG{_props}\"\n    atr_.name  f\"ABER_ATR{_props}\"\n    zg.category  sg.category  \"volatility\"\n    xg.category  atr_.category  zg.category\n\n    # Prepare DataFrame to return\n    data  {zg.name: zg, sg.name: sg, xg.name: xg, atr_.name: atr_}\n    aberdf  DataFrame(data)\n    aberdf.name  f\"ABER{_props}\"\n    aberdf.category  zg.category\n\n    return aberdf\n\n\naberration.__doc__  \\\n\"\"\"Aberration\n\nA volatility indicator similar to Keltner Channels.\n\nSources:\n    Few internet resources on definitive definition.\n    Request by Github user homily, issue #46\n\nCalculation:\n    Default Inputs:\n        length5, atr_length15\n    ATR  Average True Range\n    SMA  Simple Moving Average\n\n    ATR  ATR(lengthatr_length)\n    JG  TP  HLC3(high, low, close)\n    ZG  SMA(JG, length)\n    SG  ZG + ATR\n    XG  ZG - ATR\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): The short period. Default: 5\n    atr_length (int): The short period. Default: 15\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: zg, sg, xg, atr columns.\n\"\"\"\n\n\n\npandas_ta/volatility/accbands.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import ma\nfrom pandas_ta.utils import get_drift, get_offset, non_zero_range, verify_series\n\n\ndef accbands(high, low, close, lengthNone, cNone, driftNone, mamodeNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Acceleration Bands (ACCBANDS)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 20\n    c  float(c) if c and c > 0 else 4\n    mamode  mamode if isinstance(mamode, str) else \"sma\"\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    high_low_range  non_zero_range(high, low)\n    hl_ratio  high_low_range / (high + low)\n    hl_ratio * c\n    _lower  low * (1 - hl_ratio)\n    _upper  high * (1 + hl_ratio)\n\n    lower  ma(mamode, _lower, lengthlength)\n    mid  ma(mamode, close, lengthlength)\n    upper  ma(mamode, _upper, lengthlength)\n\n    # Offset\n    if offset ! 0:\n        lower  lower.shift(offset)\n        mid  mid.shift(offset)\n        upper  upper.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        lower.fillna(kwargs[\"fillna\"], inplaceTrue)\n        mid.fillna(kwargs[\"fillna\"], inplaceTrue)\n        upper.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        lower.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        mid.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        upper.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    lower.name  f\"ACCBL_{length}\"\n    mid.name  f\"ACCBM_{length}\"\n    upper.name  f\"ACCBU_{length}\"\n    mid.category  upper.category  lower.category  \"volatility\"\n\n    # Prepare DataFrame to return\n    data  {lower.name: lower, mid.name: mid, upper.name: upper}\n    accbandsdf  DataFrame(data)\n    accbandsdf.name  f\"ACCBANDS_{length}\"\n    accbandsdf.category  mid.category\n\n    return accbandsdf\n\n\naccbands.__doc__  \\\n\"\"\"Acceleration Bands (ACCBANDS)\n\nAcceleration Bands created by Price Headley plots upper and lower envelope\nbands around a simple moving average.\n\nSources:\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/acceleration-bands-abands/\n\nCalculation:\n    Default Inputs:\n        length10, c4\n    EMA  Exponential Moving Average\n    SMA  Simple Moving Average\n    HL_RATIO  c * (high - low) / (high + low)\n    LOW  low * (1 - HL_RATIO)\n    HIGH  high * (1 + HL_RATIO)\n\n    if 'ema':\n        LOWER  EMA(LOW, length)\n        MID  EMA(close, length)\n        UPPER  EMA(HIGH, length)\n    else:\n        LOWER  SMA(LOW, length)\n        MID  SMA(close, length)\n        UPPER  SMA(HIGH, length)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 10\n    c (int): Multiplier. Default: 4\n    mamode (str): Two options: None or 'ema'. Default: 'ema'\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: lower, mid, upper columns.\n\"\"\"\n\n\n\npandas_ta/volatility/atr.py\n\n# -*- coding: utf-8 -*-\nfrom .true_range import true_range\nfrom pandas_ta.overlap import ma\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef atr(high, low, close, lengthNone, mamodeNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Average True Range (ATR)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 14\n    mamode  mamode.lower() if mamode and isinstance(mamode, str) else \"rma\"\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    tr  true_range(highhigh, lowlow, closeclose, driftdrift)\n    atr  ma(mamode, tr, lengthlength)\n\n    percentage  kwargs.pop(\"percent\", False)\n    if percentage:\n        atr * 100 / close\n\n    # Offset\n    if offset ! 0:\n        atr  atr.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        atr.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        atr.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    atr.name  f\"ATR{mamode[0]}_{length}{'p' if percentage else ''}\"\n    atr.category  \"volatility\"\n\n    return atr\n\n\natr.__doc__  \\\n\"\"\"Average True Range (ATR)\n\nAverge True Range is used to measure volatility, especially volatility caused by\ngaps or limit moves.\n\nSources:\n    https://www.tradingview.com/wiki/Average_True_Range_(ATR)\n\nCalculation:\n    Default Inputs:\n        length14, drift1, percentFalse\n    EMA  Exponential Moving Average\n    SMA  Simple Moving Average\n    WMA  Weighted Moving Average\n    RMA  WildeR's Moving Average\n    TR  True Range\n\n    tr  TR(high, low, close, drift)\n    if 'ema':\n        ATR  EMA(tr, length)\n    elif 'sma':\n        ATR  SMA(tr, length)\n    elif 'wma':\n        ATR  WMA(tr, length)\n    else:\n        ATR  RMA(tr, length)\n\n    if percent:\n        ATR * 100 / close\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): It's period. Default: 14\n    mamode (str): \"sma\", \"ema\", \"wma\" or \"rma\". Default: \"rma\"\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    percent (bool, optional): Return as percentage. Default: False\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volatility/bbands.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import ma\nfrom pandas_ta.statistics import stdev\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef bbands(close, lengthNone, stdNone, mamodeNone, ddof0, offsetNone, **kwargs):\n    \"\"\"Indicator: Bollinger Bands (BBANDS)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 5\n    std  float(std) if std and std > 0 else 2.0\n    mamode  mamode if isinstance(mamode, str) else \"sma\"\n    ddof  int(ddof) if ddof > 0 and ddof < length else 1\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    standard_deviation  stdev(closeclose, lengthlength, ddofddof)\n    deviations  std * standard_deviation\n\n    mid  ma(mamode, close, lengthlength, **kwargs)\n    lower  mid - deviations\n    upper  mid + deviations\n\n    bandwidth  100 * (upper - lower) / mid\n\n    # Offset\n    if offset ! 0:\n        lower  lower.shift(offset)\n        mid  mid.shift(offset)\n        upper  upper.shift(offset)\n        bandwidth  bandwidth.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        lower.fillna(kwargs[\"fillna\"], inplaceTrue)\n        mid.fillna(kwargs[\"fillna\"], inplaceTrue)\n        upper.fillna(kwargs[\"fillna\"], inplaceTrue)\n        bandwidth.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        lower.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        mid.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        upper.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        bandwidth.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    lower.name  f\"BBL_{length}_{std}\"\n    mid.name  f\"BBM_{length}_{std}\"\n    upper.name  f\"BBU_{length}_{std}\"\n    bandwidth.name  f\"BBB_{length}_{std}\"\n    upper.category  lower.category  \"volatility\"\n    mid.category  bandwidth.category  upper.category\n\n    # Prepare DataFrame to return\n    data  {\n        lower.name: lower, mid.name: mid,\n        upper.name: upper, bandwidth.name: bandwidth\n    }\n    bbandsdf  DataFrame(data)\n    bbandsdf.name  f\"BBANDS_{length}_{std}\"\n    bbandsdf.category  mid.category\n\n    return bbandsdf\n\n\nbbands.__doc__  \\\n\"\"\"Bollinger Bands (BBANDS)\n\nA popular volatility indicator.\n\nSources:\n    https://www.tradingview.com/wiki/Bollinger_Bands_(BB)\n\nCalculation:\n    Default Inputs:\n        length5, std2, mamode\"sma\", ddof0\n    EMA  Exponential Moving Average\n    SMA  Simple Moving Average\n    STDEV  Standard Deviation\n    stdev  STDEV(close, length, ddof)\n    if \"ema\":\n        MID  EMA(close, length)\n    else:\n        MID  SMA(close, length)\n\n    LOWER  MID - std * stdev\n    UPPER  MID + std * stdev\n\n    BANDWIDTH  100 * (UPPER - LOWER) / MID\n\nArgs:\n    close (pd.Series): Series of 'close's\n    length (int): The short period. Default: 5\n    std (int): The long period. Default: 2\n    mamode (str): Two options: \"sma\" or \"ema\". Default: \"sma\"\n    ddof (int): Degrees of Freedom to use. Default: 0\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: lower, mid, upper, bandwidth columns.\n\"\"\"\n\n\n\npandas_ta/volatility/donchian.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef donchian(high, low, lower_lengthNone, upper_lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Donchian Channels (DC)\"\"\"\n    # Validate arguments\n    lower_length  int(lower_length) if lower_length and lower_length > 0 else 20\n    upper_length  int(upper_length) if upper_length and upper_length > 0 else 20\n    lower_min_periods  int(kwargs[\"lower_min_periods\"]) if \"lower_min_periods\" in kwargs and kwargs[\"lower_min_periods\"] is not None else lower_length\n    upper_min_periods  int(kwargs[\"upper_min_periods\"]) if \"upper_min_periods\" in kwargs and kwargs[\"upper_min_periods\"] is not None else upper_length\n    _length  max(lower_length, lower_min_periods, upper_length, upper_min_periods)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    offset  get_offset(offset)\n\n    if high is None or low is None: return\n\n    # Calculate Result\n    lower  low.rolling(lower_length, min_periodslower_min_periods).min()\n    upper  high.rolling(upper_length, min_periodsupper_min_periods).max()\n    mid  0.5 * (lower + upper)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        lower.fillna(kwargs[\"fillna\"], inplaceTrue)\n        mid.fillna(kwargs[\"fillna\"], inplaceTrue)\n        upper.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        lower.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        mid.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        upper.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Offset\n    if offset ! 0:\n        lower  lower.shift(offset)\n        mid  mid.shift(offset)\n        upper  upper.shift(offset)\n\n    # Name and Categorize it\n    lower.name  f\"DCL_{lower_length}_{upper_length}\"\n    mid.name  f\"DCM_{lower_length}_{upper_length}\"\n    upper.name  f\"DCU_{lower_length}_{upper_length}\"\n    mid.category  upper.category  lower.category  \"volatility\"\n\n    # Prepare DataFrame to return\n    data  {lower.name: lower, mid.name: mid, upper.name: upper}\n    dcdf  DataFrame(data)\n    dcdf.name  f\"DC_{lower_length}_{upper_length}\"\n    dcdf.category  mid.category\n\n    return dcdf\n\n\ndonchian.__doc__  \\\n\"\"\"Donchian Channels (DC)\n\nDonchian Channels are used to measure volatility, similar to\nBollinger Bands and Keltner Channels.\n\nSources:\n    https://www.tradingview.com/wiki/Donchian_Channels_(DC)\n\nCalculation:\n    Default Inputs:\n        lower_lengthupper_length20\n    LOWER  low.rolling(lower_length).min()\n    UPPER  high.rolling(upper_length).max()\n    MID  0.5 * (LOWER + UPPER)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    lower_length (int): The short period. Default: 20\n    upper_length (int): The short period. Default: 20\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: lower, mid, upper columns.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Context: This document is from the pandas_ta/volatility directory of the pandas_ta library, which contains Python implementations of various volatility technical indicators for financial time series analysis.\\n\\nMain topics and technologies: The files implement technical analysis indicators such as Holt-Winter Channel (hwc.py), Keltner Channels (kc.py), Mass Index (massi.py), Normalized Average True Range (natr.py), Price Distance (pdist.py), and Relative Volatility Index (rvi.py). Technologies used include pandas, numpy, and mathematical/statistical calculations commonly used in financial market analysis.')\npandas_ta/volatility/hwc.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import sqrt as npSqrt\nfrom pandas import DataFrame, Series\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef hwc(close, naNone, nbNone, ncNone, ndNone, scalarNone, channel_evalNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Holt-Winter Channel\"\"\"\n    # Validate Arguments\n    na  float(na) if na and na > 0 else 0.2\n    nb  float(nb) if nb and nb > 0 else 0.1\n    nc  float(nc) if nc and nc > 0 else 0.1\n    nd  float(nd) if nd and nd > 0 else 0.1\n    scalar  float(scalar) if scalar and scalar > 0 else 1\n    channel_eval  bool(channel_eval) if channel_eval and channel_eval else False\n    close  verify_series(close)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    last_a  last_v  last_var  0\n    last_f  last_price  last_result  close[0]\n    lower, result, upper  [], [], []\n    chan_pct_width, chan_width  [], []\n\n    m  close.size\n    for i in range(m):\n        F  (1.0 - na) * (last_f + last_v + 0.5 * last_a) + na * close[i]\n        V  (1.0 - nb) * (last_v + last_a) + nb * (F - last_f)\n        A  (1.0 - nc) * last_a + nc * (V - last_v)\n        result.append((F + V + 0.5 * A))\n\n        var  (1.0 - nd) * last_var + nd * (last_price - last_result) * (last_price - last_result)\n        stddev  npSqrt(last_var)\n        upper.append(result[i] + scalar * stddev)\n        lower.append(result[i] - scalar * stddev)\n\n        if channel_eval:\n            # channel width\n            chan_width.append(upper[i] - lower[i])\n            # channel percentage price position\n            chan_pct_width.append((close[i] - lower[i]) / (upper[i] - lower[i]))\n            # print('channel_eval (width|percentageWidth):', chan_width[i], chan_pct_width[i])\n\n        # update values\n        last_price  close[i]\n        last_a  A\n        last_f  F\n        last_v  V\n        last_var  var\n        last_result  result[i]\n\n    # Aggregate\n    hwc  Series(result, indexclose.index)\n    hwc_upper  Series(upper, indexclose.index)\n    hwc_lower  Series(lower, indexclose.index)\n    if channel_eval:\n        hwc_width  Series(chan_width, indexclose.index)\n        hwc_pctwidth  Series(chan_pct_width, indexclose.index)\n\n    # Offset\n    if offset ! 0:\n        hwc  hwc.shift(offset)\n        hwc_upper  hwc_upper.shift(offset)\n        hwc_lower  hwc_lower.shift(offset)\n        if channel_eval:\n            hwc_width  hwc_width.shift(offset)\n            hwc_pctwidth  hwc_pctwidth.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        hwc.fillna(kwargs[\"fillna\"], inplaceTrue)\n        hwc_upper.fillna(kwargs[\"fillna\"], inplaceTrue)\n        hwc_lower.fillna(kwargs[\"fillna\"], inplaceTrue)\n        if channel_eval:\n            hwc_width.fillna(kwargs[\"fillna\"], inplaceTrue)\n            hwc_pctwidth.fillna(kwargs[\"fillna\"], inplaceTrue)\n\n    if \"fill_method\" in kwargs:\n        hwc.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        hwc_upper.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        hwc_lower.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        if channel_eval:\n            hwc_width.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n            hwc_pctwidth.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    # suffix  f'{str(na).replace(\".\", \"\")}-{str(nb).replace(\".\", \"\")}-{str(nc).replace(\".\", \"\")}'\n    hwc.name  'HW-MID'\n    hwc_upper.name  \"HW-UPPER\"\n    hwc_lower.name  \"HW-LOWER\"\n    hwc.category  hwc_upper.category  hwc_lower.category  \"volatility\"\n    if channel_eval:\n        hwc_width.name  'HW-WIDTH'\n        hwc_pctwidth.name  'HW-PCTW'\n\n    # Prepare DataFrame to return\n    if channel_eval:\n        data  {hwc.name: hwc, hwc_upper.name: hwc_upper, hwc_lower.name: hwc_lower,\n                hwc_width.name: hwc_width, hwc_pctwidth.name: hwc_pctwidth}\n        df  DataFrame(data)\n        df.name  \"hwc\"\n        df.category  hwc.category\n    else:\n        data  {hwc.name: hwc, hwc_upper.name: hwc_upper, hwc_lower.name: hwc_lower}\n        df  DataFrame(data)\n        df.name  \"hwc\"\n        df.category  hwc.category\n\n    return df\n\n\n\nhwc.__doc__  \\\n\"\"\"HWC (Holt-Winter Channel)\n\nChannel indicator HWC (Holt-Winters Channel) based on HWMA - a three-parameter\nmoving average calculated by the method of Holt-Winters.\n\nThis version has been implemented for Pandas TA by rengel8 based on a\npublication for MetaTrader 5 extended by width and percentage price position\nagainst width of channel.\n\nSources:\n    https://www.mql5.com/en/code/20857\n\nCalculation:\n    HWMA[i]  F[i] + V[i] + 0.5 * A[i]\n    where..\n    F[i]  (1-na) * (F[i-1] + V[i-1] + 0.5 * A[i-1]) + na * Price[i]\n    V[i]  (1-nb) * (V[i-1] + A[i-1]) + nb * (F[i] - F[i-1])\n    A[i]  (1-nc) * A[i-1] + nc * (V[i] - V[i-1])\n\n    Top  HWMA + Multiplier * StDt\n    Bottom  HWMA - Multiplier * StDt\n    where..\n    StDt[i]  Sqrt(Var[i-1])\n    Var[i]  (1-d) * Var[i-1] + nD * (Price[i-1] - HWMA[i-1]) * (Price[i-1] - HWMA[i-1])\n\nArgs:\n    na - parameter of the equation that describes a smoothed series (from 0 to 1)\n    nb - parameter of the equation to assess the trend (from 0 to 1)\n    nc - parameter of the equation to assess seasonality (from 0 to 1)\n    nd - parameter of the channel equation (from 0 to 1)\n    scaler - multiplier for the width of the channel calculated\n    channel_eval - boolean to return width and percentage price position against price\n    close (pd.Series): Series of 'close's\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\nReturns:\n    pd.DataFrame: HW-MID, HW-UPPER, HW-LOWER columns.\n\"\"\"\n\n\n\npandas_ta/volatility/kc.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom .true_range import true_range\nfrom pandas_ta.overlap import ma\nfrom pandas_ta.utils import get_offset, high_low_range, verify_series\n\n\ndef kc(high, low, close, lengthNone, scalarNone, mamodeNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Keltner Channels (KC)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 20\n    scalar  float(scalar) if scalar and scalar > 0 else 2\n    mamode  mamode if isinstance(mamode, str) else \"ema\"\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    use_tr  kwargs.pop(\"tr\", True)\n    if use_tr:\n        range_  true_range(high, low, close)\n    else:\n        range_  high_low_range(high, low)\n\n    basis  ma(mamode, close, lengthlength)\n    band  ma(mamode, range_, lengthlength)\n\n    lower  basis - scalar * band\n    upper  basis + scalar * band\n\n    # Offset\n    if offset ! 0:\n        lower  lower.shift(offset)\n        basis  basis.shift(offset)\n        upper  upper.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        lower.fillna(kwargs[\"fillna\"], inplaceTrue)\n        basis.fillna(kwargs[\"fillna\"], inplaceTrue)\n        upper.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        lower.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        basis.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        upper.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _props  f\"{mamode.lower()[0] if len(mamode) else ''}_{length}_{scalar}\"\n    lower.name  f\"KCL{_props}\"\n    basis.name  f\"KCB{_props}\"\n    upper.name  f\"KCU{_props}\"\n    basis.category  upper.category  lower.category  \"volatility\"\n\n    # Prepare DataFrame to return\n    data  {lower.name: lower, basis.name: basis, upper.name: upper}\n    kcdf  DataFrame(data)\n    kcdf.name  f\"KC{_props}\"\n    kcdf.category  basis.category\n\n    return kcdf\n\n\nkc.__doc__  \\\n\"\"\"Keltner Channels (KC)\n\nA popular volatility indicator similar to Bollinger Bands and\nDonchian Channels.\n\nSources:\n    https://www.tradingview.com/wiki/Keltner_Channels_(KC)\n\nCalculation:\n    Default Inputs:\n        length20, scalar2, mamodeNone, trTrue\n    TR  True Range\n    SMA  Simple Moving Average\n    EMA  Exponential Moving Average\n\n    if tr:\n        RANGE  TR(high, low, close)\n    else:\n        RANGE  high - low\n\n    if mamode  \"ema\":\n        BASIS  sma(close, length)\n        BAND  sma(RANGE, length)\n    elif mamode  \"sma\":\n        BASIS  sma(close, length)\n        BAND  sma(RANGE, length)\n\n    LOWER  BASIS - scalar * BAND\n    UPPER  BASIS + scalar * BAND\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): The short period.  Default: 20\n    scalar (float): A positive float to scale the bands. Default: 2\n    mamode (str): Two options: \"sma\" or \"ema\". Default: \"ema\"\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    tr (bool): When True, it uses True Range for calculation. When False, use a\n        high - low as it's range calculation. Default: True\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: lower, basis, upper columns.\n\"\"\"\n\n\n\npandas_ta/volatility/massi.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import ema\nfrom pandas_ta.utils import get_offset, non_zero_range, verify_series\n\n\ndef massi(high, low, fastNone, slowNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Mass Index (MASSI)\"\"\"\n    # Validate arguments\n    fast  int(fast) if fast and fast > 0 else 9\n    slow  int(slow) if slow and slow > 0 else 25\n    if slow < fast:\n        fast, slow  slow, fast\n    _length  max(fast, slow)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    offset  get_offset(offset)\n    if \"length\" in kwargs: kwargs.pop(\"length\")\n\n    if high is None or low is None: return\n\n    # Calculate Result\n    high_low_range  non_zero_range(high, low)\n    hl_ema1  ema(closehigh_low_range, lengthfast, **kwargs)\n    hl_ema2  ema(closehl_ema1, lengthfast, **kwargs)\n\n    hl_ratio  hl_ema1 / hl_ema2\n    massi  hl_ratio.rolling(slow, min_periodsslow).sum()\n\n    # Offset\n    if offset ! 0:\n        massi  massi.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        massi.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        massi.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    massi.name  f\"MASSI_{fast}_{slow}\"\n    massi.category  \"volatility\"\n\n    return massi\n\n\nmassi.__doc__  \\\n\"\"\"Mass Index (MASSI)\n\nThe Mass Index is a non-directional volatility indicator that utilitizes the\nHigh-Low Range to identify trend reversals based on range expansions.\n\nSources:\n    https://stockcharts.com/school/doku.php?idchart_school:technical_indicators:mass_index\n    mi  sum(ema(high - low, 9) / ema(ema(high - low, 9), 9), length)\n\nCalculation:\n    Default Inputs:\n        fast: 9, slow: 25\n    EMA  Exponential Moving Average\n    hl  high - low\n    hl_ema1  EMA(hl, fast)\n    hl_ema2  EMA(hl_ema1, fast)\n    hl_ratio  hl_ema1 / hl_ema2\n    MASSI  SUM(hl_ratio, slow)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    fast (int): The short period. Default: 9\n    slow (int): The long period. Default: 25\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volatility/natr.py\n\n# -*- coding: utf-8 -*-\nfrom .atr import atr\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef natr(high, low, close, lengthNone, mamodeNone, scalarNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Normalized Average True Range (NATR)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 14\n    mamode  mamode if isinstance(mamode, str) else \"ema\"\n    scalar  float(scalar) if scalar else 100\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None: return\n\n    # Calculate Result\n    natr  scalar / close\n    natr * atr(highhigh, lowlow, closeclose, lengthlength, mamodemamode, driftdrift, offsetoffset, **kwargs)\n\n    # Offset\n    if offset ! 0:\n        natr  natr.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        natr.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        natr.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    natr.name  f\"NATR_{length}\"\n    natr.category  \"volatility\"\n\n    return natr\n\n\nnatr.__doc__  \\\n\"\"\"Normalized Average True Range (NATR)\n\nNormalized Average True Range attempt to normalize the average true range.\n\nSources:\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/normalized-average-true-range-natr/\n\nCalculation:\n    Default Inputs:\n        length20\n    ATR  Average True Range\n    NATR  (100 / close) * ATR(high, low, close)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): The short period. Default: 20\n    scalar (float): How much to magnify. Default: 100\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature\n\"\"\"\n\n\n\npandas_ta/volatility/pdist.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_drift, get_offset, non_zero_range, verify_series\n\n\ndef pdist(open_, high, low, close, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Price Distance (PDIST)\"\"\"\n    # Validate Arguments\n    open_  verify_series(open_)\n    high  verify_series(high)\n    low  verify_series(low)\n    close  verify_series(close)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    pdist  2 * non_zero_range(high, low)\n    pdist + non_zero_range(open_, close.shift(drift)).abs()\n    pdist - non_zero_range(close, open_).abs()\n\n    # Offset\n    if offset ! 0:\n        pdist  pdist.shift(offset)\n\n    # Name & Category\n    pdist.name  \"PDIST\"\n    pdist.category  \"volatility\"\n\n    return pdist\n\n\npdist.__doc__  \\\n\"\"\"Price Distance (PDIST)\n\nMeasures the \"distance\" covered by price movements.\n\nSources:\n    https://www.prorealcode.com/prorealtime-indicators/pricedistance/\n\nCalculation:\n    Default Inputs:\n        drift1\n\n    PDIST  2(high - low) - ABS(close - open) + ABS(open - close[drift])\n\nArgs:\n    open_ (pd.Series): Series of 'opens's\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volatility/rvi.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import ma\nfrom pandas_ta.statistics import stdev\nfrom pandas_ta.utils import get_drift, get_offset\nfrom pandas_ta.utils import unsigned_differences, verify_series\n\n\ndef rvi(close, highNone, lowNone, lengthNone, scalarNone, refinedNone, thirdsNone, mamodeNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Relative Volatility Index (RVI)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 14\n    scalar  float(scalar) if scalar and scalar > 0 else 100\n    refined  False if refined is None else refined\n    thirds  False if thirds is None else thirds\n    mamode  mamode if isinstance(mamode, str) else \"ema\"\n    close  verify_series(close, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    if refined or thirds:\n        high  verify_series(high)\n        low  verify_series(low)\n\n    # Calculate Result\n    def _rvi(source, length, scalar, mode, drift):\n        \"\"\"RVI\"\"\"\n        std  stdev(source, length)\n        pos, neg  unsigned_differences(source, amountdrift)\n\n        pos_std  pos * std\n        neg_std  neg * std\n\n        pos_avg  ma(mode, pos_std, lengthlength)\n        neg_avg  ma(mode, neg_std, lengthlength)\n\n        result  scalar * pos_avg\n        result / pos_avg + neg_avg\n        return result\n\n    _mode  \"\"\n    if refined:\n        high_rvi  _rvi(high, length, scalar, mamode, drift)\n        low_rvi  _rvi(low, length, scalar, mamode, drift)\n        rvi  0.5 * (high_rvi + low_rvi)\n        _mode  \"r\"\n    elif thirds:\n        high_rvi  _rvi(high, length, scalar, mamode, drift)\n        low_rvi  _rvi(low, length, scalar, mamode, drift)\n        close_rvi  _rvi(close, length, scalar, mamode, drift)\n        rvi  (high_rvi + low_rvi + close_rvi) / 3.0\n        _mode  \"t\"\n    else:\n        rvi  _rvi(close, length, scalar, mamode, drift)\n\n    # Offset\n    if offset ! 0:\n        rvi  rvi.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        rvi.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        rvi.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    rvi.name  f\"RVI{_mode}_{length}\"\n    rvi.category  \"volatility\"\n\n    return rvi\n\n\nrvi.__doc__  \\\n\"\"\"Relative Volatility Index (RVI)\n\nThe Relative Volatility Index (RVI) was created in 1993 and revised in 1995.\nInstead of adding up price changes like RSI based on price direction, the RVI\nadds up standard deviations based on price direction.\n\nSources:\n    https://www.tradingview.com/wiki/Keltner_Channels_(KC)\n\nCalculation:\n    Default Inputs:\n        length14, scalar100, refinedNone, thirdsNone\n    EMA  Exponential Moving Average\n    STDEV  Standard Deviation\n\n    UP  STDEV(src, length) IF src.diff() > 0 ELSE 0\n    DOWN  STDEV(src, length) IF src.diff() < 0 ELSE 0\n\n    UPSUM  EMA(UP, length)\n    DOWNSUM  EMA(DOWN, length\n\n    RVI  scalar * (UPSUM / (UPSUM + DOWNSUM))\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    length (int): The short period. Default: 14\n    scalar (float): A positive float to scale the bands. Default: 100\n    mamode (str): Options: 'sma' or 'ema'. Default: 'sma'\n    refined (bool): Use 'refined' calculation which is the average of\n        RVI(high) and RVI(low) instead of RVI(close). Default: False\n    thirds (bool): Average of high, low and close. Default: False\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: lower, basis, upper columns.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Context: Diretório pandas_ta com subpastas volatility e volume, contendo arquivos de indicadores técnicos.\\n\\nTópicos/Tecnologias: Indicadores de volatilidade (THERMO, True Range, Ulcer Index), indicadores de volume (AD, ADOSC, OBV, CMF, EFI), pandas, cálculo de médias móveis.')\npandas_ta/volatility/thermo.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import ma\nfrom pandas_ta.utils import get_offset, verify_series, get_drift\n\n\ndef thermo(high, low, lengthNone, longNone, shortNone, mamodeNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Elders Thermometer (THERMO)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 20\n    long  float(long) if long and long > 0 else 2\n    short  float(short) if short and short > 0 else 0.5\n    mamode  mamode if isinstance(mamode, str) else \"ema\"\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n    asint  kwargs.pop(\"asint\", True)\n\n    if high is None or low is None: return\n\n    # Calculate Result\n    thermoL  (low.shift(drift) - low).abs()\n    thermoH  (high - high.shift(drift)).abs()\n\n    thermo  thermoL\n    thermo  thermo.where(thermoH < thermoL, thermoH)\n    thermo.index  high.index\n\n    thermo_ma  ma(mamode, thermo, lengthlength)\n\n    # Create signals\n    thermo_long  thermo < (thermo_ma * long)\n    thermo_short  thermo > (thermo_ma * short)\n\n    # Binary output, useful for signals\n    if asint:\n        thermo_long  thermo_long.astype(int)\n        thermo_short  thermo_short.astype(int)\n\n    # Offset\n    if offset ! 0:\n        thermo  thermo.shift(offset)\n        thermo_ma  thermo_ma.shift(offset)\n        therthermo_longmo_ma  thermo_ma.shift(offset)\n        thermo_short  thermo_ma.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        thermo.fillna(kwargs[\"fillna\"], inplaceTrue)\n        thermo_ma.fillna(kwargs[\"fillna\"], inplaceTrue)\n        thermo_long.fillna(kwargs[\"fillna\"], inplaceTrue)\n        thermo_short.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        thermo.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        thermo_ma.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        thermo_long.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        thermo_short.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    _props  f\"_{length}_{long}_{short}\"\n    thermo.name  f\"THERMO{_props}\"\n    thermo_ma.name  f\"THERMOma{_props}\"\n    thermo_long.name  f\"THERMOl{_props}\"\n    thermo_short.name  f\"THERMOs{_props}\"\n\n    thermo.category  thermo_ma.category  thermo_long.category  thermo_short.category  \"volatility\"\n\n    # Prepare Dataframe to return\n    data  {\n        thermo.name: thermo,\n        thermo_ma.name: thermo_ma,\n        thermo_long.name: thermo_long,\n        thermo_short.name: thermo_short\n    }\n    df  DataFrame(data)\n    df.name  f\"THERMO{_props}\"\n    df.category  thermo.category\n\n    return df\n\n\n\nthermo.__doc__  \\\n\"\"\"Elders Thermometer (THERMO)\n\nElder's Thermometer measures price volatility.\n\nSources:\n    https://www.motivewave.com/studies/elders_thermometer.htm\n    https://www.tradingview.com/script/HqvTuEMW-Elder-s-Market-Thermometer-LazyBear/\n\nCalculation:\n    Default Inputs:\n    length20, drift1, mamodeEMA, long2, short0.5\n    EMA  Exponential Moving Average\n\n    thermoL  (low.shift(drift) - low).abs()\n    thermoH  (high - high.shift(drift)).abs()\n\n    thermo  np.where(thermoH > thermoL, thermoH, thermoL)\n    thermo_ma  ema(thermo, length)\n\n    thermo_long  thermo < (thermo_ma * long)\n    thermo_short  thermo > (thermo_ma * short)\n    thermo_long  thermo_long.astype(int)\n    thermo_short  thermo_short.astype(int)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    long(int): The buy factor\n    short(float): The sell factor\n    length (int): The  period. Default: 20\n    drift (int): The diff period. Default: 1\n    mamode (str): Three options: \"ema\", \"sma\", or \"hma\". Default: \"ema\"\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.DataFrame: thermo, thermo_ma, thermo_long, thermo_short columns.\n\"\"\"\n\n\npandas_ta/volatility/true_range.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import NaN as npNaN\nfrom pandas import DataFrame, concat\nfrom pandas_ta.utils import get_drift, get_offset, non_zero_range, verify_series\n\n\ndef true_range(high, low, close, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: True Range\"\"\"\n    # Validate arguments\n    high  verify_series(high)\n    low  verify_series(low)\n    close  verify_series(close)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    high_low_range  non_zero_range(high, low)\n    prev_close  close.shift(drift)\n    ranges  [high_low_range, high - prev_close, prev_close - low]\n    true_range  concat(ranges, axis1)\n    true_range  true_range.abs().max(axis1)\n    true_range.iloc[:drift]  npNaN\n\n    # Offset\n    if offset ! 0:\n        true_range  true_range.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        true_range.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        true_range.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    true_range.name  f\"TRUERANGE_{drift}\"\n    true_range.category  \"volatility\"\n\n    return true_range\n\n\ntrue_range.__doc__  \\\n\"\"\"True Range\n\nAn method to expand a classical range (high minus low) to include\npossible gap scenarios.\n\nSources:\n    https://www.macroption.com/true-range/\n\nCalculation:\n    Default Inputs:\n        drift1\n    ABS  Absolute Value\n    prev_close  close.shift(drift)\n    TRUE_RANGE  ABS([high - low, high - prev_close, low - prev_close])\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    drift (int): The shift period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature\n\"\"\"\n\n\n\npandas_ta/volatility/ui.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import sqrt as npsqrt\nfrom pandas_ta.overlap import sma\nfrom pandas_ta.utils import get_offset, non_zero_range, verify_series\n\n\ndef ui(close, lengthNone, scalarNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Ulcer Index (UI)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 14\n    scalar  float(scalar) if scalar and scalar > 0 else 100\n    close  verify_series(close, length)\n    offset  get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    highest_close  close.rolling(length).max()\n    downside  scalar * (close - highest_close)\n    downside / highest_close\n    d2  downside * downside\n\n    everget  kwargs.pop(\"everget\", False)\n    if everget:\n        # Everget uses SMA instead of SUM for calculation\n        ui  (sma(d2, length) / length).apply(npsqrt)\n    else:\n        ui  (d2.rolling(length).sum() / length).apply(npsqrt)\n\n    # Offset\n    if offset ! 0:\n        ui  ui.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        ui.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        ui.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    ui.name  f\"UI{'' if not everget else 'e'}_{length}\"\n    ui.category  \"volatility\"\n\n    return ui\n\n\nui.__doc__  \\\n\"\"\"Ulcer Index (UI)\n\nThe Ulcer Index by Peter Martin measures the downside volatility with the use of\nthe Quadratic Mean, which has the effect of emphasising large drawdowns.\n\nSources:\n    https://library.tradingtechnologies.com/trade/chrt-ti-ulcer-index.html\n    https://en.wikipedia.org/wiki/Ulcer_index\n    http://www.tangotools.com/ui/ui.htm\n\nCalculation:\n    Default Inputs:\n        length14, scalar100\n    HC  Highest Close\n    SMA  Simple Moving Average\n\n    HCN  HC(close, length)\n    DOWNSIDE  scalar * (close - HCN) / HCN\n    if kwargs[\"everget\"]:\n        UI  SQRT(SMA(DOWNSIDE^2, length) / length)\n    else:\n        UI  SQRT(SUM(DOWNSIDE^2, length) / length)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    close (pd.Series): Series of 'close's\n    length (int): The short period.  Default: 14\n    scalar (float): A positive float to scale the bands. Default: 100\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n    everget (value, optional): TradingView's Evergets SMA instead of SUM\n        calculation. Default: False\n\nReturns:\n    pd.Series: New feature\n\"\"\"\n\n\n\npandas_ta/volume/__init__.py\n\n# -*- coding: utf-8 -*-\nfrom .ad import ad\nfrom .adosc import adosc\nfrom .aobv import aobv\nfrom .cmf import cmf\nfrom .efi import efi\nfrom .eom import eom\nfrom .mfi import mfi\nfrom .nvi import nvi\nfrom .obv import obv\nfrom .pvi import pvi\nfrom .pvol import pvol\nfrom .pvr import pvr\nfrom .pvt import pvt\nfrom .vp import vp\n\n\n\npandas_ta/volume/ad.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, non_zero_range, verify_series\n\n\ndef ad(high, low, close, volume, open_None, offsetNone, **kwargs):\n    \"\"\"Indicator: Accumulation/Distribution (AD)\"\"\"\n    # Validate Arguments\n    high  verify_series(high)\n    low  verify_series(low)\n    close  verify_series(close)\n    volume  verify_series(volume)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    if open_ is not None:\n        open_  verify_series(open_)\n        ad  non_zero_range(close, open_)  # AD with Open\n    else:\n        ad  2 * close - (high + low)  # AD with High, Low, Close\n\n    high_low_range  non_zero_range(high, low)\n    ad * volume / high_low_range\n    ad  ad.cumsum()\n\n    # Offset\n    if offset ! 0:\n        ad  ad.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        ad.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        ad.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    ad.name  \"AD\" if open_ is None else \"ADo\"\n    ad.category  \"volume\"\n\n    return ad\n\n\nad.__doc__  \\\n\"\"\"Accumulation/Distribution (AD)\n\nAccumulation/Distribution indicator utilizes the relative position\nof the close to it's High-Low range with volume.  Then it is cumulated.\n\nSources:\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/accumulationdistribution-ad/\n\nCalculation:\n    CUM  Cumulative Sum\n    if 'open':\n        AD  close - open\n    else:\n        AD  2 * close - high - low\n\n    hl_range  high - low\n    AD  AD * volume / hl_range\n    AD  CUM(AD)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    open (pd.Series): Series of 'open's\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volume/adosc.py\n\n# -*- coding: utf-8 -*-\nfrom .ad import ad\nfrom pandas_ta.overlap import ema\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef adosc(high, low, close, volume, open_None, fastNone, slowNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Accumulation/Distribution Oscillator\"\"\"\n    # Validate Arguments\n    fast  int(fast) if fast and fast > 0 else 3\n    slow  int(slow) if slow and slow > 0 else 10\n    _length  max(fast, slow)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    volume  verify_series(volume, _length)\n    offset  get_offset(offset)\n    if \"length\" in kwargs: kwargs.pop(\"length\")\n\n    if high is None or low is None or close is None or volume is None: return\n\n    # Calculate Result\n    ad_  ad(highhigh, lowlow, closeclose, volumevolume, open_open_)\n    fast_ad  ema(closead_, lengthfast, **kwargs)\n    slow_ad  ema(closead_, lengthslow, **kwargs)\n    adosc  fast_ad - slow_ad\n\n    # Offset\n    if offset ! 0:\n        adosc  adosc.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        adosc.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        adosc.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    adosc.name  f\"ADOSC_{fast}_{slow}\"\n    adosc.category  \"volume\"\n\n    return adosc\n\n\nadosc.__doc__  \\\n\"\"\"Accumulation/Distribution Oscillator or Chaikin Oscillator\n\nAccumulation/Distribution Oscillator indicator utilizes\nAccumulation/Distribution and treats it similarily to MACD\nor APO.\n\nSources:\n    https://www.investopedia.com/articles/active-trading/031914/understanding-chaikin-oscillator.asp\n\nCalculation:\n    Default Inputs:\n        fast12, slow26\n    AD  Accum/Dist\n    ad  AD(high, low, close, open)\n    fast_ad  EMA(ad, fast)\n    slow_ad  EMA(ad, slow)\n    ADOSC  fast_ad - slow_ad\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    open (pd.Series): Series of 'open's\n    volume (pd.Series): Series of 'volume's\n    fast (int): The short period. Default: 12\n    slow (int): The long period. Default: 26\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volume/aobv.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom .obv import obv\nfrom pandas_ta.overlap import ma\nfrom pandas_ta.trend import long_run, short_run\nfrom pandas_ta.utils import get_offset, verify_series\n\n\ndef aobv(close, volume, fastNone, slowNone, mamodeNone, max_lookbackNone, min_lookbackNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Archer On Balance Volume (AOBV)\"\"\"\n    # Validate arguments\n    fast  int(fast) if fast and fast > 0 else 4\n    slow  int(slow) if slow and slow > 0 else 12\n    max_lookback  int(max_lookback) if max_lookback and max_lookback > 0 else 2\n    min_lookback  int(min_lookback) if min_lookback and min_lookback > 0 else 2\n    if slow < fast:\n        fast, slow  slow, fast\n    mamode  mamode if isinstance(mamode, str) else \"ema\"\n    _length  max(fast, slow, max_lookback, min_lookback)\n    close  verify_series(close, _length)\n    volume  verify_series(volume, _length)\n    offset  get_offset(offset)\n    if \"length\" in kwargs: kwargs.pop(\"length\")\n    run_length  kwargs.pop(\"run_length\", 2)\n\n    if close is None or volume is None: return\n\n    # Calculate Result\n    obv_  obv(closeclose, volumevolume, **kwargs)\n    maf  ma(mamode, obv_, lengthfast, **kwargs)\n    mas  ma(mamode, obv_, lengthslow, **kwargs)\n\n    # When MAs are long and short\n    obv_long  long_run(maf, mas, lengthrun_length)\n    obv_short  short_run(maf, mas, lengthrun_length)\n\n    # Offset\n    if offset ! 0:\n        obv_  obv_.shift(offset)\n        maf  maf.shift(offset)\n        mas  mas.shift(offset)\n        obv_long  obv_long.shift(offset)\n        obv_short  obv_short.shift(offset)\n\n    # # Handle fills\n    if \"fillna\" in kwargs:\n        obv_.fillna(kwargs[\"fillna\"], inplaceTrue)\n        maf.fillna(kwargs[\"fillna\"], inplaceTrue)\n        mas.fillna(kwargs[\"fillna\"], inplaceTrue)\n        obv_long.fillna(kwargs[\"fillna\"], inplaceTrue)\n        obv_short.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        obv_.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        maf.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        mas.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        obv_long.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n        obv_short.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Prepare DataFrame to return\n    _mode  mamode.lower()[0] if len(mamode) else \"\"\n    data  {\n        obv_.name: obv_,\n        f\"OBV_min_{min_lookback}\": obv_.rolling(min_lookback).min(),\n        f\"OBV_max_{max_lookback}\": obv_.rolling(max_lookback).max(),\n        f\"OBV{_mode}_{fast}\": maf,\n        f\"OBV{_mode}_{slow}\": mas,\n        f\"AOBV_LR_{run_length}\": obv_long,\n        f\"AOBV_SR_{run_length}\": obv_short,\n    }\n    aobvdf  DataFrame(data)\n\n    # Name and Categorize it\n    aobvdf.name  f\"AOBV{_mode}_{fast}_{slow}_{min_lookback}_{max_lookback}_{run_length}\"\n    aobvdf.category  \"volume\"\n\n    return aobvdf\n\n\n\npandas_ta/volume/cmf.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, non_zero_range, verify_series\n\n\ndef cmf(high, low, close, volume, open_None, lengthNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Chaikin Money Flow (CMF)\"\"\"\n    # Validate Arguments\n    length  int(length) if length and length > 0 else 20\n    min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    _length  max(length, min_periods)\n    high  verify_series(high, _length)\n    low  verify_series(low, _length)\n    close  verify_series(close, _length)\n    volume  verify_series(volume, _length)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None or volume is None: return\n\n    # Calculate Result\n    if open_ is not None:\n        open_  verify_series(open_)\n        ad  non_zero_range(close, open_)  # AD with Open\n    else:\n        ad  2 * close - (high + low)  # AD with High, Low, Close\n\n    ad * volume / non_zero_range(high, low)\n    cmf  ad.rolling(length, min_periodsmin_periods).sum()\n    cmf / volume.rolling(length, min_periodsmin_periods).sum()\n\n    # Offset\n    if offset ! 0:\n        cmf  cmf.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        cmf.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        cmf.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    cmf.name  f\"CMF_{length}\"\n    cmf.category  \"volume\"\n\n    return cmf\n\n\ncmf.__doc__  \\\n\"\"\"Chaikin Money Flow (CMF)\n\nChailin Money Flow measures the amount of money flow volume over a specific\nperiod in conjunction with Accumulation/Distribution.\n\nSources:\n    https://www.tradingview.com/wiki/Chaikin_Money_Flow_(CMF)\n    https://stockcharts.com/school/doku.php?idchart_school:technical_indicators:chaikin_money_flow_cmf\n\nCalculation:\n    Default Inputs:\n        length20\n    if 'open':\n        ad  close - open\n    else:\n        ad  2 * close - high - low\n\n    hl_range  high - low\n    ad  ad * volume / hl_range\n    CMF  SUM(ad, length) / SUM(volume, length)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    open_ (pd.Series): Series of 'open's. Default: None\n    length (int): The short period. Default: 20\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volume/efi.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import ma\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef efi(close, volume, lengthNone, driftNone, mamodeNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Elder's Force Index (EFI)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 13\n    mamode  mamode if isinstance(mamode, str) else \"ema\"\n    close  verify_series(close, length)\n    volume  verify_series(volume, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if close is None or volume is None: return\n\n    # Calculate Result\n    pv_diff  close.diff(drift) * volume\n    efi  ma(mamode, pv_diff, lengthlength)\n\n    # Offset\n    if offset ! 0:\n        efi  efi.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        efi.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        efi.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    efi.name  f\"EFI_{length}\"\n    efi.category  \"volume\"\n\n    return efi\n\n\nefi.__doc__  \\\n\"\"\"Elder's Force Index (EFI)\n\nElder's Force Index measures the power behind a price movement using price\nand volume as well as potential reversals and price corrections.\n\nSources:\n    https://www.tradingview.com/wiki/Elder%27s_Force_Index_(EFI)\n    https://www.motivewave.com/studies/elders_force_index.htm\n\nCalculation:\n    Default Inputs:\n        length20, drift1, mamodeNone\n    EMA  Exponential Moving Average\n    SMA  Simple Moving Average\n\n    pv_diff  close.diff(drift) * volume\n    if mamode  'sma':\n        EFI  SMA(pv_diff, length)\n    else:\n        EFI  EMA(pv_diff, length)\n\nArgs:\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    length (int): The short period. Default: 13\n    drift (int): The diff period. Default: 1\n    mamode (str): Two options: None or \"sma\". Default: None\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\n",
        "AgentRunResult(output='Context: This content is from the pandas_ta/volume directory, which contains various volume-based technical analysis indicators for the pandas_ta (Pandas Technical Analysis) library.\\n\\nMain topics and technologies: Python implementations of technical indicators like EOM, MFI, NVI, OBV, PVI, PVOL, PVR, PVT, and VP for analyzing financial time series data using volume and price. Each module defines a function to compute a specific volume-related indicator, returning pd.Series or pd.DataFrame objects with optional handling for missing values and customizable parameters.')\npandas_ta/volume/eom.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.overlap import hl2, sma\nfrom pandas_ta.utils import get_drift, get_offset, non_zero_range, verify_series\n\n\ndef eom(high, low, close, volume, lengthNone, divisorNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Ease of Movement (EOM)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 14\n    divisor  divisor if divisor and divisor > 0 else 100000000\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    volume  verify_series(volume, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None or volume is None: return\n\n    # Calculate Result\n    high_low_range  non_zero_range(high, low)\n    distance   hl2(highhigh, lowlow)\n    distance - hl2(highhigh.shift(drift), lowlow.shift(drift))\n    box_ratio  volume / divisor\n    box_ratio / high_low_range\n    eom  distance / box_ratio\n    eom  sma(eom, lengthlength)\n\n    # Offset\n    if offset ! 0:\n        eom  eom.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        eom.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        eom.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    eom.name  f\"EOM_{length}_{divisor}\"\n    eom.category  \"volume\"\n\n    return eom\n\n\neom.__doc__  \\\n\"\"\"Ease of Movement (EOM)\n\nEase of Movement is a volume based oscillator that is designed to measure the\nrelationship between price and volume flucuating across a zero line.\n\nSources:\n    https://www.tradingview.com/wiki/Ease_of_Movement_(EOM)\n    https://www.motivewave.com/studies/ease_of_movement.htm\n    https://stockcharts.com/school/doku.php?idchart_school:technical_indicators:ease_of_movement_emv\n\nCalculation:\n    Default Inputs:\n        length14, divisor100000000, drift1\n    SMA  Simple Moving Average\n    hl_range  high - low\n    distance  0.5 * (high - high.shift(drift) + low - low.shift(drift))\n    box_ratio  (volume / divisor) / hl_range\n    eom  distance / box_ratio\n    EOM  SMA(eom, length)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    length (int): The short period. Default: 14\n    drift (int): The diff period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volume/mfi.py\n\n# -*- coding: utf-8 -*-\nfrom pandas import DataFrame\nfrom pandas_ta.overlap import hlc3\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef mfi(high, low, close, volume, lengthNone, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Money Flow Index (MFI)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 14\n    high  verify_series(high, length)\n    low  verify_series(low, length)\n    close  verify_series(close, length)\n    volume  verify_series(volume, length)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    if high is None or low is None or close is None or volume is None: return\n\n    # Calculate Result\n    typical_price  hlc3(highhigh, lowlow, closeclose)\n    raw_money_flow  typical_price * volume\n\n    tdf  DataFrame({\"diff\": 0, \"rmf\": raw_money_flow, \"+mf\": 0, \"-mf\": 0})\n\n    tdf.loc[(typical_price.diff(drift) > 0), \"diff\"]  1\n    tdf.loc[tdf[\"diff\"]  1, \"+mf\"]  raw_money_flow\n\n    tdf.loc[(typical_price.diff(drift) < 0), \"diff\"]  -1\n    tdf.loc[tdf[\"diff\"]  -1, \"-mf\"]  raw_money_flow\n\n    psum  tdf[\"+mf\"].rolling(length).sum()\n    nsum  tdf[\"-mf\"].rolling(length).sum()\n    tdf[\"mr\"]  psum / nsum\n    mfi  100 * psum / (psum + nsum)\n    tdf[\"mfi\"]  mfi\n\n    # Offset\n    if offset ! 0:\n        mfi  mfi.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        mfi.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        mfi.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    mfi.name  f\"MFI_{length}\"\n    mfi.category  \"volume\"\n\n    return mfi\n\n\nmfi.__doc__  \\\n\"\"\"Money Flow Index (MFI)\n\nMoney Flow Index is an oscillator indicator that is used to measure buying and\nselling pressure by utilizing both price and volume.\n\nSources:\n    https://www.tradingview.com/wiki/Money_Flow_(MFI)\n\nCalculation:\n    Default Inputs:\n        length14, drift1\n    tp  typical_price  hlc3  (high + low + close) / 3\n    rmf  raw_money_flow  tp * volume\n\n    pmf  pos_money_flow  SUM(rmf, length) if tp.diff(drift) > 0 else 0\n    nmf  neg_money_flow  SUM(rmf, length) if tp.diff(drift) < 0 else 0\n\n    MFR  money_flow_ratio  pmf / nmf\n    MFI  money_flow_index  100 * pmf / (pmf + nmf)\n\nArgs:\n    high (pd.Series): Series of 'high's\n    low (pd.Series): Series of 'low's\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    length (int): The sum period. Default: 14\n    drift (int): The difference period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volume/nvi.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.momentum import roc\nfrom pandas_ta.utils import get_offset, signed_series, verify_series\n\n\ndef nvi(close, volume, lengthNone, initialNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Negative Volume Index (NVI)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 1\n    # min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    initial  int(initial) if initial and initial > 0 else 1000\n    close  verify_series(close, length)\n    volume  verify_series(volume, length)\n    offset  get_offset(offset)\n\n    if close is None or volume is None: return\n\n    # Calculate Result\n    roc_  roc(closeclose, lengthlength)\n    signed_volume  signed_series(volume, initial1)\n    nvi  signed_volume[signed_volume < 0].abs() * roc_\n    nvi.fillna(0, inplaceTrue)\n    nvi.iloc[0]  initial\n    nvi  nvi.cumsum()\n\n    # Offset\n    if offset ! 0:\n        nvi  nvi.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        nvi.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        nvi.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    nvi.name  f\"NVI_{length}\"\n    nvi.category  \"volume\"\n\n    return nvi\n\n\nnvi.__doc__  \\\n\"\"\"Negative Volume Index (NVI)\n\nThe Negative Volume Index is a cumulative indicator that uses volume change in\nan attempt to identify where smart money is active.\n\nSources:\n    https://stockcharts.com/school/doku.php?idchart_school:technical_indicators:negative_volume_inde\n    https://www.motivewave.com/studies/negative_volume_index.htm\n\nCalculation:\n    Default Inputs:\n        length1, initial1000\n    ROC  Rate of Change\n\n    roc  ROC(close, length)\n    signed_volume  signed_series(volume, initial1)\n    nvi  signed_volume[signed_volume < 0].abs() * roc_\n    nvi.fillna(0, inplaceTrue)\n    nvi.iloc[0] initial\n    nvi  nvi.cumsum()\n\nArgs:\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    length (int): The short period. Default: 13\n    initial (int): The short period. Default: 1000\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volume/obv.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, signed_series, verify_series\n\n\ndef obv(close, volume, offsetNone, **kwargs):\n    \"\"\"Indicator: On Balance Volume (OBV)\"\"\"\n    # Validate arguments\n    close  verify_series(close)\n    volume  verify_series(volume)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    signed_volume  signed_series(close, initial1) * volume\n    obv  signed_volume.cumsum()\n\n    # Offset\n    if offset ! 0:\n        obv  obv.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        obv.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        obv.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    obv.name  f\"OBV\"\n    obv.category  \"volume\"\n\n    return obv\n\n\nobv.__doc__  \\\n\"\"\"On Balance Volume (OBV)\n\nOn Balance Volume is a cumulative indicator to measure buying and selling\npressure.\n\nSources:\n    https://www.tradingview.com/wiki/On_Balance_Volume_(OBV)\n    https://www.tradingtechnologies.com/help/x-study/technical-indicator-definitions/on-balance-volume-obv/\n    https://www.motivewave.com/studies/on_balance_volume.htm\n\nCalculation:\n    signed_volume  signed_series(close, initial1) * volume\n    obv  signed_volume.cumsum()\n\nArgs:\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volume/pvi.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.momentum import roc\nfrom pandas_ta.utils import get_offset, signed_series, verify_series\n\n\ndef pvi(close, volume, lengthNone, initialNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Positive Volume Index (PVI)\"\"\"\n    # Validate arguments\n    length  int(length) if length and length > 0 else 1\n    # min_periods  int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    initial  int(initial) if initial and initial > 0 else 1000\n    close  verify_series(close, length)\n    volume  verify_series(volume, length)\n    offset  get_offset(offset)\n\n    if close is None or volume is None: return\n\n    # Calculate Result\n    roc_  roc(closeclose, lengthlength)\n    signed_volume  signed_series(volume, initial1)\n    pvi  signed_volume[signed_volume > 0].abs() * roc_\n    pvi.fillna(0, inplaceTrue)\n    pvi.iloc[0]  initial\n    pvi  pvi.cumsum()\n\n    # Offset\n    if offset ! 0:\n        pvi  pvi.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        pvi.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        pvi.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    pvi.name  f\"PVI_{length}\"\n    pvi.category  \"volume\"\n\n    return pvi\n\n\npvi.__doc__  \\\n\"\"\"Positive Volume Index (PVI)\n\nThe Positive Volume Index is a cumulative indicator that uses volume change in\nan attempt to identify where smart money is active.\nUsed in conjunction with NVI.\n\nSources:\n    https://www.investopedia.com/terms/p/pvi.asp\n\nCalculation:\n    Default Inputs:\n        length1, initial1000\n    ROC  Rate of Change\n\n    roc  ROC(close, length)\n    signed_volume  signed_series(volume, initial1)\n    pvi  signed_volume[signed_volume > 0].abs() * roc_\n    pvi.fillna(0, inplaceTrue)\n    pvi.iloc[0] initial\n    pvi  pvi.cumsum()\n\nArgs:\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    length (int): The short period. Default: 13\n    initial (int): The short period. Default: 1000\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volume/pvol.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import get_offset, signed_series, verify_series\n\n\ndef pvol(close, volume, offsetNone, **kwargs):\n    \"\"\"Indicator: Price-Volume (PVOL)\"\"\"\n    # Validate arguments\n    close  verify_series(close)\n    volume  verify_series(volume)\n    offset  get_offset(offset)\n    signed  kwargs.pop(\"signed\", False)\n\n    # Calculate Result\n    if signed:\n        pvol  signed_series(close, 1) * close * volume\n    else:\n        pvol  close * volume\n\n    # Offset\n    if offset ! 0:\n        pvol  pvol.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        pvol.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        pvol.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    pvol.name  f\"PVOL\"\n    pvol.category  \"volume\"\n\n    return pvol\n\n\npvol.__doc__  \\\n\"\"\"Price-Volume (PVOL)\n\nReturns a series of the product of price and volume.\n\nCalculation:\n    if signed:\n        pvol  signed_series(close, 1) * close * volume\n    else:\n        pvol  close * volume\n\nArgs:\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    signed (bool): Keeps the sign of the difference in 'close's. Default: True\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volume/pvr.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.utils import verify_series\nfrom numpy import nan as npNaN\nfrom pandas import Series\n\n\ndef pvr(close, volume):\n    \"\"\" Indicator: Price Volume Rank\"\"\"\n    # Validate arguments\n    close  verify_series(close)\n    volume  verify_series(volume)\n\n    # Calculate Result\n    close_diff  close.diff().fillna(0)\n    volume_diff  volume.diff().fillna(0)\n    pvr_  Series(npNaN, indexclose.index)\n    pvr_.loc[(close_diff > 0) & (volume_diff > 0)]  1\n    pvr_.loc[(close_diff > 0) & (volume_diff < 0)]   2\n    pvr_.loc[(close_diff < 0) & (volume_diff > 0)]   3\n    pvr_.loc[(close_diff < 0) & (volume_diff < 0)]    4\n\n    # Name and Categorize it\n    pvr_.name  f\"PVR\"\n    pvr_.category  \"volume\"\n\n    return pvr_\n\n\npvr.__doc__  \\\n\"\"\"Price Volume Rank\n\nThe Price Volume Rank was developed by Anthony J. Macek and is described in his\narticle in the June, 1994 issue of Technical Analysis of Stocks & Commodities\nMagazine. It was developed as a simple indicator that could be calculated even\nwithout a computer. The basic interpretation is to buy when the PV Rank is below\n2.5 and sell when it is above 2.5.\n\nSources:\n    https://www.fmlabs.com/reference/default.htm?urlPVrank.htm\n\nCalculation:\n    if 'close change' > 0 and 'volume change' > 0\n        return 1\n    if 'close change' > 0 and 'volume change' < 0\n        return 2\n    if 'close change' < 0 and 'volume change' > 0\n        return 3\n    if 'close change' < 0 and 'volume change' < 0\n        return 4\nArgs:\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volume/pvt.py\n\n# -*- coding: utf-8 -*-\nfrom pandas_ta.momentum import roc\nfrom pandas_ta.utils import get_drift, get_offset, verify_series\n\n\ndef pvt(close, volume, driftNone, offsetNone, **kwargs):\n    \"\"\"Indicator: Price-Volume Trend (PVT)\"\"\"\n    # Validate arguments\n    close  verify_series(close)\n    volume  verify_series(volume)\n    drift  get_drift(drift)\n    offset  get_offset(offset)\n\n    # Calculate Result\n    pv  roc(closeclose, lengthdrift) * volume\n    pvt  pv.cumsum()\n\n    # Offset\n    if offset ! 0:\n        pvt  pvt.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        pvt.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        pvt.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    pvt.name  f\"PVT\"\n    pvt.category  \"volume\"\n\n    return pvt\n\n\npvt.__doc__  \\\n\"\"\"Price-Volume Trend (PVT)\n\nThe Price-Volume Trend utilizes the Rate of Change with volume to\nand it's cumulative values to determine money flow.\n\nSources:\n    https://www.tradingview.com/wiki/Price_Volume_Trend_(PVT)\n\nCalculation:\n    Default Inputs:\n        drift1\n    ROC  Rate of Change\n    pv  ROC(close, drift) * volume\n    PVT  pv.cumsum()\n\nArgs:\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    drift (int): The diff period. Default: 1\n    offset (int): How many periods to offset the result. Default: 0\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n\nReturns:\n    pd.Series: New feature generated.\n\"\"\"\n\n\n\npandas_ta/volume/vp.py\n\n# -*- coding: utf-8 -*-\nfrom numpy import array_split\nfrom pandas import concat, DataFrame\nfrom pandas_ta.utils import signed_series, verify_series\n\n\ndef vp(close, volume, widthNone, **kwargs):\n    \"\"\"Indicator: Volume Profile (VP)\"\"\"\n    # Validate arguments\n    width  int(width) if width and width > 0 else 10\n    close  verify_series(close, width)\n    volume  verify_series(volume, width)\n    sort_close  kwargs.pop(\"sort_close\", False)\n\n    if close is None or volume is None: return\n\n    # Setup\n    signed_volume  signed_series(volume, initial1)\n    pos_volume  signed_volume[signed_volume > 0] * volume\n    neg_volume  signed_volume[signed_volume < 0] * -volume\n    vp  concat([close, pos_volume, neg_volume], axis1)\n\n    close_col  f\"{vp.columns[0]}\"\n    high_price_col  f\"high_{close_col}\"\n    low_price_col  f\"low_{close_col}\"\n    mean_price_col  f\"mean_{close_col}\"\n    mid_price_col  f\"mid_{close_col}\"\n\n    volume_col  f\"{vp.columns[1]}\"\n    pos_volume_col  f\"pos_{volume_col}\"\n    neg_volume_col  f\"neg_{volume_col}\"\n    total_volume_col  f\"total_{volume_col}\"\n    vp.columns  [close_col, pos_volume_col, neg_volume_col]\n\n    # sort_close: Sort by close before splitting into ranges. Default: False\n    # If False, it sorts by date index or chronological versus by price\n    if sort_close:\n        vp.sort_values(by[close_col], inplaceTrue)\n\n    # Calculate Result\n    vp_ranges  array_split(vp, width)\n    result  ({\n        low_price_col: r[close_col].min(),\n        mean_price_col: r[close_col].mean(),\n        high_price_col: r[close_col].max(),\n        pos_volume_col: r[pos_volume_col].sum(),\n        neg_volume_col: r[neg_volume_col].sum(),\n    } for r in vp_ranges)\n    vpdf  DataFrame(result)\n    vpdf[total_volume_col]  vpdf[pos_volume_col] + vpdf[neg_volume_col]\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        vpdf.fillna(kwargs[\"fillna\"], inplaceTrue)\n    if \"fill_method\" in kwargs:\n        vpdf.fillna(methodkwargs[\"fill_method\"], inplaceTrue)\n\n    # Name and Categorize it\n    vpdf.name  f\"VP_{width}\"\n    vpdf.category  \"volume\"\n\n    return vpdf\n\n\nvp.__doc__  \\\n\"\"\"Volume Profile (VP)\n\nCalculates the Volume Profile by slicing price into ranges.\nNote: Value Area is not calculated.\n\nSources:\n    https://stockcharts.com/school/doku.php?idchart_school:technical_indicators:volume_by_price\n    https://www.tradingview.com/wiki/Volume_Profile\n    http://www.ranchodinero.com/volume-tpo-essentials/\n    https://www.tradingtechnologies.com/blog/2013/05/15/volume-at-price/\n\nCalculation:\n    Default Inputs:\n        width10\n\n    vp  pd.concat([close, pos_volume, neg_volume], axis1)\n    vp_ranges  np.array_split(vp, width)\n    result  ({high_close, low_close, mean_close, neg_volume, pos_volume} foreach range in vp_ranges)\n    vpdf  pd.DataFrame(result)\n    vpdf['total_volume']  vpdf['pos_volume'] + vpdf['neg_volume']\n\nArgs:\n    close (pd.Series): Series of 'close's\n    volume (pd.Series): Series of 'volume's\n    width (int): How many ranges to distrubute price into. Default: 10\n\nKwargs:\n    fillna (value, optional): pd.DataFrame.fillna(value)\n    fill_method (value, optional): Type of fill method\n    sort_close (value, optional): Whether to sort by close before splitting\n        into ranges. Default: False\n\nReturns:\n    pd.DataFrame: New feature generated.\n\"\"\"\n\n\n\n"
    ],
    ".github": [
        "AgentRunResult(output='Context: .github/ISSUE_TEMPLATE folder in the root directory.  \\nCovers: GitHub issue templates for reporting bugs, requesting features, and suggesting new indicators for the Pandas TA project. Includes prompts for version info, code samples, and context.')\n.github/ISSUE_TEMPLATE/bug_report.md\n\n---\nname: Bug report\nabout: Create a report to help us improve.\ntitle: ''\nlabels: bug\nassignees: twopirllc\n\n---\n\n**Which version are you running? The lastest version is on Github. Pip is for major releases.**\n```python\nimport pandas_ta as ta\nprint(ta.version)\n```\n\n**Upgrade.**\n```sh\n$ pip install -U git+https://github.com/twopirllc/pandas-ta\n```\n\n**Describe the bug**\nA clear and concise description of what the bug is.\n\n**To Reproduce**\nProvide sample code.\n\n**Expected behavior**\nA clear and concise description of what you expected to happen.\n\n**Screenshots**\nIf applicable, add screenshots to help explain your problem.\n\n**Additional context**\nAdd any other context about the problem here.\n\nThanks for using Pandas TA!\n\n\n\n.github/ISSUE_TEMPLATE/feature_request.md\n\n---\nname: Feature request\nabout: Suggest an idea for this project.\ntitle: ''\nlabels: enhancement\nassignees: ''\n\n---\n\n**Which version are you running? The lastest version is Github. Pip is for major releases.**\n```python\nimport pandas_ta as ta\nprint(ta.version)\n```\n\n**Upgrade.**\n```sh\n$ pip install -U git+https://github.com/twopirllc/pandas-ta\n```\n\n**Is your feature request related to a problem? Please describe.**\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\n\n**Describe the solution you'd like**\nA clear and concise description of what you want to happen.\n\n**Describe alternatives you've considered**\nA clear and concise description of any alternative solutions or features you've considered.\n\n**Additional context**\nAdd any other context or screenshots about the feature request here.\n\nThanks for using Pandas TA!\n\n\n\n.github/ISSUE_TEMPLATE/indicator-request.md\n\n---\nname: Indicator Request\nabout: Be as detailed as possible with links please.\ntitle: ''\nlabels: enhancement\nassignees: twopirllc\n\n---\n\n**Which version are you running? The lastest version is on Github. Pip is for major releases.**\n```python\nimport pandas_ta as ta\nprint(ta.version)\n```\n\n**Upgrade.**\n```sh\n$ pip install -U git+https://github.com/twopirllc/pandas-ta\n```\n\n**Is your feature request related to a problem? Please describe.**\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\n\n**Describe the solution you'd like**\nA clear and concise description of what you want to happen.\n\n**Describe alternatives you've considered**\nA clear and concise description of any alternative solutions or features you've considered.\n\n**Additional context**\nAdd any other context, web links, or screenshots about the feature request here.\n\nThanks for using Pandas TA!"
    ],
    "docs": [
        "AgentRunResult(output='Este conteúdo pertence à pasta docs, dedicada à documentação do projeto pandas_ta. Ele inclui arquivos de configuração do Sphinx (conf.py), arquivos de build (Makefile, make.bat) e o índice principal (index.rst). As tecnologias principais envolvidas são Sphinx, reStructuredText (.rst) e Python, com foco em gerar documentação HTML, LaTeX, Texinfo, Epub e man pages para o projeto.')\ndocs/Makefile\n\n# Minimal makefile for Sphinx documentation\n#\n\n# You can set these variables from the command line.\nSPHINXOPTS    \nSPHINXBUILD    sphinx-build\nSOURCEDIR      .\nBUILDDIR       _build\n\n# Put it first so that \"make\" without argument is like \"make help\".\nhelp:\n\t@$(SPHINXBUILD) -M help \"$(SOURCEDIR)\" \"$(BUILDDIR)\" $(SPHINXOPTS) $(O)\n\n.PHONY: help Makefile\n\n# Catch-all target: route all unknown targets to Sphinx using the new\n# \"make mode\" option.  $(O) is meant as a shortcut for $(SPHINXOPTS).\n%: Makefile\n\t@$(SPHINXBUILD) -M $@ \"$(SOURCEDIR)\" \"$(BUILDDIR)\" $(SPHINXOPTS) $(O)\n\n\ndocs/conf.py\n\n# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\n# import os\n# import sys\n# sys.path.insert(0, os.path.abspath('.'))\n\n# -- Project information -----------------------------------------------------\n\nproject  \"pandas_ta\"\ncopyright  \"2019, Kevin Johnson\"\nauthor  \"Kevin Johnson\"\n\n# The short X.Y version\nversion  \"0.0.1\"\n# The full version, including alpha/beta/rc tags\nrelease  \"alpha\"\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx  '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions  [\n    \"sphinx.ext.todo\",\n    \"sphinx.ext.mathjax\",\n    \"sphinx.ext.viewcode\",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path  [\"_templates\"]\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix  ['.rst', '.md']\nsource_suffix  \".rst\"\n\n# The master toctree document.\nmaster_doc  \"index\"\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage  None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns  [\"_build\", \"Thumbs.db\", \".DS_Store\"]\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style  None\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme  \"alabaster\"\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options  {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path  [\"_static\"]\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don't match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``['localtoc.html', 'relations.html', 'sourcelink.html',\n# 'searchbox.html']``.\n#\n# html_sidebars  {}\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename  \"pandas_tadoc\"\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements  {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.\n    #\n    # 'preamble': '',\n    # Latex figure (float) alignment\n    #\n    # 'figure_align': 'htbp',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents  [\n    (\n        master_doc,\n        \"pandas_ta.tex\",\n        \"pandas\\\\_ta Documentation\",\n        \"Kevin Johnson\",\n        \"manual\",\n    ),\n]\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages  [(master_doc, \"pandas_ta\", \"pandas_ta Documentation\", [author], 1)]\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents  [\n    (\n        master_doc,\n        \"pandas_ta\",\n        \"pandas_ta Documentation\",\n        author,\n        \"pandas_ta\",\n        \"One line description of project.\",\n        \"Miscellaneous\",\n    ),\n]\n\n# -- Options for Epub output -------------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title  project\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#\n# epub_identifier  ''\n\n# A unique identification for the text.\n#\n# epub_uid  ''\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files  [\"search.html\"]\n\n# -- Extension configuration -------------------------------------------------\n\n# -- Options for todo extension ----------------------------------------------\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos  True\n\n\n\ndocs/index.rst\n\n.. pandas_ta documentation master file, created by\n   sphinx-quickstart on Mon Feb 18 11:41:11 2019.\n   You can adapt this file completely to your liking, but it should at least\n   contain the root `toctree` directive.\n\nWelcome to pandas_ta's documentation!\n\n\n.. toctree::\n   :maxdepth: 2\n   :caption: Contents:\n\n\n\nIndices and tables\n\n\n* :ref:`genindex`\n* :ref:`modindex`\n* :ref:`search`\n\n\n\ndocs/make.bat\n\n@ECHO OFF\n\npushd %~dp0\n\nREM Command file for Sphinx documentation\n\nif \"%SPHINXBUILD%\"  \"\" (\n\tset SPHINXBUILDsphinx-build\n)\nset SOURCEDIR.\nset BUILDDIR_build\n\nif \"%1\"  \"\" goto help\n\n%SPHINXBUILD% >NUL 2>NUL\nif errorlevel 9009 (\n\techo.\n\techo.The 'sphinx-build' command was not found. Make sure you have Sphinx\n\techo.installed, then set the SPHINXBUILD environment variable to point\n\techo.to the full path of the 'sphinx-build' executable. Alternatively you\n\techo.may add the Sphinx directory to PATH.\n\techo.\n\techo.If you don't have Sphinx installed, grab it from\n\techo.http://sphinx-doc.org/\n\texit /b 1\n)\n\n%SPHINXBUILD% -M %1 %SOURCEDIR% %BUILDDIR% %SPHINXOPTS%\ngoto end\n\n:help\n%SPHINXBUILD% -M help %SOURCEDIR% %BUILDDIR% %SPHINXOPTS%\n\n:end\npopd\n\n\n\n"
    ]
}